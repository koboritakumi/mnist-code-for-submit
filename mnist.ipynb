{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#print(sys.path)\n",
    "#sys.path.append('/Users/takumi/opt/anaconda3/envs/qc/lib/python3.9/site-packages')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas\n",
    "import tensorflow as tf\n",
    "from keras.layers import *\n",
    "#from keras.optimizers import *\n",
    "\n",
    "#dir(tf.keras.layers)\n",
    "#dir(tf.keras.optimizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train :  (60000, 28, 28)\n",
      "y_train :  (60000,)\n",
      "X_test :  (10000, 28, 28)\n",
      "y_test :  (10000,)\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train),(X_test, y_test) = mnist.load_data()\n",
    "X_train  = X_train.astype('float32')\n",
    "X_test   = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "print(\"X_train : \", X_train.shape)\n",
    "print(\"y_train : \", y_train.shape)\n",
    "print(\"X_test : \", X_test.shape)\n",
    "print(\"y_test : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_initialize(y_data):\n",
    "        y=[]\n",
    "        for _ in range(len(y_data)):\n",
    "            now=np.zeros(10)\n",
    "            now[y_data[_]]=1.0\n",
    "            y.append(now)\n",
    "\n",
    "        return np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = y_initialize(y_train)\n",
    "#y_test = y_initialize(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train (i=1):  0\n",
      "X_train (i=1): \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train (i=10):  3\n",
      "X_train (i=10): \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train (i=100):  5\n",
      "X_train (i=100): \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in [1,10,100]:\n",
    "    print(\"y_train\", \"(i=\"+str(i)+\"): \", y_train[i])\n",
    "    print(\"X_train\", \"(i=\"+str(i)+\"): \")    \n",
    "    plt.imshow(X_train[i], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/takumi/opt/anaconda3/envs/quantum/lib/python3.9/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(Flatten(input_shape=(28,28)))\n",
    "model.add(Dense(256,input_dim=784))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10,input_dim=256))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0)\n",
    "model.compile(optimizer=opt,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "#model.compile(optimizer=opt,\n",
    "#              loss='categorical_crossentropy',\n",
    "#              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks = []\n",
    "#callbacks.append(tf.keras.callbacks.CSVLogger(CSV_FILE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.0088 - accuracy: 0.7732 - val_loss: 0.5368 - val_accuracy: 0.8758\n",
      "Epoch 2/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.4765 - accuracy: 0.8778 - val_loss: 0.4004 - val_accuracy: 0.8967\n",
      "Epoch 3/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.3922 - accuracy: 0.8946 - val_loss: 0.3516 - val_accuracy: 0.9049\n",
      "Epoch 4/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.3527 - accuracy: 0.9028 - val_loss: 0.3240 - val_accuracy: 0.9114\n",
      "Epoch 5/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.3278 - accuracy: 0.9089 - val_loss: 0.3039 - val_accuracy: 0.9147\n",
      "Epoch 6/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.3093 - accuracy: 0.9137 - val_loss: 0.2893 - val_accuracy: 0.9198\n",
      "Epoch 7/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2945 - accuracy: 0.9174 - val_loss: 0.2772 - val_accuracy: 0.9239\n",
      "Epoch 8/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2822 - accuracy: 0.9206 - val_loss: 0.2666 - val_accuracy: 0.9273\n",
      "Epoch 9/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2713 - accuracy: 0.9241 - val_loss: 0.2587 - val_accuracy: 0.9294\n",
      "Epoch 10/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2617 - accuracy: 0.9264 - val_loss: 0.2508 - val_accuracy: 0.9294\n",
      "Epoch 11/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.2528 - accuracy: 0.9288 - val_loss: 0.2426 - val_accuracy: 0.9327\n",
      "Epoch 12/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2448 - accuracy: 0.9316 - val_loss: 0.2360 - val_accuracy: 0.9332\n",
      "Epoch 13/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2373 - accuracy: 0.9338 - val_loss: 0.2290 - val_accuracy: 0.9361\n",
      "Epoch 14/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2303 - accuracy: 0.9355 - val_loss: 0.2233 - val_accuracy: 0.9376\n",
      "Epoch 15/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2238 - accuracy: 0.9375 - val_loss: 0.2182 - val_accuracy: 0.9379\n",
      "Epoch 16/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2177 - accuracy: 0.9395 - val_loss: 0.2125 - val_accuracy: 0.9396\n",
      "Epoch 17/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.2120 - accuracy: 0.9407 - val_loss: 0.2076 - val_accuracy: 0.9409\n",
      "Epoch 18/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2064 - accuracy: 0.9425 - val_loss: 0.2025 - val_accuracy: 0.9429\n",
      "Epoch 19/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.2012 - accuracy: 0.9443 - val_loss: 0.1983 - val_accuracy: 0.9426\n",
      "Epoch 20/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1963 - accuracy: 0.9452 - val_loss: 0.1941 - val_accuracy: 0.9441\n",
      "Epoch 21/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1916 - accuracy: 0.9465 - val_loss: 0.1897 - val_accuracy: 0.9462\n",
      "Epoch 22/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1870 - accuracy: 0.9476 - val_loss: 0.1866 - val_accuracy: 0.9466\n",
      "Epoch 23/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1828 - accuracy: 0.9491 - val_loss: 0.1824 - val_accuracy: 0.9483\n",
      "Epoch 24/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1787 - accuracy: 0.9502 - val_loss: 0.1795 - val_accuracy: 0.9480\n",
      "Epoch 25/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1746 - accuracy: 0.9511 - val_loss: 0.1759 - val_accuracy: 0.9486\n",
      "Epoch 26/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1707 - accuracy: 0.9523 - val_loss: 0.1729 - val_accuracy: 0.9500\n",
      "Epoch 27/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1672 - accuracy: 0.9534 - val_loss: 0.1698 - val_accuracy: 0.9499\n",
      "Epoch 28/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1638 - accuracy: 0.9544 - val_loss: 0.1665 - val_accuracy: 0.9516\n",
      "Epoch 29/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1603 - accuracy: 0.9555 - val_loss: 0.1638 - val_accuracy: 0.9516\n",
      "Epoch 30/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1573 - accuracy: 0.9562 - val_loss: 0.1612 - val_accuracy: 0.9534\n",
      "Epoch 31/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1540 - accuracy: 0.9574 - val_loss: 0.1583 - val_accuracy: 0.9542\n",
      "Epoch 32/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1510 - accuracy: 0.9582 - val_loss: 0.1556 - val_accuracy: 0.9550\n",
      "Epoch 33/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1482 - accuracy: 0.9587 - val_loss: 0.1535 - val_accuracy: 0.9561\n",
      "Epoch 34/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1454 - accuracy: 0.9599 - val_loss: 0.1508 - val_accuracy: 0.9566\n",
      "Epoch 35/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1428 - accuracy: 0.9604 - val_loss: 0.1490 - val_accuracy: 0.9570\n",
      "Epoch 36/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1401 - accuracy: 0.9615 - val_loss: 0.1468 - val_accuracy: 0.9572\n",
      "Epoch 37/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1378 - accuracy: 0.9619 - val_loss: 0.1446 - val_accuracy: 0.9578\n",
      "Epoch 38/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1353 - accuracy: 0.9628 - val_loss: 0.1421 - val_accuracy: 0.9588\n",
      "Epoch 39/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1330 - accuracy: 0.9634 - val_loss: 0.1414 - val_accuracy: 0.9583\n",
      "Epoch 40/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1307 - accuracy: 0.9645 - val_loss: 0.1383 - val_accuracy: 0.9597\n",
      "Epoch 41/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1286 - accuracy: 0.9648 - val_loss: 0.1370 - val_accuracy: 0.9601\n",
      "Epoch 42/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1264 - accuracy: 0.9653 - val_loss: 0.1355 - val_accuracy: 0.9601\n",
      "Epoch 43/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1243 - accuracy: 0.9660 - val_loss: 0.1333 - val_accuracy: 0.9609\n",
      "Epoch 44/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1224 - accuracy: 0.9665 - val_loss: 0.1314 - val_accuracy: 0.9618\n",
      "Epoch 45/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1204 - accuracy: 0.9673 - val_loss: 0.1303 - val_accuracy: 0.9611\n",
      "Epoch 46/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1185 - accuracy: 0.9681 - val_loss: 0.1285 - val_accuracy: 0.9624\n",
      "Epoch 47/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1167 - accuracy: 0.9683 - val_loss: 0.1271 - val_accuracy: 0.9629\n",
      "Epoch 48/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1150 - accuracy: 0.9690 - val_loss: 0.1257 - val_accuracy: 0.9627\n",
      "Epoch 49/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1131 - accuracy: 0.9696 - val_loss: 0.1242 - val_accuracy: 0.9626\n",
      "Epoch 50/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1115 - accuracy: 0.9699 - val_loss: 0.1229 - val_accuracy: 0.9630\n",
      "Epoch 51/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1099 - accuracy: 0.9706 - val_loss: 0.1219 - val_accuracy: 0.9642\n",
      "Epoch 52/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1084 - accuracy: 0.9709 - val_loss: 0.1205 - val_accuracy: 0.9641\n",
      "Epoch 53/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1068 - accuracy: 0.9715 - val_loss: 0.1190 - val_accuracy: 0.9645\n",
      "Epoch 54/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1053 - accuracy: 0.9717 - val_loss: 0.1173 - val_accuracy: 0.9651\n",
      "Epoch 55/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1038 - accuracy: 0.9726 - val_loss: 0.1171 - val_accuracy: 0.9647\n",
      "Epoch 56/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1024 - accuracy: 0.9725 - val_loss: 0.1156 - val_accuracy: 0.9656\n",
      "Epoch 57/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1010 - accuracy: 0.9733 - val_loss: 0.1142 - val_accuracy: 0.9662\n",
      "Epoch 58/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0996 - accuracy: 0.9736 - val_loss: 0.1134 - val_accuracy: 0.9664\n",
      "Epoch 59/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0983 - accuracy: 0.9740 - val_loss: 0.1120 - val_accuracy: 0.9667\n",
      "Epoch 60/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0970 - accuracy: 0.9744 - val_loss: 0.1110 - val_accuracy: 0.9666\n",
      "Epoch 61/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0957 - accuracy: 0.9745 - val_loss: 0.1105 - val_accuracy: 0.9676\n",
      "Epoch 62/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0946 - accuracy: 0.9749 - val_loss: 0.1097 - val_accuracy: 0.9670\n",
      "Epoch 63/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0934 - accuracy: 0.9754 - val_loss: 0.1080 - val_accuracy: 0.9677\n",
      "Epoch 64/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0922 - accuracy: 0.9758 - val_loss: 0.1076 - val_accuracy: 0.9679\n",
      "Epoch 65/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0910 - accuracy: 0.9760 - val_loss: 0.1072 - val_accuracy: 0.9684\n",
      "Epoch 66/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0899 - accuracy: 0.9762 - val_loss: 0.1055 - val_accuracy: 0.9684\n",
      "Epoch 67/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0888 - accuracy: 0.9766 - val_loss: 0.1049 - val_accuracy: 0.9690\n",
      "Epoch 68/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0877 - accuracy: 0.9768 - val_loss: 0.1043 - val_accuracy: 0.9688\n",
      "Epoch 69/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0867 - accuracy: 0.9770 - val_loss: 0.1037 - val_accuracy: 0.9687\n",
      "Epoch 70/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0856 - accuracy: 0.9772 - val_loss: 0.1025 - val_accuracy: 0.9693\n",
      "Epoch 71/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0847 - accuracy: 0.9776 - val_loss: 0.1015 - val_accuracy: 0.9690\n",
      "Epoch 72/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0836 - accuracy: 0.9779 - val_loss: 0.1010 - val_accuracy: 0.9699\n",
      "Epoch 73/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0827 - accuracy: 0.9780 - val_loss: 0.1004 - val_accuracy: 0.9699\n",
      "Epoch 74/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0817 - accuracy: 0.9784 - val_loss: 0.0996 - val_accuracy: 0.9701\n",
      "Epoch 75/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0808 - accuracy: 0.9784 - val_loss: 0.0987 - val_accuracy: 0.9701\n",
      "Epoch 76/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0800 - accuracy: 0.9789 - val_loss: 0.0980 - val_accuracy: 0.9701\n",
      "Epoch 77/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0790 - accuracy: 0.9790 - val_loss: 0.0973 - val_accuracy: 0.9710\n",
      "Epoch 78/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0781 - accuracy: 0.9791 - val_loss: 0.0968 - val_accuracy: 0.9710\n",
      "Epoch 79/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0773 - accuracy: 0.9793 - val_loss: 0.0959 - val_accuracy: 0.9707\n",
      "Epoch 80/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0765 - accuracy: 0.9796 - val_loss: 0.0956 - val_accuracy: 0.9708\n",
      "Epoch 81/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0757 - accuracy: 0.9798 - val_loss: 0.0951 - val_accuracy: 0.9712\n",
      "Epoch 82/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0749 - accuracy: 0.9802 - val_loss: 0.0948 - val_accuracy: 0.9711\n",
      "Epoch 83/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0741 - accuracy: 0.9802 - val_loss: 0.0943 - val_accuracy: 0.9715\n",
      "Epoch 84/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0733 - accuracy: 0.9806 - val_loss: 0.0939 - val_accuracy: 0.9714\n",
      "Epoch 85/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0726 - accuracy: 0.9809 - val_loss: 0.0926 - val_accuracy: 0.9716\n",
      "Epoch 86/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0718 - accuracy: 0.9809 - val_loss: 0.0924 - val_accuracy: 0.9719\n",
      "Epoch 87/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0710 - accuracy: 0.9812 - val_loss: 0.0917 - val_accuracy: 0.9722\n",
      "Epoch 88/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0703 - accuracy: 0.9812 - val_loss: 0.0916 - val_accuracy: 0.9718\n",
      "Epoch 89/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0696 - accuracy: 0.9814 - val_loss: 0.0911 - val_accuracy: 0.9718\n",
      "Epoch 90/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0689 - accuracy: 0.9816 - val_loss: 0.0907 - val_accuracy: 0.9722\n",
      "Epoch 91/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0682 - accuracy: 0.9820 - val_loss: 0.0896 - val_accuracy: 0.9722\n",
      "Epoch 92/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0676 - accuracy: 0.9822 - val_loss: 0.0896 - val_accuracy: 0.9725\n",
      "Epoch 93/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0669 - accuracy: 0.9823 - val_loss: 0.0891 - val_accuracy: 0.9728\n",
      "Epoch 94/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0662 - accuracy: 0.9826 - val_loss: 0.0890 - val_accuracy: 0.9729\n",
      "Epoch 95/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0656 - accuracy: 0.9827 - val_loss: 0.0879 - val_accuracy: 0.9726\n",
      "Epoch 96/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0649 - accuracy: 0.9830 - val_loss: 0.0879 - val_accuracy: 0.9727\n",
      "Epoch 97/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0643 - accuracy: 0.9832 - val_loss: 0.0876 - val_accuracy: 0.9727\n",
      "Epoch 98/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0638 - accuracy: 0.9831 - val_loss: 0.0866 - val_accuracy: 0.9730\n",
      "Epoch 99/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0632 - accuracy: 0.9834 - val_loss: 0.0864 - val_accuracy: 0.9733\n",
      "Epoch 100/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0626 - accuracy: 0.9834 - val_loss: 0.0861 - val_accuracy: 0.9732\n",
      "Epoch 101/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0620 - accuracy: 0.9837 - val_loss: 0.0855 - val_accuracy: 0.9733\n",
      "Epoch 102/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0614 - accuracy: 0.9841 - val_loss: 0.0852 - val_accuracy: 0.9736\n",
      "Epoch 103/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0608 - accuracy: 0.9840 - val_loss: 0.0851 - val_accuracy: 0.9737\n",
      "Epoch 104/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0603 - accuracy: 0.9844 - val_loss: 0.0844 - val_accuracy: 0.9737\n",
      "Epoch 105/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0597 - accuracy: 0.9847 - val_loss: 0.0841 - val_accuracy: 0.9735\n",
      "Epoch 106/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0592 - accuracy: 0.9847 - val_loss: 0.0842 - val_accuracy: 0.9739\n",
      "Epoch 107/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0587 - accuracy: 0.9847 - val_loss: 0.0836 - val_accuracy: 0.9740\n",
      "Epoch 108/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0582 - accuracy: 0.9851 - val_loss: 0.0831 - val_accuracy: 0.9741\n",
      "Epoch 109/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0576 - accuracy: 0.9850 - val_loss: 0.0830 - val_accuracy: 0.9740\n",
      "Epoch 110/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0571 - accuracy: 0.9851 - val_loss: 0.0825 - val_accuracy: 0.9742\n",
      "Epoch 111/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0566 - accuracy: 0.9857 - val_loss: 0.0821 - val_accuracy: 0.9751\n",
      "Epoch 112/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0561 - accuracy: 0.9856 - val_loss: 0.0816 - val_accuracy: 0.9752\n",
      "Epoch 113/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0556 - accuracy: 0.9857 - val_loss: 0.0817 - val_accuracy: 0.9743\n",
      "Epoch 114/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0552 - accuracy: 0.9860 - val_loss: 0.0813 - val_accuracy: 0.9749\n",
      "Epoch 115/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0547 - accuracy: 0.9862 - val_loss: 0.0816 - val_accuracy: 0.9745\n",
      "Epoch 116/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0542 - accuracy: 0.9862 - val_loss: 0.0806 - val_accuracy: 0.9755\n",
      "Epoch 117/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0538 - accuracy: 0.9864 - val_loss: 0.0801 - val_accuracy: 0.9751\n",
      "Epoch 118/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0533 - accuracy: 0.9865 - val_loss: 0.0803 - val_accuracy: 0.9752\n",
      "Epoch 119/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0529 - accuracy: 0.9867 - val_loss: 0.0800 - val_accuracy: 0.9748\n",
      "Epoch 120/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0525 - accuracy: 0.9867 - val_loss: 0.0793 - val_accuracy: 0.9754\n",
      "Epoch 121/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0520 - accuracy: 0.9870 - val_loss: 0.0795 - val_accuracy: 0.9747\n",
      "Epoch 122/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0516 - accuracy: 0.9869 - val_loss: 0.0790 - val_accuracy: 0.9759\n",
      "Epoch 123/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0511 - accuracy: 0.9872 - val_loss: 0.0790 - val_accuracy: 0.9757\n",
      "Epoch 124/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0507 - accuracy: 0.9873 - val_loss: 0.0787 - val_accuracy: 0.9757\n",
      "Epoch 125/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0503 - accuracy: 0.9874 - val_loss: 0.0779 - val_accuracy: 0.9759\n",
      "Epoch 126/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0499 - accuracy: 0.9874 - val_loss: 0.0781 - val_accuracy: 0.9753\n",
      "Epoch 127/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0496 - accuracy: 0.9875 - val_loss: 0.0778 - val_accuracy: 0.9758\n",
      "Epoch 128/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0491 - accuracy: 0.9876 - val_loss: 0.0777 - val_accuracy: 0.9759\n",
      "Epoch 129/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0487 - accuracy: 0.9879 - val_loss: 0.0775 - val_accuracy: 0.9758\n",
      "Epoch 130/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0483 - accuracy: 0.9880 - val_loss: 0.0769 - val_accuracy: 0.9765\n",
      "Epoch 131/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0480 - accuracy: 0.9879 - val_loss: 0.0767 - val_accuracy: 0.9761\n",
      "Epoch 132/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0476 - accuracy: 0.9883 - val_loss: 0.0769 - val_accuracy: 0.9763\n",
      "Epoch 133/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0472 - accuracy: 0.9885 - val_loss: 0.0763 - val_accuracy: 0.9763\n",
      "Epoch 134/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0468 - accuracy: 0.9884 - val_loss: 0.0762 - val_accuracy: 0.9760\n",
      "Epoch 135/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0465 - accuracy: 0.9887 - val_loss: 0.0763 - val_accuracy: 0.9762\n",
      "Epoch 136/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0461 - accuracy: 0.9887 - val_loss: 0.0758 - val_accuracy: 0.9763\n",
      "Epoch 137/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0458 - accuracy: 0.9887 - val_loss: 0.0755 - val_accuracy: 0.9762\n",
      "Epoch 138/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0454 - accuracy: 0.9890 - val_loss: 0.0757 - val_accuracy: 0.9761\n",
      "Epoch 139/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0451 - accuracy: 0.9890 - val_loss: 0.0753 - val_accuracy: 0.9761\n",
      "Epoch 140/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0447 - accuracy: 0.9893 - val_loss: 0.0747 - val_accuracy: 0.9768\n",
      "Epoch 141/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0444 - accuracy: 0.9893 - val_loss: 0.0748 - val_accuracy: 0.9766\n",
      "Epoch 142/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0440 - accuracy: 0.9894 - val_loss: 0.0747 - val_accuracy: 0.9767\n",
      "Epoch 143/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0437 - accuracy: 0.9894 - val_loss: 0.0748 - val_accuracy: 0.9770\n",
      "Epoch 144/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0434 - accuracy: 0.9897 - val_loss: 0.0744 - val_accuracy: 0.9765\n",
      "Epoch 145/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0431 - accuracy: 0.9897 - val_loss: 0.0744 - val_accuracy: 0.9765\n",
      "Epoch 146/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0427 - accuracy: 0.9899 - val_loss: 0.0742 - val_accuracy: 0.9770\n",
      "Epoch 147/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0424 - accuracy: 0.9901 - val_loss: 0.0736 - val_accuracy: 0.9772\n",
      "Epoch 148/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0421 - accuracy: 0.9899 - val_loss: 0.0737 - val_accuracy: 0.9770\n",
      "Epoch 149/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0418 - accuracy: 0.9902 - val_loss: 0.0737 - val_accuracy: 0.9769\n",
      "Epoch 150/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0415 - accuracy: 0.9902 - val_loss: 0.0735 - val_accuracy: 0.9770\n",
      "Epoch 151/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0412 - accuracy: 0.9904 - val_loss: 0.0737 - val_accuracy: 0.9771\n",
      "Epoch 152/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0409 - accuracy: 0.9905 - val_loss: 0.0733 - val_accuracy: 0.9773\n",
      "Epoch 153/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0406 - accuracy: 0.9907 - val_loss: 0.0733 - val_accuracy: 0.9771\n",
      "Epoch 154/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0403 - accuracy: 0.9905 - val_loss: 0.0728 - val_accuracy: 0.9777\n",
      "Epoch 155/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0400 - accuracy: 0.9908 - val_loss: 0.0728 - val_accuracy: 0.9770\n",
      "Epoch 156/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0397 - accuracy: 0.9909 - val_loss: 0.0725 - val_accuracy: 0.9774\n",
      "Epoch 157/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0394 - accuracy: 0.9910 - val_loss: 0.0728 - val_accuracy: 0.9774\n",
      "Epoch 158/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0392 - accuracy: 0.9908 - val_loss: 0.0722 - val_accuracy: 0.9775\n",
      "Epoch 159/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0389 - accuracy: 0.9911 - val_loss: 0.0719 - val_accuracy: 0.9778\n",
      "Epoch 160/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0386 - accuracy: 0.9912 - val_loss: 0.0717 - val_accuracy: 0.9776\n",
      "Epoch 161/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0383 - accuracy: 0.9913 - val_loss: 0.0717 - val_accuracy: 0.9778\n",
      "Epoch 162/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0381 - accuracy: 0.9912 - val_loss: 0.0718 - val_accuracy: 0.9778\n",
      "Epoch 163/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0378 - accuracy: 0.9914 - val_loss: 0.0717 - val_accuracy: 0.9776\n",
      "Epoch 164/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0375 - accuracy: 0.9913 - val_loss: 0.0717 - val_accuracy: 0.9777\n",
      "Epoch 165/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0373 - accuracy: 0.9916 - val_loss: 0.0711 - val_accuracy: 0.9776\n",
      "Epoch 166/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0370 - accuracy: 0.9917 - val_loss: 0.0711 - val_accuracy: 0.9780\n",
      "Epoch 167/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0367 - accuracy: 0.9917 - val_loss: 0.0715 - val_accuracy: 0.9777\n",
      "Epoch 168/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0365 - accuracy: 0.9916 - val_loss: 0.0711 - val_accuracy: 0.9773\n",
      "Epoch 169/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0362 - accuracy: 0.9919 - val_loss: 0.0711 - val_accuracy: 0.9779\n",
      "Epoch 170/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0360 - accuracy: 0.9920 - val_loss: 0.0708 - val_accuracy: 0.9781\n",
      "Epoch 171/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0357 - accuracy: 0.9922 - val_loss: 0.0703 - val_accuracy: 0.9782\n",
      "Epoch 172/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0355 - accuracy: 0.9920 - val_loss: 0.0706 - val_accuracy: 0.9776\n",
      "Epoch 173/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0353 - accuracy: 0.9921 - val_loss: 0.0703 - val_accuracy: 0.9778\n",
      "Epoch 174/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0350 - accuracy: 0.9922 - val_loss: 0.0705 - val_accuracy: 0.9779\n",
      "Epoch 175/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0348 - accuracy: 0.9923 - val_loss: 0.0700 - val_accuracy: 0.9778\n",
      "Epoch 176/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0346 - accuracy: 0.9924 - val_loss: 0.0700 - val_accuracy: 0.9778\n",
      "Epoch 177/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0344 - accuracy: 0.9924 - val_loss: 0.0700 - val_accuracy: 0.9781\n",
      "Epoch 178/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0341 - accuracy: 0.9924 - val_loss: 0.0699 - val_accuracy: 0.9781\n",
      "Epoch 179/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0339 - accuracy: 0.9925 - val_loss: 0.0698 - val_accuracy: 0.9783\n",
      "Epoch 180/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0336 - accuracy: 0.9926 - val_loss: 0.0698 - val_accuracy: 0.9784\n",
      "Epoch 181/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0334 - accuracy: 0.9928 - val_loss: 0.0695 - val_accuracy: 0.9778\n",
      "Epoch 182/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0332 - accuracy: 0.9926 - val_loss: 0.0697 - val_accuracy: 0.9778\n",
      "Epoch 183/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0330 - accuracy: 0.9927 - val_loss: 0.0697 - val_accuracy: 0.9777\n",
      "Epoch 184/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0328 - accuracy: 0.9929 - val_loss: 0.0692 - val_accuracy: 0.9779\n",
      "Epoch 185/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0325 - accuracy: 0.9929 - val_loss: 0.0692 - val_accuracy: 0.9777\n",
      "Epoch 186/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0323 - accuracy: 0.9930 - val_loss: 0.0695 - val_accuracy: 0.9780\n",
      "Epoch 187/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0321 - accuracy: 0.9932 - val_loss: 0.0691 - val_accuracy: 0.9783\n",
      "Epoch 188/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0319 - accuracy: 0.9932 - val_loss: 0.0688 - val_accuracy: 0.9781\n",
      "Epoch 189/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0317 - accuracy: 0.9933 - val_loss: 0.0687 - val_accuracy: 0.9776\n",
      "Epoch 190/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0315 - accuracy: 0.9933 - val_loss: 0.0690 - val_accuracy: 0.9776\n",
      "Epoch 191/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0313 - accuracy: 0.9934 - val_loss: 0.0685 - val_accuracy: 0.9779\n",
      "Epoch 192/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0311 - accuracy: 0.9933 - val_loss: 0.0685 - val_accuracy: 0.9780\n",
      "Epoch 193/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0309 - accuracy: 0.9934 - val_loss: 0.0684 - val_accuracy: 0.9781\n",
      "Epoch 194/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0306 - accuracy: 0.9936 - val_loss: 0.0684 - val_accuracy: 0.9779\n",
      "Epoch 195/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0305 - accuracy: 0.9935 - val_loss: 0.0681 - val_accuracy: 0.9778\n",
      "Epoch 196/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0303 - accuracy: 0.9937 - val_loss: 0.0680 - val_accuracy: 0.9779\n",
      "Epoch 197/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0301 - accuracy: 0.9938 - val_loss: 0.0681 - val_accuracy: 0.9783\n",
      "Epoch 198/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0299 - accuracy: 0.9939 - val_loss: 0.0678 - val_accuracy: 0.9781\n",
      "Epoch 199/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0297 - accuracy: 0.9939 - val_loss: 0.0680 - val_accuracy: 0.9778\n",
      "Epoch 200/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0295 - accuracy: 0.9938 - val_loss: 0.0681 - val_accuracy: 0.9783\n",
      "Epoch 201/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0293 - accuracy: 0.9941 - val_loss: 0.0677 - val_accuracy: 0.9784\n",
      "Epoch 202/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0292 - accuracy: 0.9940 - val_loss: 0.0682 - val_accuracy: 0.9781\n",
      "Epoch 203/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0290 - accuracy: 0.9941 - val_loss: 0.0678 - val_accuracy: 0.9781\n",
      "Epoch 204/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0288 - accuracy: 0.9941 - val_loss: 0.0675 - val_accuracy: 0.9780\n",
      "Epoch 205/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0286 - accuracy: 0.9944 - val_loss: 0.0679 - val_accuracy: 0.9781\n",
      "Epoch 206/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0284 - accuracy: 0.9942 - val_loss: 0.0678 - val_accuracy: 0.9779\n",
      "Epoch 207/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0282 - accuracy: 0.9944 - val_loss: 0.0674 - val_accuracy: 0.9784\n",
      "Epoch 208/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0281 - accuracy: 0.9946 - val_loss: 0.0673 - val_accuracy: 0.9783\n",
      "Epoch 209/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0279 - accuracy: 0.9946 - val_loss: 0.0672 - val_accuracy: 0.9782\n",
      "Epoch 210/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0278 - accuracy: 0.9946 - val_loss: 0.0670 - val_accuracy: 0.9784\n",
      "Epoch 211/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0276 - accuracy: 0.9945 - val_loss: 0.0671 - val_accuracy: 0.9785\n",
      "Epoch 212/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0274 - accuracy: 0.9947 - val_loss: 0.0674 - val_accuracy: 0.9779\n",
      "Epoch 213/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0273 - accuracy: 0.9949 - val_loss: 0.0671 - val_accuracy: 0.9782\n",
      "Epoch 214/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0271 - accuracy: 0.9948 - val_loss: 0.0669 - val_accuracy: 0.9785\n",
      "Epoch 215/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0269 - accuracy: 0.9948 - val_loss: 0.0670 - val_accuracy: 0.9784\n",
      "Epoch 216/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0268 - accuracy: 0.9949 - val_loss: 0.0669 - val_accuracy: 0.9782\n",
      "Epoch 217/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0266 - accuracy: 0.9949 - val_loss: 0.0669 - val_accuracy: 0.9782\n",
      "Epoch 218/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0264 - accuracy: 0.9949 - val_loss: 0.0671 - val_accuracy: 0.9779\n",
      "Epoch 219/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0263 - accuracy: 0.9950 - val_loss: 0.0667 - val_accuracy: 0.9783\n",
      "Epoch 220/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0261 - accuracy: 0.9951 - val_loss: 0.0665 - val_accuracy: 0.9791\n",
      "Epoch 221/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0260 - accuracy: 0.9951 - val_loss: 0.0666 - val_accuracy: 0.9782\n",
      "Epoch 222/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0258 - accuracy: 0.9951 - val_loss: 0.0665 - val_accuracy: 0.9780\n",
      "Epoch 223/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0257 - accuracy: 0.9954 - val_loss: 0.0668 - val_accuracy: 0.9779\n",
      "Epoch 224/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0255 - accuracy: 0.9952 - val_loss: 0.0665 - val_accuracy: 0.9783\n",
      "Epoch 225/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0254 - accuracy: 0.9953 - val_loss: 0.0666 - val_accuracy: 0.9782\n",
      "Epoch 226/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0252 - accuracy: 0.9954 - val_loss: 0.0663 - val_accuracy: 0.9790\n",
      "Epoch 227/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0251 - accuracy: 0.9954 - val_loss: 0.0665 - val_accuracy: 0.9781\n",
      "Epoch 228/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0249 - accuracy: 0.9955 - val_loss: 0.0665 - val_accuracy: 0.9784\n",
      "Epoch 229/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0248 - accuracy: 0.9955 - val_loss: 0.0665 - val_accuracy: 0.9782\n",
      "Epoch 230/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0246 - accuracy: 0.9955 - val_loss: 0.0663 - val_accuracy: 0.9781\n",
      "Epoch 231/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0245 - accuracy: 0.9956 - val_loss: 0.0662 - val_accuracy: 0.9786\n",
      "Epoch 232/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0243 - accuracy: 0.9957 - val_loss: 0.0663 - val_accuracy: 0.9785\n",
      "Epoch 233/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0242 - accuracy: 0.9957 - val_loss: 0.0660 - val_accuracy: 0.9785\n",
      "Epoch 234/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0241 - accuracy: 0.9957 - val_loss: 0.0662 - val_accuracy: 0.9788\n",
      "Epoch 235/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0239 - accuracy: 0.9958 - val_loss: 0.0659 - val_accuracy: 0.9789\n",
      "Epoch 236/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0238 - accuracy: 0.9959 - val_loss: 0.0658 - val_accuracy: 0.9785\n",
      "Epoch 237/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0236 - accuracy: 0.9959 - val_loss: 0.0659 - val_accuracy: 0.9787\n",
      "Epoch 238/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0235 - accuracy: 0.9959 - val_loss: 0.0661 - val_accuracy: 0.9781\n",
      "Epoch 239/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0234 - accuracy: 0.9959 - val_loss: 0.0658 - val_accuracy: 0.9787\n",
      "Epoch 240/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0232 - accuracy: 0.9961 - val_loss: 0.0658 - val_accuracy: 0.9790\n",
      "Epoch 241/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0231 - accuracy: 0.9960 - val_loss: 0.0657 - val_accuracy: 0.9788\n",
      "Epoch 242/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0230 - accuracy: 0.9962 - val_loss: 0.0657 - val_accuracy: 0.9788\n",
      "Epoch 243/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0229 - accuracy: 0.9962 - val_loss: 0.0656 - val_accuracy: 0.9788\n",
      "Epoch 244/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0227 - accuracy: 0.9962 - val_loss: 0.0660 - val_accuracy: 0.9785\n",
      "Epoch 245/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0226 - accuracy: 0.9962 - val_loss: 0.0657 - val_accuracy: 0.9784\n",
      "Epoch 246/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0225 - accuracy: 0.9963 - val_loss: 0.0655 - val_accuracy: 0.9787\n",
      "Epoch 247/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0223 - accuracy: 0.9962 - val_loss: 0.0657 - val_accuracy: 0.9787\n",
      "Epoch 248/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0222 - accuracy: 0.9963 - val_loss: 0.0656 - val_accuracy: 0.9785\n",
      "Epoch 249/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0221 - accuracy: 0.9963 - val_loss: 0.0657 - val_accuracy: 0.9783\n",
      "Epoch 250/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0220 - accuracy: 0.9964 - val_loss: 0.0656 - val_accuracy: 0.9783\n",
      "Epoch 251/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0219 - accuracy: 0.9964 - val_loss: 0.0653 - val_accuracy: 0.9787\n",
      "Epoch 252/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0217 - accuracy: 0.9966 - val_loss: 0.0654 - val_accuracy: 0.9789\n",
      "Epoch 253/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0216 - accuracy: 0.9965 - val_loss: 0.0652 - val_accuracy: 0.9790\n",
      "Epoch 254/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0215 - accuracy: 0.9966 - val_loss: 0.0654 - val_accuracy: 0.9788\n",
      "Epoch 255/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0214 - accuracy: 0.9966 - val_loss: 0.0654 - val_accuracy: 0.9784\n",
      "Epoch 256/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0213 - accuracy: 0.9966 - val_loss: 0.0654 - val_accuracy: 0.9784\n",
      "Epoch 257/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0211 - accuracy: 0.9966 - val_loss: 0.0657 - val_accuracy: 0.9784\n",
      "Epoch 258/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0210 - accuracy: 0.9965 - val_loss: 0.0652 - val_accuracy: 0.9791\n",
      "Epoch 259/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0209 - accuracy: 0.9966 - val_loss: 0.0652 - val_accuracy: 0.9787\n",
      "Epoch 260/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0208 - accuracy: 0.9968 - val_loss: 0.0655 - val_accuracy: 0.9788\n",
      "Epoch 261/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0207 - accuracy: 0.9967 - val_loss: 0.0650 - val_accuracy: 0.9785\n",
      "Epoch 262/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0206 - accuracy: 0.9969 - val_loss: 0.0653 - val_accuracy: 0.9787\n",
      "Epoch 263/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0205 - accuracy: 0.9968 - val_loss: 0.0653 - val_accuracy: 0.9788\n",
      "Epoch 264/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0204 - accuracy: 0.9969 - val_loss: 0.0651 - val_accuracy: 0.9785\n",
      "Epoch 265/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0203 - accuracy: 0.9970 - val_loss: 0.0651 - val_accuracy: 0.9790\n",
      "Epoch 266/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0202 - accuracy: 0.9969 - val_loss: 0.0649 - val_accuracy: 0.9788\n",
      "Epoch 267/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0200 - accuracy: 0.9970 - val_loss: 0.0648 - val_accuracy: 0.9783\n",
      "Epoch 268/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0199 - accuracy: 0.9972 - val_loss: 0.0653 - val_accuracy: 0.9788\n",
      "Epoch 269/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0198 - accuracy: 0.9971 - val_loss: 0.0650 - val_accuracy: 0.9789\n",
      "Epoch 270/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0197 - accuracy: 0.9970 - val_loss: 0.0650 - val_accuracy: 0.9786\n",
      "Epoch 271/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0196 - accuracy: 0.9971 - val_loss: 0.0649 - val_accuracy: 0.9787\n",
      "Epoch 272/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0195 - accuracy: 0.9971 - val_loss: 0.0649 - val_accuracy: 0.9787\n",
      "Epoch 273/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0194 - accuracy: 0.9972 - val_loss: 0.0650 - val_accuracy: 0.9787\n",
      "Epoch 274/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0193 - accuracy: 0.9971 - val_loss: 0.0648 - val_accuracy: 0.9787\n",
      "Epoch 275/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0192 - accuracy: 0.9973 - val_loss: 0.0646 - val_accuracy: 0.9791\n",
      "Epoch 276/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0191 - accuracy: 0.9973 - val_loss: 0.0646 - val_accuracy: 0.9785\n",
      "Epoch 277/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0190 - accuracy: 0.9973 - val_loss: 0.0648 - val_accuracy: 0.9787\n",
      "Epoch 278/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0189 - accuracy: 0.9973 - val_loss: 0.0647 - val_accuracy: 0.9784\n",
      "Epoch 279/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0188 - accuracy: 0.9974 - val_loss: 0.0651 - val_accuracy: 0.9790\n",
      "Epoch 280/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0187 - accuracy: 0.9973 - val_loss: 0.0647 - val_accuracy: 0.9791\n",
      "Epoch 281/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0186 - accuracy: 0.9973 - val_loss: 0.0647 - val_accuracy: 0.9789\n",
      "Epoch 282/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0185 - accuracy: 0.9975 - val_loss: 0.0648 - val_accuracy: 0.9787\n",
      "Epoch 283/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0184 - accuracy: 0.9974 - val_loss: 0.0648 - val_accuracy: 0.9785\n",
      "Epoch 284/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0183 - accuracy: 0.9974 - val_loss: 0.0647 - val_accuracy: 0.9790\n",
      "Epoch 285/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0182 - accuracy: 0.9974 - val_loss: 0.0648 - val_accuracy: 0.9790\n",
      "Epoch 286/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0182 - accuracy: 0.9976 - val_loss: 0.0646 - val_accuracy: 0.9790\n",
      "Epoch 287/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0181 - accuracy: 0.9977 - val_loss: 0.0646 - val_accuracy: 0.9791\n",
      "Epoch 288/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0180 - accuracy: 0.9975 - val_loss: 0.0647 - val_accuracy: 0.9787\n",
      "Epoch 289/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0179 - accuracy: 0.9976 - val_loss: 0.0646 - val_accuracy: 0.9789\n",
      "Epoch 290/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0178 - accuracy: 0.9977 - val_loss: 0.0645 - val_accuracy: 0.9790\n",
      "Epoch 291/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0177 - accuracy: 0.9977 - val_loss: 0.0645 - val_accuracy: 0.9788\n",
      "Epoch 292/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0176 - accuracy: 0.9978 - val_loss: 0.0645 - val_accuracy: 0.9790\n",
      "Epoch 293/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0175 - accuracy: 0.9977 - val_loss: 0.0645 - val_accuracy: 0.9788\n",
      "Epoch 294/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0174 - accuracy: 0.9977 - val_loss: 0.0645 - val_accuracy: 0.9793\n",
      "Epoch 295/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0174 - accuracy: 0.9978 - val_loss: 0.0643 - val_accuracy: 0.9792\n",
      "Epoch 296/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0173 - accuracy: 0.9977 - val_loss: 0.0644 - val_accuracy: 0.9789\n",
      "Epoch 297/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0172 - accuracy: 0.9978 - val_loss: 0.0643 - val_accuracy: 0.9791\n",
      "Epoch 298/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0171 - accuracy: 0.9978 - val_loss: 0.0644 - val_accuracy: 0.9788\n",
      "Epoch 299/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0170 - accuracy: 0.9978 - val_loss: 0.0645 - val_accuracy: 0.9796\n",
      "Epoch 300/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0169 - accuracy: 0.9979 - val_loss: 0.0646 - val_accuracy: 0.9789\n",
      "Epoch 301/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0168 - accuracy: 0.9979 - val_loss: 0.0643 - val_accuracy: 0.9792\n",
      "Epoch 302/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0168 - accuracy: 0.9979 - val_loss: 0.0643 - val_accuracy: 0.9791\n",
      "Epoch 303/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0167 - accuracy: 0.9979 - val_loss: 0.0646 - val_accuracy: 0.9794\n",
      "Epoch 304/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0166 - accuracy: 0.9979 - val_loss: 0.0643 - val_accuracy: 0.9790\n",
      "Epoch 305/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0165 - accuracy: 0.9980 - val_loss: 0.0644 - val_accuracy: 0.9793\n",
      "Epoch 306/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0164 - accuracy: 0.9981 - val_loss: 0.0643 - val_accuracy: 0.9793\n",
      "Epoch 307/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0164 - accuracy: 0.9980 - val_loss: 0.0644 - val_accuracy: 0.9790\n",
      "Epoch 308/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0163 - accuracy: 0.9980 - val_loss: 0.0644 - val_accuracy: 0.9791\n",
      "Epoch 309/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0162 - accuracy: 0.9981 - val_loss: 0.0645 - val_accuracy: 0.9792\n",
      "Epoch 310/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0161 - accuracy: 0.9981 - val_loss: 0.0643 - val_accuracy: 0.9793\n",
      "Epoch 311/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0160 - accuracy: 0.9981 - val_loss: 0.0642 - val_accuracy: 0.9796\n",
      "Epoch 312/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0160 - accuracy: 0.9981 - val_loss: 0.0642 - val_accuracy: 0.9792\n",
      "Epoch 313/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0159 - accuracy: 0.9980 - val_loss: 0.0642 - val_accuracy: 0.9790\n",
      "Epoch 314/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0158 - accuracy: 0.9982 - val_loss: 0.0645 - val_accuracy: 0.9794\n",
      "Epoch 315/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0157 - accuracy: 0.9983 - val_loss: 0.0645 - val_accuracy: 0.9790\n",
      "Epoch 316/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0157 - accuracy: 0.9982 - val_loss: 0.0643 - val_accuracy: 0.9797\n",
      "Epoch 317/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0156 - accuracy: 0.9982 - val_loss: 0.0642 - val_accuracy: 0.9790\n",
      "Epoch 318/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0155 - accuracy: 0.9982 - val_loss: 0.0644 - val_accuracy: 0.9792\n",
      "Epoch 319/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0154 - accuracy: 0.9983 - val_loss: 0.0644 - val_accuracy: 0.9794\n",
      "Epoch 320/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0154 - accuracy: 0.9983 - val_loss: 0.0642 - val_accuracy: 0.9795\n",
      "Epoch 321/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0153 - accuracy: 0.9983 - val_loss: 0.0644 - val_accuracy: 0.9792\n",
      "Epoch 322/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0152 - accuracy: 0.9983 - val_loss: 0.0644 - val_accuracy: 0.9798\n",
      "Epoch 323/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0152 - accuracy: 0.9983 - val_loss: 0.0643 - val_accuracy: 0.9797\n",
      "Epoch 324/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0151 - accuracy: 0.9983 - val_loss: 0.0642 - val_accuracy: 0.9796\n",
      "Epoch 325/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0150 - accuracy: 0.9984 - val_loss: 0.0644 - val_accuracy: 0.9793\n",
      "Epoch 326/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0150 - accuracy: 0.9984 - val_loss: 0.0642 - val_accuracy: 0.9793\n",
      "Epoch 327/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0149 - accuracy: 0.9984 - val_loss: 0.0642 - val_accuracy: 0.9796\n",
      "Epoch 328/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0148 - accuracy: 0.9983 - val_loss: 0.0643 - val_accuracy: 0.9795\n",
      "Epoch 329/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0147 - accuracy: 0.9984 - val_loss: 0.0643 - val_accuracy: 0.9795\n",
      "Epoch 330/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0147 - accuracy: 0.9984 - val_loss: 0.0642 - val_accuracy: 0.9795\n",
      "Epoch 331/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0146 - accuracy: 0.9984 - val_loss: 0.0643 - val_accuracy: 0.9796\n",
      "Epoch 332/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0145 - accuracy: 0.9985 - val_loss: 0.0642 - val_accuracy: 0.9794\n",
      "Epoch 333/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0145 - accuracy: 0.9985 - val_loss: 0.0643 - val_accuracy: 0.9794\n",
      "Epoch 334/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0144 - accuracy: 0.9985 - val_loss: 0.0644 - val_accuracy: 0.9795\n",
      "Epoch 335/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0144 - accuracy: 0.9985 - val_loss: 0.0641 - val_accuracy: 0.9794\n",
      "Epoch 336/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0143 - accuracy: 0.9986 - val_loss: 0.0642 - val_accuracy: 0.9798\n",
      "Epoch 337/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0142 - accuracy: 0.9985 - val_loss: 0.0644 - val_accuracy: 0.9795\n",
      "Epoch 338/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0142 - accuracy: 0.9986 - val_loss: 0.0642 - val_accuracy: 0.9797\n",
      "Epoch 339/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0141 - accuracy: 0.9986 - val_loss: 0.0644 - val_accuracy: 0.9796\n",
      "Epoch 340/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0140 - accuracy: 0.9985 - val_loss: 0.0640 - val_accuracy: 0.9797\n",
      "Epoch 341/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0140 - accuracy: 0.9987 - val_loss: 0.0643 - val_accuracy: 0.9798\n",
      "Epoch 342/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0139 - accuracy: 0.9986 - val_loss: 0.0642 - val_accuracy: 0.9797\n",
      "Epoch 343/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0138 - accuracy: 0.9986 - val_loss: 0.0642 - val_accuracy: 0.9799\n",
      "Epoch 344/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0138 - accuracy: 0.9986 - val_loss: 0.0641 - val_accuracy: 0.9797\n",
      "Epoch 345/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0137 - accuracy: 0.9987 - val_loss: 0.0642 - val_accuracy: 0.9798\n",
      "Epoch 346/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0137 - accuracy: 0.9987 - val_loss: 0.0642 - val_accuracy: 0.9797\n",
      "Epoch 347/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0136 - accuracy: 0.9986 - val_loss: 0.0641 - val_accuracy: 0.9798\n",
      "Epoch 348/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0135 - accuracy: 0.9986 - val_loss: 0.0641 - val_accuracy: 0.9798\n",
      "Epoch 349/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0135 - accuracy: 0.9986 - val_loss: 0.0644 - val_accuracy: 0.9798\n",
      "Epoch 350/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0134 - accuracy: 0.9987 - val_loss: 0.0644 - val_accuracy: 0.9797\n",
      "Epoch 351/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0133 - accuracy: 0.9987 - val_loss: 0.0642 - val_accuracy: 0.9798\n",
      "Epoch 352/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0133 - accuracy: 0.9988 - val_loss: 0.0642 - val_accuracy: 0.9795\n",
      "Epoch 353/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0132 - accuracy: 0.9988 - val_loss: 0.0642 - val_accuracy: 0.9798\n",
      "Epoch 354/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0132 - accuracy: 0.9987 - val_loss: 0.0642 - val_accuracy: 0.9798\n",
      "Epoch 355/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0131 - accuracy: 0.9987 - val_loss: 0.0642 - val_accuracy: 0.9798\n",
      "Epoch 356/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0130 - accuracy: 0.9988 - val_loss: 0.0643 - val_accuracy: 0.9800\n",
      "Epoch 357/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0130 - accuracy: 0.9987 - val_loss: 0.0642 - val_accuracy: 0.9801\n",
      "Epoch 358/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0129 - accuracy: 0.9988 - val_loss: 0.0642 - val_accuracy: 0.9797\n",
      "Epoch 359/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0129 - accuracy: 0.9988 - val_loss: 0.0643 - val_accuracy: 0.9796\n",
      "Epoch 360/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0128 - accuracy: 0.9988 - val_loss: 0.0642 - val_accuracy: 0.9798\n",
      "Epoch 361/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0128 - accuracy: 0.9988 - val_loss: 0.0642 - val_accuracy: 0.9801\n",
      "Epoch 362/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0127 - accuracy: 0.9988 - val_loss: 0.0642 - val_accuracy: 0.9798\n",
      "Epoch 363/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0127 - accuracy: 0.9988 - val_loss: 0.0644 - val_accuracy: 0.9799\n",
      "Epoch 364/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0126 - accuracy: 0.9988 - val_loss: 0.0643 - val_accuracy: 0.9797\n",
      "Epoch 365/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0126 - accuracy: 0.9989 - val_loss: 0.0641 - val_accuracy: 0.9794\n",
      "Epoch 366/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0125 - accuracy: 0.9989 - val_loss: 0.0643 - val_accuracy: 0.9797\n",
      "Epoch 367/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0125 - accuracy: 0.9989 - val_loss: 0.0642 - val_accuracy: 0.9800\n",
      "Epoch 368/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0124 - accuracy: 0.9990 - val_loss: 0.0642 - val_accuracy: 0.9796\n",
      "Epoch 369/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0124 - accuracy: 0.9989 - val_loss: 0.0642 - val_accuracy: 0.9798\n",
      "Epoch 370/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0123 - accuracy: 0.9989 - val_loss: 0.0644 - val_accuracy: 0.9800\n",
      "Epoch 371/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0123 - accuracy: 0.9990 - val_loss: 0.0643 - val_accuracy: 0.9798\n",
      "Epoch 372/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0122 - accuracy: 0.9990 - val_loss: 0.0643 - val_accuracy: 0.9799\n",
      "Epoch 373/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0121 - accuracy: 0.9990 - val_loss: 0.0641 - val_accuracy: 0.9799\n",
      "Epoch 374/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0121 - accuracy: 0.9990 - val_loss: 0.0642 - val_accuracy: 0.9796\n",
      "Epoch 375/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0120 - accuracy: 0.9990 - val_loss: 0.0643 - val_accuracy: 0.9800\n",
      "Epoch 376/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0120 - accuracy: 0.9990 - val_loss: 0.0643 - val_accuracy: 0.9800\n",
      "Epoch 377/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0119 - accuracy: 0.9990 - val_loss: 0.0644 - val_accuracy: 0.9800\n",
      "Epoch 378/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0119 - accuracy: 0.9990 - val_loss: 0.0643 - val_accuracy: 0.9800\n",
      "Epoch 379/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0118 - accuracy: 0.9990 - val_loss: 0.0643 - val_accuracy: 0.9799\n",
      "Epoch 380/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0118 - accuracy: 0.9990 - val_loss: 0.0642 - val_accuracy: 0.9798\n",
      "Epoch 381/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0117 - accuracy: 0.9990 - val_loss: 0.0645 - val_accuracy: 0.9800\n",
      "Epoch 382/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0117 - accuracy: 0.9991 - val_loss: 0.0644 - val_accuracy: 0.9800\n",
      "Epoch 383/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0116 - accuracy: 0.9991 - val_loss: 0.0643 - val_accuracy: 0.9801\n",
      "Epoch 384/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0116 - accuracy: 0.9991 - val_loss: 0.0642 - val_accuracy: 0.9800\n",
      "Epoch 385/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0116 - accuracy: 0.9990 - val_loss: 0.0644 - val_accuracy: 0.9800\n",
      "Epoch 386/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0115 - accuracy: 0.9990 - val_loss: 0.0644 - val_accuracy: 0.9800\n",
      "Epoch 387/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0114 - accuracy: 0.9991 - val_loss: 0.0643 - val_accuracy: 0.9799\n",
      "Epoch 388/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0114 - accuracy: 0.9991 - val_loss: 0.0643 - val_accuracy: 0.9800\n",
      "Epoch 389/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0114 - accuracy: 0.9991 - val_loss: 0.0642 - val_accuracy: 0.9799\n",
      "Epoch 390/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0113 - accuracy: 0.9991 - val_loss: 0.0643 - val_accuracy: 0.9797\n",
      "Epoch 391/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0113 - accuracy: 0.9991 - val_loss: 0.0644 - val_accuracy: 0.9798\n",
      "Epoch 392/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0112 - accuracy: 0.9992 - val_loss: 0.0643 - val_accuracy: 0.9801\n",
      "Epoch 393/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0112 - accuracy: 0.9991 - val_loss: 0.0643 - val_accuracy: 0.9797\n",
      "Epoch 394/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0111 - accuracy: 0.9992 - val_loss: 0.0642 - val_accuracy: 0.9799\n",
      "Epoch 395/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0111 - accuracy: 0.9991 - val_loss: 0.0643 - val_accuracy: 0.9799\n",
      "Epoch 396/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0110 - accuracy: 0.9992 - val_loss: 0.0644 - val_accuracy: 0.9798\n",
      "Epoch 397/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0110 - accuracy: 0.9992 - val_loss: 0.0644 - val_accuracy: 0.9797\n",
      "Epoch 398/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0110 - accuracy: 0.9992 - val_loss: 0.0642 - val_accuracy: 0.9797\n",
      "Epoch 399/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0109 - accuracy: 0.9992 - val_loss: 0.0643 - val_accuracy: 0.9798\n",
      "Epoch 400/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0109 - accuracy: 0.9992 - val_loss: 0.0644 - val_accuracy: 0.9800\n",
      "Epoch 401/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0108 - accuracy: 0.9992 - val_loss: 0.0643 - val_accuracy: 0.9797\n",
      "Epoch 402/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0108 - accuracy: 0.9992 - val_loss: 0.0646 - val_accuracy: 0.9798\n",
      "Epoch 403/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0107 - accuracy: 0.9992 - val_loss: 0.0645 - val_accuracy: 0.9797\n",
      "Epoch 404/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0107 - accuracy: 0.9992 - val_loss: 0.0644 - val_accuracy: 0.9800\n",
      "Epoch 405/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0107 - accuracy: 0.9993 - val_loss: 0.0643 - val_accuracy: 0.9796\n",
      "Epoch 406/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0106 - accuracy: 0.9992 - val_loss: 0.0642 - val_accuracy: 0.9798\n",
      "Epoch 407/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0106 - accuracy: 0.9993 - val_loss: 0.0645 - val_accuracy: 0.9799\n",
      "Epoch 408/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0105 - accuracy: 0.9993 - val_loss: 0.0646 - val_accuracy: 0.9799\n",
      "Epoch 409/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0105 - accuracy: 0.9992 - val_loss: 0.0646 - val_accuracy: 0.9798\n",
      "Epoch 410/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0104 - accuracy: 0.9993 - val_loss: 0.0646 - val_accuracy: 0.9800\n",
      "Epoch 411/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0104 - accuracy: 0.9993 - val_loss: 0.0645 - val_accuracy: 0.9801\n",
      "Epoch 412/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0104 - accuracy: 0.9993 - val_loss: 0.0644 - val_accuracy: 0.9801\n",
      "Epoch 413/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0103 - accuracy: 0.9993 - val_loss: 0.0644 - val_accuracy: 0.9800\n",
      "Epoch 414/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0103 - accuracy: 0.9993 - val_loss: 0.0643 - val_accuracy: 0.9801\n",
      "Epoch 415/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0102 - accuracy: 0.9992 - val_loss: 0.0643 - val_accuracy: 0.9799\n",
      "Epoch 416/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0102 - accuracy: 0.9993 - val_loss: 0.0645 - val_accuracy: 0.9797\n",
      "Epoch 417/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0102 - accuracy: 0.9993 - val_loss: 0.0645 - val_accuracy: 0.9799\n",
      "Epoch 418/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0101 - accuracy: 0.9994 - val_loss: 0.0643 - val_accuracy: 0.9795\n",
      "Epoch 419/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0101 - accuracy: 0.9994 - val_loss: 0.0646 - val_accuracy: 0.9801\n",
      "Epoch 420/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0101 - accuracy: 0.9993 - val_loss: 0.0646 - val_accuracy: 0.9798\n",
      "Epoch 421/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0100 - accuracy: 0.9994 - val_loss: 0.0645 - val_accuracy: 0.9800\n",
      "Epoch 422/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0100 - accuracy: 0.9994 - val_loss: 0.0646 - val_accuracy: 0.9801\n",
      "Epoch 423/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0099 - accuracy: 0.9994 - val_loss: 0.0647 - val_accuracy: 0.9797\n",
      "Epoch 424/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0099 - accuracy: 0.9993 - val_loss: 0.0646 - val_accuracy: 0.9800\n",
      "Epoch 425/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0099 - accuracy: 0.9993 - val_loss: 0.0644 - val_accuracy: 0.9800\n",
      "Epoch 426/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0098 - accuracy: 0.9994 - val_loss: 0.0648 - val_accuracy: 0.9801\n",
      "Epoch 427/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0098 - accuracy: 0.9993 - val_loss: 0.0645 - val_accuracy: 0.9799\n",
      "Epoch 428/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0098 - accuracy: 0.9994 - val_loss: 0.0645 - val_accuracy: 0.9799\n",
      "Epoch 429/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0097 - accuracy: 0.9993 - val_loss: 0.0647 - val_accuracy: 0.9799\n",
      "Epoch 430/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0097 - accuracy: 0.9994 - val_loss: 0.0647 - val_accuracy: 0.9799\n",
      "Epoch 431/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0096 - accuracy: 0.9994 - val_loss: 0.0647 - val_accuracy: 0.9801\n",
      "Epoch 432/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0096 - accuracy: 0.9994 - val_loss: 0.0647 - val_accuracy: 0.9801\n",
      "Epoch 433/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0096 - accuracy: 0.9994 - val_loss: 0.0649 - val_accuracy: 0.9802\n",
      "Epoch 434/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0095 - accuracy: 0.9994 - val_loss: 0.0646 - val_accuracy: 0.9801\n",
      "Epoch 435/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0095 - accuracy: 0.9994 - val_loss: 0.0647 - val_accuracy: 0.9802\n",
      "Epoch 436/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0095 - accuracy: 0.9994 - val_loss: 0.0647 - val_accuracy: 0.9799\n",
      "Epoch 437/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0094 - accuracy: 0.9994 - val_loss: 0.0646 - val_accuracy: 0.9800\n",
      "Epoch 438/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0094 - accuracy: 0.9994 - val_loss: 0.0646 - val_accuracy: 0.9800\n",
      "Epoch 439/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0094 - accuracy: 0.9994 - val_loss: 0.0646 - val_accuracy: 0.9801\n",
      "Epoch 440/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0093 - accuracy: 0.9994 - val_loss: 0.0647 - val_accuracy: 0.9799\n",
      "Epoch 441/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0093 - accuracy: 0.9994 - val_loss: 0.0647 - val_accuracy: 0.9800\n",
      "Epoch 442/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0093 - accuracy: 0.9994 - val_loss: 0.0646 - val_accuracy: 0.9799\n",
      "Epoch 443/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0092 - accuracy: 0.9994 - val_loss: 0.0646 - val_accuracy: 0.9801\n",
      "Epoch 444/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0092 - accuracy: 0.9994 - val_loss: 0.0646 - val_accuracy: 0.9802\n",
      "Epoch 445/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0092 - accuracy: 0.9994 - val_loss: 0.0647 - val_accuracy: 0.9800\n",
      "Epoch 446/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0091 - accuracy: 0.9994 - val_loss: 0.0648 - val_accuracy: 0.9798\n",
      "Epoch 447/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0091 - accuracy: 0.9994 - val_loss: 0.0649 - val_accuracy: 0.9801\n",
      "Epoch 448/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0091 - accuracy: 0.9994 - val_loss: 0.0646 - val_accuracy: 0.9802\n",
      "Epoch 449/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0090 - accuracy: 0.9994 - val_loss: 0.0648 - val_accuracy: 0.9798\n",
      "Epoch 450/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0090 - accuracy: 0.9994 - val_loss: 0.0649 - val_accuracy: 0.9800\n",
      "Epoch 451/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0090 - accuracy: 0.9995 - val_loss: 0.0649 - val_accuracy: 0.9800\n",
      "Epoch 452/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0089 - accuracy: 0.9994 - val_loss: 0.0649 - val_accuracy: 0.9799\n",
      "Epoch 453/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0089 - accuracy: 0.9995 - val_loss: 0.0649 - val_accuracy: 0.9799\n",
      "Epoch 454/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0089 - accuracy: 0.9995 - val_loss: 0.0648 - val_accuracy: 0.9801\n",
      "Epoch 455/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0088 - accuracy: 0.9995 - val_loss: 0.0649 - val_accuracy: 0.9800\n",
      "Epoch 456/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0088 - accuracy: 0.9995 - val_loss: 0.0648 - val_accuracy: 0.9799\n",
      "Epoch 457/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0088 - accuracy: 0.9995 - val_loss: 0.0650 - val_accuracy: 0.9800\n",
      "Epoch 458/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0087 - accuracy: 0.9995 - val_loss: 0.0650 - val_accuracy: 0.9801\n",
      "Epoch 459/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0087 - accuracy: 0.9995 - val_loss: 0.0647 - val_accuracy: 0.9801\n",
      "Epoch 460/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0087 - accuracy: 0.9995 - val_loss: 0.0651 - val_accuracy: 0.9801\n",
      "Epoch 461/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0086 - accuracy: 0.9995 - val_loss: 0.0649 - val_accuracy: 0.9801\n",
      "Epoch 462/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0086 - accuracy: 0.9995 - val_loss: 0.0649 - val_accuracy: 0.9799\n",
      "Epoch 463/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0086 - accuracy: 0.9996 - val_loss: 0.0649 - val_accuracy: 0.9801\n",
      "Epoch 464/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0085 - accuracy: 0.9995 - val_loss: 0.0648 - val_accuracy: 0.9801\n",
      "Epoch 465/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0085 - accuracy: 0.9995 - val_loss: 0.0649 - val_accuracy: 0.9800\n",
      "Epoch 466/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0085 - accuracy: 0.9995 - val_loss: 0.0649 - val_accuracy: 0.9801\n",
      "Epoch 467/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0084 - accuracy: 0.9995 - val_loss: 0.0649 - val_accuracy: 0.9802\n",
      "Epoch 468/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0084 - accuracy: 0.9996 - val_loss: 0.0650 - val_accuracy: 0.9801\n",
      "Epoch 469/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0084 - accuracy: 0.9996 - val_loss: 0.0650 - val_accuracy: 0.9803\n",
      "Epoch 470/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0084 - accuracy: 0.9996 - val_loss: 0.0649 - val_accuracy: 0.9800\n",
      "Epoch 471/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0083 - accuracy: 0.9996 - val_loss: 0.0650 - val_accuracy: 0.9800\n",
      "Epoch 472/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0083 - accuracy: 0.9996 - val_loss: 0.0650 - val_accuracy: 0.9800\n",
      "Epoch 473/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0083 - accuracy: 0.9995 - val_loss: 0.0650 - val_accuracy: 0.9799\n",
      "Epoch 474/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0082 - accuracy: 0.9995 - val_loss: 0.0650 - val_accuracy: 0.9801\n",
      "Epoch 475/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0082 - accuracy: 0.9996 - val_loss: 0.0649 - val_accuracy: 0.9801\n",
      "Epoch 476/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0082 - accuracy: 0.9996 - val_loss: 0.0650 - val_accuracy: 0.9800\n",
      "Epoch 477/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0082 - accuracy: 0.9996 - val_loss: 0.0649 - val_accuracy: 0.9804\n",
      "Epoch 478/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0081 - accuracy: 0.9996 - val_loss: 0.0650 - val_accuracy: 0.9800\n",
      "Epoch 479/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0081 - accuracy: 0.9996 - val_loss: 0.0649 - val_accuracy: 0.9799\n",
      "Epoch 480/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0081 - accuracy: 0.9996 - val_loss: 0.0650 - val_accuracy: 0.9801\n",
      "Epoch 481/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0081 - accuracy: 0.9996 - val_loss: 0.0652 - val_accuracy: 0.9802\n",
      "Epoch 482/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0080 - accuracy: 0.9996 - val_loss: 0.0651 - val_accuracy: 0.9801\n",
      "Epoch 483/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0080 - accuracy: 0.9996 - val_loss: 0.0650 - val_accuracy: 0.9802\n",
      "Epoch 484/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0080 - accuracy: 0.9996 - val_loss: 0.0651 - val_accuracy: 0.9801\n",
      "Epoch 485/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0079 - accuracy: 0.9996 - val_loss: 0.0650 - val_accuracy: 0.9802\n",
      "Epoch 486/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0079 - accuracy: 0.9996 - val_loss: 0.0651 - val_accuracy: 0.9800\n",
      "Epoch 487/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0079 - accuracy: 0.9996 - val_loss: 0.0652 - val_accuracy: 0.9803\n",
      "Epoch 488/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0079 - accuracy: 0.9996 - val_loss: 0.0651 - val_accuracy: 0.9802\n",
      "Epoch 489/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0078 - accuracy: 0.9996 - val_loss: 0.0652 - val_accuracy: 0.9802\n",
      "Epoch 490/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0078 - accuracy: 0.9996 - val_loss: 0.0651 - val_accuracy: 0.9800\n",
      "Epoch 491/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0078 - accuracy: 0.9996 - val_loss: 0.0651 - val_accuracy: 0.9803\n",
      "Epoch 492/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0078 - accuracy: 0.9996 - val_loss: 0.0652 - val_accuracy: 0.9801\n",
      "Epoch 493/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0077 - accuracy: 0.9996 - val_loss: 0.0652 - val_accuracy: 0.9799\n",
      "Epoch 494/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0077 - accuracy: 0.9996 - val_loss: 0.0652 - val_accuracy: 0.9800\n",
      "Epoch 495/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0077 - accuracy: 0.9996 - val_loss: 0.0652 - val_accuracy: 0.9800\n",
      "Epoch 496/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0077 - accuracy: 0.9996 - val_loss: 0.0651 - val_accuracy: 0.9801\n",
      "Epoch 497/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0076 - accuracy: 0.9996 - val_loss: 0.0652 - val_accuracy: 0.9800\n",
      "Epoch 498/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0076 - accuracy: 0.9996 - val_loss: 0.0651 - val_accuracy: 0.9801\n",
      "Epoch 499/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0076 - accuracy: 0.9996 - val_loss: 0.0651 - val_accuracy: 0.9801\n",
      "Epoch 500/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0076 - accuracy: 0.9996 - val_loss: 0.0652 - val_accuracy: 0.9800\n",
      "Epoch 501/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0075 - accuracy: 0.9996 - val_loss: 0.0653 - val_accuracy: 0.9801\n",
      "Epoch 502/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0075 - accuracy: 0.9996 - val_loss: 0.0653 - val_accuracy: 0.9802\n",
      "Epoch 503/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0075 - accuracy: 0.9996 - val_loss: 0.0653 - val_accuracy: 0.9802\n",
      "Epoch 504/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0074 - accuracy: 0.9996 - val_loss: 0.0652 - val_accuracy: 0.9804\n",
      "Epoch 505/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0074 - accuracy: 0.9997 - val_loss: 0.0651 - val_accuracy: 0.9805\n",
      "Epoch 506/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0074 - accuracy: 0.9996 - val_loss: 0.0653 - val_accuracy: 0.9804\n",
      "Epoch 507/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0074 - accuracy: 0.9996 - val_loss: 0.0652 - val_accuracy: 0.9806\n",
      "Epoch 508/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0073 - accuracy: 0.9997 - val_loss: 0.0654 - val_accuracy: 0.9805\n",
      "Epoch 509/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0073 - accuracy: 0.9996 - val_loss: 0.0653 - val_accuracy: 0.9802\n",
      "Epoch 510/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0073 - accuracy: 0.9997 - val_loss: 0.0653 - val_accuracy: 0.9804\n",
      "Epoch 511/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0073 - accuracy: 0.9997 - val_loss: 0.0653 - val_accuracy: 0.9801\n",
      "Epoch 512/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0073 - accuracy: 0.9997 - val_loss: 0.0654 - val_accuracy: 0.9803\n",
      "Epoch 513/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0072 - accuracy: 0.9997 - val_loss: 0.0653 - val_accuracy: 0.9802\n",
      "Epoch 514/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0072 - accuracy: 0.9997 - val_loss: 0.0654 - val_accuracy: 0.9801\n",
      "Epoch 515/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0072 - accuracy: 0.9997 - val_loss: 0.0653 - val_accuracy: 0.9802\n",
      "Epoch 516/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0072 - accuracy: 0.9996 - val_loss: 0.0653 - val_accuracy: 0.9800\n",
      "Epoch 517/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0071 - accuracy: 0.9997 - val_loss: 0.0654 - val_accuracy: 0.9801\n",
      "Epoch 518/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0071 - accuracy: 0.9997 - val_loss: 0.0653 - val_accuracy: 0.9803\n",
      "Epoch 519/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0071 - accuracy: 0.9997 - val_loss: 0.0655 - val_accuracy: 0.9802\n",
      "Epoch 520/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0071 - accuracy: 0.9997 - val_loss: 0.0654 - val_accuracy: 0.9801\n",
      "Epoch 521/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0071 - accuracy: 0.9997 - val_loss: 0.0654 - val_accuracy: 0.9802\n",
      "Epoch 522/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0070 - accuracy: 0.9997 - val_loss: 0.0655 - val_accuracy: 0.9801\n",
      "Epoch 523/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0070 - accuracy: 0.9997 - val_loss: 0.0655 - val_accuracy: 0.9805\n",
      "Epoch 524/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0070 - accuracy: 0.9997 - val_loss: 0.0655 - val_accuracy: 0.9802\n",
      "Epoch 525/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0070 - accuracy: 0.9996 - val_loss: 0.0656 - val_accuracy: 0.9802\n",
      "Epoch 526/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0069 - accuracy: 0.9997 - val_loss: 0.0656 - val_accuracy: 0.9803\n",
      "Epoch 527/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0069 - accuracy: 0.9997 - val_loss: 0.0655 - val_accuracy: 0.9804\n",
      "Epoch 528/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0069 - accuracy: 0.9997 - val_loss: 0.0656 - val_accuracy: 0.9801\n",
      "Epoch 529/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0069 - accuracy: 0.9997 - val_loss: 0.0656 - val_accuracy: 0.9801\n",
      "Epoch 530/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0069 - accuracy: 0.9997 - val_loss: 0.0655 - val_accuracy: 0.9803\n",
      "Epoch 531/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0068 - accuracy: 0.9997 - val_loss: 0.0654 - val_accuracy: 0.9804\n",
      "Epoch 532/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0068 - accuracy: 0.9997 - val_loss: 0.0656 - val_accuracy: 0.9803\n",
      "Epoch 533/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0068 - accuracy: 0.9997 - val_loss: 0.0657 - val_accuracy: 0.9807\n",
      "Epoch 534/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0068 - accuracy: 0.9997 - val_loss: 0.0656 - val_accuracy: 0.9801\n",
      "Epoch 535/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0067 - accuracy: 0.9997 - val_loss: 0.0656 - val_accuracy: 0.9804\n",
      "Epoch 536/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0067 - accuracy: 0.9997 - val_loss: 0.0657 - val_accuracy: 0.9801\n",
      "Epoch 537/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0067 - accuracy: 0.9997 - val_loss: 0.0655 - val_accuracy: 0.9805\n",
      "Epoch 538/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0067 - accuracy: 0.9997 - val_loss: 0.0657 - val_accuracy: 0.9802\n",
      "Epoch 539/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0067 - accuracy: 0.9997 - val_loss: 0.0656 - val_accuracy: 0.9803\n",
      "Epoch 540/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0066 - accuracy: 0.9997 - val_loss: 0.0656 - val_accuracy: 0.9803\n",
      "Epoch 541/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0066 - accuracy: 0.9997 - val_loss: 0.0656 - val_accuracy: 0.9801\n",
      "Epoch 542/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0066 - accuracy: 0.9997 - val_loss: 0.0658 - val_accuracy: 0.9803\n",
      "Epoch 543/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0066 - accuracy: 0.9997 - val_loss: 0.0657 - val_accuracy: 0.9804\n",
      "Epoch 544/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0065 - accuracy: 0.9997 - val_loss: 0.0658 - val_accuracy: 0.9801\n",
      "Epoch 545/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0065 - accuracy: 0.9997 - val_loss: 0.0657 - val_accuracy: 0.9803\n",
      "Epoch 546/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0065 - accuracy: 0.9997 - val_loss: 0.0657 - val_accuracy: 0.9803\n",
      "Epoch 547/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0065 - accuracy: 0.9997 - val_loss: 0.0657 - val_accuracy: 0.9804\n",
      "Epoch 548/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0065 - accuracy: 0.9997 - val_loss: 0.0657 - val_accuracy: 0.9803\n",
      "Epoch 549/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0064 - accuracy: 0.9997 - val_loss: 0.0657 - val_accuracy: 0.9806\n",
      "Epoch 550/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0064 - accuracy: 0.9997 - val_loss: 0.0657 - val_accuracy: 0.9802\n",
      "Epoch 551/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0064 - accuracy: 0.9997 - val_loss: 0.0656 - val_accuracy: 0.9805\n",
      "Epoch 552/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0064 - accuracy: 0.9997 - val_loss: 0.0657 - val_accuracy: 0.9805\n",
      "Epoch 553/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0064 - accuracy: 0.9997 - val_loss: 0.0657 - val_accuracy: 0.9802\n",
      "Epoch 554/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0064 - accuracy: 0.9997 - val_loss: 0.0657 - val_accuracy: 0.9805\n",
      "Epoch 555/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0063 - accuracy: 0.9997 - val_loss: 0.0658 - val_accuracy: 0.9805\n",
      "Epoch 556/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0063 - accuracy: 0.9997 - val_loss: 0.0658 - val_accuracy: 0.9803\n",
      "Epoch 557/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0063 - accuracy: 0.9997 - val_loss: 0.0658 - val_accuracy: 0.9804\n",
      "Epoch 558/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0063 - accuracy: 0.9997 - val_loss: 0.0658 - val_accuracy: 0.9804\n",
      "Epoch 559/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0063 - accuracy: 0.9997 - val_loss: 0.0658 - val_accuracy: 0.9803\n",
      "Epoch 560/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0062 - accuracy: 0.9997 - val_loss: 0.0658 - val_accuracy: 0.9804\n",
      "Epoch 561/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0062 - accuracy: 0.9997 - val_loss: 0.0660 - val_accuracy: 0.9805\n",
      "Epoch 562/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0062 - accuracy: 0.9998 - val_loss: 0.0659 - val_accuracy: 0.9801\n",
      "Epoch 563/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0062 - accuracy: 0.9997 - val_loss: 0.0659 - val_accuracy: 0.9804\n",
      "Epoch 564/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0062 - accuracy: 0.9998 - val_loss: 0.0658 - val_accuracy: 0.9803\n",
      "Epoch 565/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0061 - accuracy: 0.9997 - val_loss: 0.0659 - val_accuracy: 0.9803\n",
      "Epoch 566/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0061 - accuracy: 0.9998 - val_loss: 0.0661 - val_accuracy: 0.9803\n",
      "Epoch 567/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0061 - accuracy: 0.9998 - val_loss: 0.0659 - val_accuracy: 0.9804\n",
      "Epoch 568/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0061 - accuracy: 0.9998 - val_loss: 0.0660 - val_accuracy: 0.9802\n",
      "Epoch 569/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0061 - accuracy: 0.9998 - val_loss: 0.0660 - val_accuracy: 0.9806\n",
      "Epoch 570/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0061 - accuracy: 0.9998 - val_loss: 0.0660 - val_accuracy: 0.9804\n",
      "Epoch 571/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0060 - accuracy: 0.9998 - val_loss: 0.0660 - val_accuracy: 0.9803\n",
      "Epoch 572/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0060 - accuracy: 0.9998 - val_loss: 0.0660 - val_accuracy: 0.9802\n",
      "Epoch 573/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0060 - accuracy: 0.9998 - val_loss: 0.0660 - val_accuracy: 0.9804\n",
      "Epoch 574/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0060 - accuracy: 0.9998 - val_loss: 0.0661 - val_accuracy: 0.9805\n",
      "Epoch 575/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0060 - accuracy: 0.9998 - val_loss: 0.0660 - val_accuracy: 0.9803\n",
      "Epoch 576/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0060 - accuracy: 0.9998 - val_loss: 0.0660 - val_accuracy: 0.9804\n",
      "Epoch 577/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0059 - accuracy: 0.9998 - val_loss: 0.0660 - val_accuracy: 0.9803\n",
      "Epoch 578/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0059 - accuracy: 0.9998 - val_loss: 0.0661 - val_accuracy: 0.9805\n",
      "Epoch 579/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0059 - accuracy: 0.9998 - val_loss: 0.0661 - val_accuracy: 0.9806\n",
      "Epoch 580/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0059 - accuracy: 0.9998 - val_loss: 0.0661 - val_accuracy: 0.9803\n",
      "Epoch 581/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0059 - accuracy: 0.9998 - val_loss: 0.0660 - val_accuracy: 0.9803\n",
      "Epoch 582/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0058 - accuracy: 0.9998 - val_loss: 0.0662 - val_accuracy: 0.9803\n",
      "Epoch 583/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0058 - accuracy: 0.9998 - val_loss: 0.0662 - val_accuracy: 0.9804\n",
      "Epoch 584/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0058 - accuracy: 0.9998 - val_loss: 0.0661 - val_accuracy: 0.9804\n",
      "Epoch 585/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0058 - accuracy: 0.9998 - val_loss: 0.0663 - val_accuracy: 0.9803\n",
      "Epoch 586/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0058 - accuracy: 0.9998 - val_loss: 0.0662 - val_accuracy: 0.9805\n",
      "Epoch 587/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0058 - accuracy: 0.9998 - val_loss: 0.0662 - val_accuracy: 0.9803\n",
      "Epoch 588/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0057 - accuracy: 0.9998 - val_loss: 0.0662 - val_accuracy: 0.9806\n",
      "Epoch 589/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0057 - accuracy: 0.9998 - val_loss: 0.0662 - val_accuracy: 0.9805\n",
      "Epoch 590/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0057 - accuracy: 0.9998 - val_loss: 0.0664 - val_accuracy: 0.9802\n",
      "Epoch 591/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0057 - accuracy: 0.9998 - val_loss: 0.0662 - val_accuracy: 0.9806\n",
      "Epoch 592/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0057 - accuracy: 0.9998 - val_loss: 0.0662 - val_accuracy: 0.9803\n",
      "Epoch 593/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0057 - accuracy: 0.9998 - val_loss: 0.0663 - val_accuracy: 0.9803\n",
      "Epoch 594/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0056 - accuracy: 0.9998 - val_loss: 0.0663 - val_accuracy: 0.9806\n",
      "Epoch 595/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0056 - accuracy: 0.9998 - val_loss: 0.0663 - val_accuracy: 0.9805\n",
      "Epoch 596/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0056 - accuracy: 0.9998 - val_loss: 0.0663 - val_accuracy: 0.9807\n",
      "Epoch 597/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0056 - accuracy: 0.9998 - val_loss: 0.0663 - val_accuracy: 0.9804\n",
      "Epoch 598/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0056 - accuracy: 0.9998 - val_loss: 0.0663 - val_accuracy: 0.9803\n",
      "Epoch 599/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0056 - accuracy: 0.9998 - val_loss: 0.0663 - val_accuracy: 0.9804\n",
      "Epoch 600/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0055 - accuracy: 0.9998 - val_loss: 0.0664 - val_accuracy: 0.9804\n",
      "Epoch 601/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0055 - accuracy: 0.9998 - val_loss: 0.0663 - val_accuracy: 0.9805\n",
      "Epoch 602/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0055 - accuracy: 0.9998 - val_loss: 0.0664 - val_accuracy: 0.9805\n",
      "Epoch 603/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0055 - accuracy: 0.9998 - val_loss: 0.0664 - val_accuracy: 0.9804\n",
      "Epoch 604/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0055 - accuracy: 0.9998 - val_loss: 0.0665 - val_accuracy: 0.9805\n",
      "Epoch 605/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0055 - accuracy: 0.9998 - val_loss: 0.0663 - val_accuracy: 0.9806\n",
      "Epoch 606/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0055 - accuracy: 0.9998 - val_loss: 0.0665 - val_accuracy: 0.9805\n",
      "Epoch 607/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 0.0664 - val_accuracy: 0.9804\n",
      "Epoch 608/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 0.0664 - val_accuracy: 0.9804\n",
      "Epoch 609/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 0.0664 - val_accuracy: 0.9807\n",
      "Epoch 610/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 0.0665 - val_accuracy: 0.9806\n",
      "Epoch 611/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 0.0664 - val_accuracy: 0.9803\n",
      "Epoch 612/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 0.0666 - val_accuracy: 0.9805\n",
      "Epoch 613/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 0.0665 - val_accuracy: 0.9805\n",
      "Epoch 614/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0053 - accuracy: 0.9998 - val_loss: 0.0664 - val_accuracy: 0.9805\n",
      "Epoch 615/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0053 - accuracy: 0.9998 - val_loss: 0.0666 - val_accuracy: 0.9804\n",
      "Epoch 616/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0053 - accuracy: 0.9998 - val_loss: 0.0666 - val_accuracy: 0.9805\n",
      "Epoch 617/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0053 - accuracy: 0.9998 - val_loss: 0.0665 - val_accuracy: 0.9806\n",
      "Epoch 618/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0053 - accuracy: 0.9998 - val_loss: 0.0665 - val_accuracy: 0.9805\n",
      "Epoch 619/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0053 - accuracy: 0.9998 - val_loss: 0.0665 - val_accuracy: 0.9806\n",
      "Epoch 620/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0052 - accuracy: 0.9999 - val_loss: 0.0666 - val_accuracy: 0.9806\n",
      "Epoch 621/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0052 - accuracy: 0.9998 - val_loss: 0.0666 - val_accuracy: 0.9805\n",
      "Epoch 622/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0052 - accuracy: 0.9998 - val_loss: 0.0665 - val_accuracy: 0.9804\n",
      "Epoch 623/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0052 - accuracy: 0.9998 - val_loss: 0.0666 - val_accuracy: 0.9804\n",
      "Epoch 624/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0052 - accuracy: 0.9998 - val_loss: 0.0667 - val_accuracy: 0.9806\n",
      "Epoch 625/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0052 - accuracy: 0.9999 - val_loss: 0.0667 - val_accuracy: 0.9805\n",
      "Epoch 626/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0052 - accuracy: 0.9999 - val_loss: 0.0667 - val_accuracy: 0.9804\n",
      "Epoch 627/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0052 - accuracy: 0.9998 - val_loss: 0.0667 - val_accuracy: 0.9805\n",
      "Epoch 628/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0051 - accuracy: 0.9998 - val_loss: 0.0667 - val_accuracy: 0.9806\n",
      "Epoch 629/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0051 - accuracy: 0.9999 - val_loss: 0.0668 - val_accuracy: 0.9805\n",
      "Epoch 630/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0051 - accuracy: 0.9999 - val_loss: 0.0666 - val_accuracy: 0.9804\n",
      "Epoch 631/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0051 - accuracy: 0.9999 - val_loss: 0.0667 - val_accuracy: 0.9804\n",
      "Epoch 632/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0051 - accuracy: 0.9999 - val_loss: 0.0667 - val_accuracy: 0.9807\n",
      "Epoch 633/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0051 - accuracy: 0.9999 - val_loss: 0.0668 - val_accuracy: 0.9805\n",
      "Epoch 634/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0051 - accuracy: 0.9999 - val_loss: 0.0667 - val_accuracy: 0.9804\n",
      "Epoch 635/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0050 - accuracy: 0.9999 - val_loss: 0.0668 - val_accuracy: 0.9804\n",
      "Epoch 636/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0050 - accuracy: 0.9999 - val_loss: 0.0669 - val_accuracy: 0.9802\n",
      "Epoch 637/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0050 - accuracy: 0.9999 - val_loss: 0.0667 - val_accuracy: 0.9804\n",
      "Epoch 638/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0050 - accuracy: 0.9999 - val_loss: 0.0668 - val_accuracy: 0.9804\n",
      "Epoch 639/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0050 - accuracy: 0.9999 - val_loss: 0.0669 - val_accuracy: 0.9803\n",
      "Epoch 640/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0050 - accuracy: 0.9999 - val_loss: 0.0669 - val_accuracy: 0.9805\n",
      "Epoch 641/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0050 - accuracy: 0.9999 - val_loss: 0.0668 - val_accuracy: 0.9804\n",
      "Epoch 642/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0049 - accuracy: 0.9999 - val_loss: 0.0667 - val_accuracy: 0.9804\n",
      "Epoch 643/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0049 - accuracy: 0.9999 - val_loss: 0.0668 - val_accuracy: 0.9804\n",
      "Epoch 644/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0049 - accuracy: 0.9999 - val_loss: 0.0668 - val_accuracy: 0.9804\n",
      "Epoch 645/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0049 - accuracy: 0.9999 - val_loss: 0.0668 - val_accuracy: 0.9805\n",
      "Epoch 646/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0049 - accuracy: 0.9999 - val_loss: 0.0668 - val_accuracy: 0.9805\n",
      "Epoch 647/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0049 - accuracy: 0.9999 - val_loss: 0.0668 - val_accuracy: 0.9804\n",
      "Epoch 648/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0049 - accuracy: 0.9999 - val_loss: 0.0669 - val_accuracy: 0.9804\n",
      "Epoch 649/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0049 - accuracy: 0.9999 - val_loss: 0.0670 - val_accuracy: 0.9806\n",
      "Epoch 650/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0048 - accuracy: 0.9999 - val_loss: 0.0670 - val_accuracy: 0.9804\n",
      "Epoch 651/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0048 - accuracy: 0.9999 - val_loss: 0.0670 - val_accuracy: 0.9804\n",
      "Epoch 652/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0048 - accuracy: 0.9999 - val_loss: 0.0670 - val_accuracy: 0.9805\n",
      "Epoch 653/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0048 - accuracy: 0.9999 - val_loss: 0.0670 - val_accuracy: 0.9804\n",
      "Epoch 654/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0048 - accuracy: 0.9999 - val_loss: 0.0670 - val_accuracy: 0.9805\n",
      "Epoch 655/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0048 - accuracy: 0.9999 - val_loss: 0.0670 - val_accuracy: 0.9804\n",
      "Epoch 656/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0048 - accuracy: 0.9999 - val_loss: 0.0670 - val_accuracy: 0.9805\n",
      "Epoch 657/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0048 - accuracy: 0.9999 - val_loss: 0.0670 - val_accuracy: 0.9805\n",
      "Epoch 658/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0047 - accuracy: 0.9999 - val_loss: 0.0672 - val_accuracy: 0.9805\n",
      "Epoch 659/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0047 - accuracy: 0.9999 - val_loss: 0.0670 - val_accuracy: 0.9805\n",
      "Epoch 660/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0047 - accuracy: 0.9999 - val_loss: 0.0671 - val_accuracy: 0.9805\n",
      "Epoch 661/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0047 - accuracy: 0.9999 - val_loss: 0.0671 - val_accuracy: 0.9805\n",
      "Epoch 662/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0047 - accuracy: 0.9999 - val_loss: 0.0670 - val_accuracy: 0.9805\n",
      "Epoch 663/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0047 - accuracy: 0.9999 - val_loss: 0.0672 - val_accuracy: 0.9804\n",
      "Epoch 664/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0047 - accuracy: 0.9999 - val_loss: 0.0671 - val_accuracy: 0.9808\n",
      "Epoch 665/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0047 - accuracy: 0.9999 - val_loss: 0.0670 - val_accuracy: 0.9805\n",
      "Epoch 666/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0046 - accuracy: 0.9999 - val_loss: 0.0671 - val_accuracy: 0.9806\n",
      "Epoch 667/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0046 - accuracy: 0.9999 - val_loss: 0.0671 - val_accuracy: 0.9802\n",
      "Epoch 668/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0046 - accuracy: 0.9999 - val_loss: 0.0672 - val_accuracy: 0.9803\n",
      "Epoch 669/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0046 - accuracy: 0.9999 - val_loss: 0.0673 - val_accuracy: 0.9803\n",
      "Epoch 670/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0046 - accuracy: 0.9999 - val_loss: 0.0671 - val_accuracy: 0.9802\n",
      "Epoch 671/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0046 - accuracy: 0.9999 - val_loss: 0.0672 - val_accuracy: 0.9805\n",
      "Epoch 672/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0046 - accuracy: 0.9999 - val_loss: 0.0672 - val_accuracy: 0.9805\n",
      "Epoch 673/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0046 - accuracy: 0.9999 - val_loss: 0.0672 - val_accuracy: 0.9805\n",
      "Epoch 674/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0046 - accuracy: 0.9999 - val_loss: 0.0672 - val_accuracy: 0.9808\n",
      "Epoch 675/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0045 - accuracy: 0.9999 - val_loss: 0.0671 - val_accuracy: 0.9804\n",
      "Epoch 676/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0045 - accuracy: 0.9999 - val_loss: 0.0673 - val_accuracy: 0.9804\n",
      "Epoch 677/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0045 - accuracy: 0.9999 - val_loss: 0.0672 - val_accuracy: 0.9805\n",
      "Epoch 678/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0045 - accuracy: 0.9999 - val_loss: 0.0673 - val_accuracy: 0.9803\n",
      "Epoch 679/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0045 - accuracy: 0.9999 - val_loss: 0.0672 - val_accuracy: 0.9802\n",
      "Epoch 680/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0045 - accuracy: 0.9999 - val_loss: 0.0674 - val_accuracy: 0.9804\n",
      "Epoch 681/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0045 - accuracy: 0.9999 - val_loss: 0.0672 - val_accuracy: 0.9805\n",
      "Epoch 682/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0045 - accuracy: 0.9999 - val_loss: 0.0674 - val_accuracy: 0.9805\n",
      "Epoch 683/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0045 - accuracy: 0.9999 - val_loss: 0.0674 - val_accuracy: 0.9806\n",
      "Epoch 684/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0044 - accuracy: 0.9999 - val_loss: 0.0674 - val_accuracy: 0.9806\n",
      "Epoch 685/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0044 - accuracy: 0.9999 - val_loss: 0.0674 - val_accuracy: 0.9806\n",
      "Epoch 686/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0044 - accuracy: 0.9999 - val_loss: 0.0674 - val_accuracy: 0.9806\n",
      "Epoch 687/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0044 - accuracy: 0.9999 - val_loss: 0.0674 - val_accuracy: 0.9803\n",
      "Epoch 688/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0044 - accuracy: 0.9999 - val_loss: 0.0674 - val_accuracy: 0.9805\n",
      "Epoch 689/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0044 - accuracy: 0.9999 - val_loss: 0.0675 - val_accuracy: 0.9804\n",
      "Epoch 690/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0044 - accuracy: 0.9999 - val_loss: 0.0674 - val_accuracy: 0.9804\n",
      "Epoch 691/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0044 - accuracy: 0.9999 - val_loss: 0.0674 - val_accuracy: 0.9803\n",
      "Epoch 692/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0044 - accuracy: 0.9999 - val_loss: 0.0675 - val_accuracy: 0.9803\n",
      "Epoch 693/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0044 - accuracy: 0.9999 - val_loss: 0.0675 - val_accuracy: 0.9804\n",
      "Epoch 694/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0043 - accuracy: 0.9999 - val_loss: 0.0675 - val_accuracy: 0.9804\n",
      "Epoch 695/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0674 - val_accuracy: 0.9807\n",
      "Epoch 696/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0043 - accuracy: 0.9999 - val_loss: 0.0674 - val_accuracy: 0.9807\n",
      "Epoch 697/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0043 - accuracy: 0.9999 - val_loss: 0.0674 - val_accuracy: 0.9807\n",
      "Epoch 698/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0043 - accuracy: 0.9999 - val_loss: 0.0675 - val_accuracy: 0.9803\n",
      "Epoch 699/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0043 - accuracy: 0.9999 - val_loss: 0.0677 - val_accuracy: 0.9805\n",
      "Epoch 700/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0043 - accuracy: 0.9999 - val_loss: 0.0675 - val_accuracy: 0.9806\n",
      "Epoch 701/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0043 - accuracy: 0.9999 - val_loss: 0.0675 - val_accuracy: 0.9807\n",
      "Epoch 702/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0043 - accuracy: 0.9999 - val_loss: 0.0676 - val_accuracy: 0.9806\n",
      "Epoch 703/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0042 - accuracy: 0.9999 - val_loss: 0.0676 - val_accuracy: 0.9803\n",
      "Epoch 704/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0042 - accuracy: 0.9999 - val_loss: 0.0676 - val_accuracy: 0.9805\n",
      "Epoch 705/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0042 - accuracy: 0.9999 - val_loss: 0.0676 - val_accuracy: 0.9804\n",
      "Epoch 706/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0042 - accuracy: 0.9999 - val_loss: 0.0676 - val_accuracy: 0.9803\n",
      "Epoch 707/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0042 - accuracy: 0.9999 - val_loss: 0.0676 - val_accuracy: 0.9805\n",
      "Epoch 708/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0042 - accuracy: 0.9999 - val_loss: 0.0677 - val_accuracy: 0.9806\n",
      "Epoch 709/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0042 - accuracy: 0.9999 - val_loss: 0.0676 - val_accuracy: 0.9804\n",
      "Epoch 710/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0042 - accuracy: 0.9999 - val_loss: 0.0676 - val_accuracy: 0.9806\n",
      "Epoch 711/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0042 - accuracy: 0.9999 - val_loss: 0.0676 - val_accuracy: 0.9804\n",
      "Epoch 712/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0042 - accuracy: 0.9999 - val_loss: 0.0677 - val_accuracy: 0.9804\n",
      "Epoch 713/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.0677 - val_accuracy: 0.9804\n",
      "Epoch 714/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.0678 - val_accuracy: 0.9803\n",
      "Epoch 715/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.0677 - val_accuracy: 0.9806\n",
      "Epoch 716/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.0677 - val_accuracy: 0.9805\n",
      "Epoch 717/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.0676 - val_accuracy: 0.9807\n",
      "Epoch 718/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.0677 - val_accuracy: 0.9806\n",
      "Epoch 719/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.0678 - val_accuracy: 0.9804\n",
      "Epoch 720/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.0678 - val_accuracy: 0.9805\n",
      "Epoch 721/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.0677 - val_accuracy: 0.9808\n",
      "Epoch 722/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.0678 - val_accuracy: 0.9807\n",
      "Epoch 723/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0678 - val_accuracy: 0.9807\n",
      "Epoch 724/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0040 - accuracy: 0.9999 - val_loss: 0.0678 - val_accuracy: 0.9806\n",
      "Epoch 725/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0040 - accuracy: 0.9999 - val_loss: 0.0678 - val_accuracy: 0.9805\n",
      "Epoch 726/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0040 - accuracy: 0.9999 - val_loss: 0.0678 - val_accuracy: 0.9805\n",
      "Epoch 727/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0040 - accuracy: 0.9999 - val_loss: 0.0678 - val_accuracy: 0.9806\n",
      "Epoch 728/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0040 - accuracy: 0.9999 - val_loss: 0.0679 - val_accuracy: 0.9805\n",
      "Epoch 729/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0040 - accuracy: 0.9999 - val_loss: 0.0679 - val_accuracy: 0.9804\n",
      "Epoch 730/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0680 - val_accuracy: 0.9804\n",
      "Epoch 731/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 0.9806\n",
      "Epoch 732/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0040 - accuracy: 0.9999 - val_loss: 0.0679 - val_accuracy: 0.9806\n",
      "Epoch 733/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0040 - accuracy: 0.9999 - val_loss: 0.0679 - val_accuracy: 0.9806\n",
      "Epoch 734/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0040 - accuracy: 0.9999 - val_loss: 0.0680 - val_accuracy: 0.9806\n",
      "Epoch 735/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0039 - accuracy: 0.9999 - val_loss: 0.0679 - val_accuracy: 0.9806\n",
      "Epoch 736/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0039 - accuracy: 0.9999 - val_loss: 0.0680 - val_accuracy: 0.9804\n",
      "Epoch 737/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0680 - val_accuracy: 0.9806\n",
      "Epoch 738/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0680 - val_accuracy: 0.9807\n",
      "Epoch 739/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0039 - accuracy: 0.9999 - val_loss: 0.0681 - val_accuracy: 0.9806\n",
      "Epoch 740/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 0.9806\n",
      "Epoch 741/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0680 - val_accuracy: 0.9805\n",
      "Epoch 742/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0680 - val_accuracy: 0.9806\n",
      "Epoch 743/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0680 - val_accuracy: 0.9807\n",
      "Epoch 744/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0681 - val_accuracy: 0.9805\n",
      "Epoch 745/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0681 - val_accuracy: 0.9805\n",
      "Epoch 746/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0680 - val_accuracy: 0.9807\n",
      "Epoch 747/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0680 - val_accuracy: 0.9807\n",
      "Epoch 748/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0681 - val_accuracy: 0.9805\n",
      "Epoch 749/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0681 - val_accuracy: 0.9807\n",
      "Epoch 750/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0680 - val_accuracy: 0.9807\n",
      "Epoch 751/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0681 - val_accuracy: 0.9805\n",
      "Epoch 752/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0680 - val_accuracy: 0.9806\n",
      "Epoch 753/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0682 - val_accuracy: 0.9804\n",
      "Epoch 754/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0682 - val_accuracy: 0.9806\n",
      "Epoch 755/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0683 - val_accuracy: 0.9805\n",
      "Epoch 756/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0682 - val_accuracy: 0.9805\n",
      "Epoch 757/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0682 - val_accuracy: 0.9808\n",
      "Epoch 758/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0682 - val_accuracy: 0.9807\n",
      "Epoch 759/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0682 - val_accuracy: 0.9806\n",
      "Epoch 760/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0682 - val_accuracy: 0.9805\n",
      "Epoch 761/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0683 - val_accuracy: 0.9806\n",
      "Epoch 762/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0683 - val_accuracy: 0.9806\n",
      "Epoch 763/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 0.9805\n",
      "Epoch 764/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0683 - val_accuracy: 0.9806\n",
      "Epoch 765/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0682 - val_accuracy: 0.9806\n",
      "Epoch 766/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 0.9806\n",
      "Epoch 767/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0683 - val_accuracy: 0.9807\n",
      "Epoch 768/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0683 - val_accuracy: 0.9806\n",
      "Epoch 769/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 0.9807\n",
      "Epoch 770/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0683 - val_accuracy: 0.9806\n",
      "Epoch 771/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0683 - val_accuracy: 0.9806\n",
      "Epoch 772/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 0.9806\n",
      "Epoch 773/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0683 - val_accuracy: 0.9807\n",
      "Epoch 774/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0683 - val_accuracy: 0.9807\n",
      "Epoch 775/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 0.9807\n",
      "Epoch 776/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 0.9806\n",
      "Epoch 777/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 0.9806\n",
      "Epoch 778/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 0.9807\n",
      "Epoch 779/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 0.9807\n",
      "Epoch 780/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 0.9807\n",
      "Epoch 781/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 0.9806\n",
      "Epoch 782/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 0.9806\n",
      "Epoch 783/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 0.9807\n",
      "Epoch 784/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 0.9806\n",
      "Epoch 785/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 0.9805\n",
      "Epoch 786/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 0.9807\n",
      "Epoch 787/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 0.9808\n",
      "Epoch 788/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0686 - val_accuracy: 0.9805\n",
      "Epoch 789/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0686 - val_accuracy: 0.9806\n",
      "Epoch 790/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0686 - val_accuracy: 0.9805\n",
      "Epoch 791/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 0.9808\n",
      "Epoch 792/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 0.9807\n",
      "Epoch 793/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0686 - val_accuracy: 0.9808\n",
      "Epoch 794/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0686 - val_accuracy: 0.9806\n",
      "Epoch 795/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0686 - val_accuracy: 0.9807\n",
      "Epoch 796/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0686 - val_accuracy: 0.9808\n",
      "Epoch 797/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0686 - val_accuracy: 0.9806\n",
      "Epoch 798/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0687 - val_accuracy: 0.9806\n",
      "Epoch 799/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0687 - val_accuracy: 0.9804\n",
      "Epoch 800/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0687 - val_accuracy: 0.9807\n",
      "Epoch 801/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0687 - val_accuracy: 0.9808\n",
      "Epoch 802/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0687 - val_accuracy: 0.9807\n",
      "Epoch 803/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 0.9805\n",
      "Epoch 804/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0687 - val_accuracy: 0.9807\n",
      "Epoch 805/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0687 - val_accuracy: 0.9806\n",
      "Epoch 806/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 0.9804\n",
      "Epoch 807/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 0.9808\n",
      "Epoch 808/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 0.9806\n",
      "Epoch 809/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0687 - val_accuracy: 0.9807\n",
      "Epoch 810/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0687 - val_accuracy: 0.9807\n",
      "Epoch 811/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 0.9808\n",
      "Epoch 812/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 0.9805\n",
      "Epoch 813/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 0.9806\n",
      "Epoch 814/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 0.9806\n",
      "Epoch 815/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0687 - val_accuracy: 0.9807\n",
      "Epoch 816/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 0.9808\n",
      "Epoch 817/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 0.9807\n",
      "Epoch 818/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 0.9808\n",
      "Epoch 819/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0689 - val_accuracy: 0.9808\n",
      "Epoch 820/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0689 - val_accuracy: 0.9808\n",
      "Epoch 821/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0689 - val_accuracy: 0.9805\n",
      "Epoch 822/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 0.9808\n",
      "Epoch 823/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0689 - val_accuracy: 0.9806\n",
      "Epoch 824/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0689 - val_accuracy: 0.9808\n",
      "Epoch 825/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0690 - val_accuracy: 0.9806\n",
      "Epoch 826/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0690 - val_accuracy: 0.9806\n",
      "Epoch 827/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0690 - val_accuracy: 0.9806\n",
      "Epoch 828/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0690 - val_accuracy: 0.9808\n",
      "Epoch 829/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0689 - val_accuracy: 0.9808\n",
      "Epoch 830/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0690 - val_accuracy: 0.9808\n",
      "Epoch 831/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0690 - val_accuracy: 0.9807\n",
      "Epoch 832/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0690 - val_accuracy: 0.9807\n",
      "Epoch 833/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9806\n",
      "Epoch 834/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9808\n",
      "Epoch 835/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9806\n",
      "Epoch 836/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9806\n",
      "Epoch 837/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9804\n",
      "Epoch 838/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9808\n",
      "Epoch 839/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9807\n",
      "Epoch 840/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9807\n",
      "Epoch 841/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9807\n",
      "Epoch 842/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0690 - val_accuracy: 0.9808\n",
      "Epoch 843/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0692 - val_accuracy: 0.9807\n",
      "Epoch 844/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0692 - val_accuracy: 0.9806\n",
      "Epoch 845/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0692 - val_accuracy: 0.9805\n",
      "Epoch 846/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9808\n",
      "Epoch 847/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0692 - val_accuracy: 0.9807\n",
      "Epoch 848/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0692 - val_accuracy: 0.9808\n",
      "Epoch 849/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9807\n",
      "Epoch 850/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0692 - val_accuracy: 0.9808\n",
      "Epoch 851/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0692 - val_accuracy: 0.9806\n",
      "Epoch 852/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0692 - val_accuracy: 0.9807\n",
      "Epoch 853/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0692 - val_accuracy: 0.9809\n",
      "Epoch 854/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0692 - val_accuracy: 0.9809\n",
      "Epoch 855/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0693 - val_accuracy: 0.9807\n",
      "Epoch 856/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0693 - val_accuracy: 0.9807\n",
      "Epoch 857/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 0.9807\n",
      "Epoch 858/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 0.9807\n",
      "Epoch 859/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0693 - val_accuracy: 0.9808\n",
      "Epoch 860/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0693 - val_accuracy: 0.9809\n",
      "Epoch 861/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0693 - val_accuracy: 0.9809\n",
      "Epoch 862/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0693 - val_accuracy: 0.9806\n",
      "Epoch 863/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0693 - val_accuracy: 0.9806\n",
      "Epoch 864/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0693 - val_accuracy: 0.9806\n",
      "Epoch 865/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 0.9805\n",
      "Epoch 866/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 0.9806\n",
      "Epoch 867/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0693 - val_accuracy: 0.9808\n",
      "Epoch 868/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 0.9808\n",
      "Epoch 869/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0693 - val_accuracy: 0.9807\n",
      "Epoch 870/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 0.9807\n",
      "Epoch 871/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 0.9807\n",
      "Epoch 872/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 0.9808\n",
      "Epoch 873/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 0.9806\n",
      "Epoch 874/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 0.9807\n",
      "Epoch 875/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 0.9805\n",
      "Epoch 876/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0695 - val_accuracy: 0.9805\n",
      "Epoch 877/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0695 - val_accuracy: 0.9806\n",
      "Epoch 878/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0695 - val_accuracy: 0.9808\n",
      "Epoch 879/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 0.9807\n",
      "Epoch 880/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0695 - val_accuracy: 0.9805\n",
      "Epoch 881/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0695 - val_accuracy: 0.9808\n",
      "Epoch 882/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0695 - val_accuracy: 0.9806\n",
      "Epoch 883/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0695 - val_accuracy: 0.9808\n",
      "Epoch 884/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0695 - val_accuracy: 0.9807\n",
      "Epoch 885/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0696 - val_accuracy: 0.9808\n",
      "Epoch 886/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0696 - val_accuracy: 0.9807\n",
      "Epoch 887/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0695 - val_accuracy: 0.9807\n",
      "Epoch 888/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0696 - val_accuracy: 0.9806\n",
      "Epoch 889/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9806\n",
      "Epoch 890/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0696 - val_accuracy: 0.9806\n",
      "Epoch 891/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0696 - val_accuracy: 0.9808\n",
      "Epoch 892/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9806\n",
      "Epoch 893/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9807\n",
      "Epoch 894/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9807\n",
      "Epoch 895/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9807\n",
      "Epoch 896/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9809\n",
      "Epoch 897/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9806\n",
      "Epoch 898/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9808\n",
      "Epoch 899/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9808\n",
      "Epoch 900/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0696 - val_accuracy: 0.9807\n",
      "Epoch 901/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9808\n",
      "Epoch 902/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9806\n",
      "Epoch 903/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0698 - val_accuracy: 0.9808\n",
      "Epoch 904/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9806\n",
      "Epoch 905/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9807\n",
      "Epoch 906/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0698 - val_accuracy: 0.9807\n",
      "Epoch 907/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0698 - val_accuracy: 0.9807\n",
      "Epoch 908/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9806\n",
      "Epoch 909/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0698 - val_accuracy: 0.9807\n",
      "Epoch 910/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0698 - val_accuracy: 0.9808\n",
      "Epoch 911/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0698 - val_accuracy: 0.9807\n",
      "Epoch 912/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0698 - val_accuracy: 0.9808\n",
      "Epoch 913/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0698 - val_accuracy: 0.9806\n",
      "Epoch 914/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 0.9806\n",
      "Epoch 915/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0698 - val_accuracy: 0.9807\n",
      "Epoch 916/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 0.9806\n",
      "Epoch 917/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 0.9807\n",
      "Epoch 918/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 0.9805\n",
      "Epoch 919/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0700 - val_accuracy: 0.9806\n",
      "Epoch 920/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 0.9806\n",
      "Epoch 921/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 0.9807\n",
      "Epoch 922/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0700 - val_accuracy: 0.9808\n",
      "Epoch 923/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 0.9806\n",
      "Epoch 924/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0700 - val_accuracy: 0.9805\n",
      "Epoch 925/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0700 - val_accuracy: 0.9806\n",
      "Epoch 926/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 0.9806\n",
      "Epoch 927/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0700 - val_accuracy: 0.9807\n",
      "Epoch 928/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0700 - val_accuracy: 0.9808\n",
      "Epoch 929/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0700 - val_accuracy: 0.9807\n",
      "Epoch 930/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0700 - val_accuracy: 0.9807\n",
      "Epoch 931/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0701 - val_accuracy: 0.9806\n",
      "Epoch 932/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0700 - val_accuracy: 0.9807\n",
      "Epoch 933/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0700 - val_accuracy: 0.9807\n",
      "Epoch 934/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0701 - val_accuracy: 0.9806\n",
      "Epoch 935/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0701 - val_accuracy: 0.9808\n",
      "Epoch 936/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0701 - val_accuracy: 0.9806\n",
      "Epoch 937/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9806\n",
      "Epoch 938/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9806\n",
      "Epoch 939/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0701 - val_accuracy: 0.9805\n",
      "Epoch 940/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0701 - val_accuracy: 0.9806\n",
      "Epoch 941/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0701 - val_accuracy: 0.9806\n",
      "Epoch 942/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0701 - val_accuracy: 0.9806\n",
      "Epoch 943/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9807\n",
      "Epoch 944/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0701 - val_accuracy: 0.9806\n",
      "Epoch 945/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0701 - val_accuracy: 0.9807\n",
      "Epoch 946/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9805\n",
      "Epoch 947/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9808\n",
      "Epoch 948/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9808\n",
      "Epoch 949/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9807\n",
      "Epoch 950/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9806\n",
      "Epoch 951/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9807\n",
      "Epoch 952/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9807\n",
      "Epoch 953/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9807\n",
      "Epoch 954/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9807\n",
      "Epoch 955/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0703 - val_accuracy: 0.9807\n",
      "Epoch 956/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0703 - val_accuracy: 0.9808\n",
      "Epoch 957/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9806\n",
      "Epoch 958/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0703 - val_accuracy: 0.9806\n",
      "Epoch 959/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0703 - val_accuracy: 0.9808\n",
      "Epoch 960/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9808\n",
      "Epoch 961/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0703 - val_accuracy: 0.9809\n",
      "Epoch 962/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0703 - val_accuracy: 0.9808\n",
      "Epoch 963/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0703 - val_accuracy: 0.9807\n",
      "Epoch 964/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0703 - val_accuracy: 0.9808\n",
      "Epoch 965/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0703 - val_accuracy: 0.9808\n",
      "Epoch 966/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0704 - val_accuracy: 0.9808\n",
      "Epoch 967/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0703 - val_accuracy: 0.9806\n",
      "Epoch 968/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0703 - val_accuracy: 0.9808\n",
      "Epoch 969/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0704 - val_accuracy: 0.9807\n",
      "Epoch 970/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0704 - val_accuracy: 0.9807\n",
      "Epoch 971/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0703 - val_accuracy: 0.9807\n",
      "Epoch 972/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0704 - val_accuracy: 0.9808\n",
      "Epoch 973/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0704 - val_accuracy: 0.9807\n",
      "Epoch 974/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0704 - val_accuracy: 0.9806\n",
      "Epoch 975/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0704 - val_accuracy: 0.9808\n",
      "Epoch 976/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0704 - val_accuracy: 0.9807\n",
      "Epoch 977/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0704 - val_accuracy: 0.9808\n",
      "Epoch 978/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0705 - val_accuracy: 0.9809\n",
      "Epoch 979/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0705 - val_accuracy: 0.9808\n",
      "Epoch 980/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0705 - val_accuracy: 0.9807\n",
      "Epoch 981/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0706 - val_accuracy: 0.9808\n",
      "Epoch 982/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0705 - val_accuracy: 0.9808\n",
      "Epoch 983/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0706 - val_accuracy: 0.9807\n",
      "Epoch 984/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0705 - val_accuracy: 0.9808\n",
      "Epoch 985/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0705 - val_accuracy: 0.9807\n",
      "Epoch 986/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0706 - val_accuracy: 0.9808\n",
      "Epoch 987/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0705 - val_accuracy: 0.9807\n",
      "Epoch 988/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0705 - val_accuracy: 0.9807\n",
      "Epoch 989/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0706 - val_accuracy: 0.9808\n",
      "Epoch 990/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0706 - val_accuracy: 0.9807\n",
      "Epoch 991/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0706 - val_accuracy: 0.9807\n",
      "Epoch 992/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0706 - val_accuracy: 0.9808\n",
      "Epoch 993/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0706 - val_accuracy: 0.9807\n",
      "Epoch 994/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0706 - val_accuracy: 0.9807\n",
      "Epoch 995/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0706 - val_accuracy: 0.9808\n",
      "Epoch 996/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0707 - val_accuracy: 0.9806\n",
      "Epoch 997/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0706 - val_accuracy: 0.9808\n",
      "Epoch 998/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0706 - val_accuracy: 0.9806\n",
      "Epoch 999/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0706 - val_accuracy: 0.9807\n",
      "Epoch 1000/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0706 - val_accuracy: 0.9808\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    batch_size=100, \n",
    "                    epochs=1000,\n",
    "                    verbose=1, \n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 49s 807us/step - loss: 0.0024 - accuracy: 1.0000\n",
      "loss(train): 0.002398\n",
      "accuracy(train): 1.0\n",
      "\n",
      "10000/10000 [==============================] - 8s 800us/step - loss: 0.0706 - accuracy: 0.9808\n",
      "loss(test): 0.07064\n",
      "accuracy(test): 0.9808\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAArdklEQVR4nO3de5zcdX3v8ddnZnZmr8kmmyXkBgkaIEG5mQMVq4JUi1pPqJcilSNSLcWKiNYqam3tseeUtuqxqMcctJEiXqoiihQVQTjRY7gECPcEQhKSJbfN5rLZ+1w+54/vb5LZ2Ul2NuzsbGbfz8djHjO/++c3u/P7/L7f7+/3+5q7IyIiUixW7QBERGRyUoIQEZGSlCBERKQkJQgRESlJCUJEREpSghARkZKUIGTKM7OFZuZmlihj3veZ2W8nIi6RalOCkGOKmW02syEzm1U0fm10kF9YpdBEao4ShByLNgGX5gfM7JVAQ/XCmRzKKQGJjIUShByLvg28t2D4cuDmwhnMbLqZ3WxmnWb2gpn9jZnFomlxM/uCme02s43AW0ss+29mtt3MXjSzfzCzeDmBmdkPzWyHme03s1VmdlrBtAYz+2IUz34z+62ZNUTTft/Mfmdm+8xsq5m9Lxp/n5l9oGAdw6q4olLTh8zsOeC5aNy/RuvoNrOHzey1BfPHzezTZva8mR2Ipi8ws6+Z2ReL9uVnZnZtOfsttUkJQo5F9wPTzGxJdOC+BLilaJ6vANOBk4DXExLKFdG0Pwf+CDgLWAa8s2jZfwcywMujed4EfIDy/BxYDBwHPAJ8p2DaF4BXAecBM4FPADkzOyFa7itAO3AmsLbM7QFcDJwLLI2GH4rWMRP4LvBDM6uPpn2MUPp6CzAN+DOgj7DPlxYk0VnAhcD3xhCH1Bp310uvY+YFbAb+APgb4B+Bi4BfAQnAgYVAHBgElhYs9xfAfdHnXwNXFUx7U7RsApgdLdtQMP1S4N7o8/uA35YZa2u03umEk7F+4IwS830KuO0w67gP+EDB8LDtR+t/wyhx7M1vF1gPLD/MfM8Ab4w+Xw3cWe2/t17VfanOUo5V3wZWAYsoql4CZgFJ4IWCcS8A86LPc4GtRdPyTgTqgO1mlh8XK5q/pKg08z+AdxFKArmCeFJAPfB8iUUXHGZ8uYbFZmZ/RSjxzCUkkGlRDKNt69+BywgJ9zLgX19CTFIDVMUkxyR3f4HQWP0W4MdFk3cDacLBPu8E4MXo83bCgbJwWt5WQglilru3Rq9p7n4ao/tTYDmhhDOdUJoBsCimAeBlJZbbepjxAL1AY8Hw8SXmOfhI5qi94ZPAnwAz3L0V2B/FMNq2bgGWm9kZwBLgJ4eZT6YIJQg5lr2fUL3SWzjS3bPAD4D/YWYtZnYioe49307xA+AaM5tvZjOA6wqW3Q7cBXzRzKaZWczMXmZmry8jnhZCcukiHNT/Z8F6c8BK4EtmNjdqLH61maUI7RR/YGZ/YmYJM2szszOjRdcCbzezRjN7ebTPo8WQATqBhJn9LaEEkfdN4PNmttiC082sLYqxg9B+8W3gVnfvL2OfpYYpQcgxy92fd/c1h5n8YcLZ90bgt4TG2pXRtG8AvwQeIzQkF5dA3kuoonqaUH//I2BOGSHdTKiuejFa9v6i6R8HniAchPcA/wTE3H0LoST0V9H4tcAZ0TL/CxgCdhKqgL7Dkf2S0OD9bBTLAMOroL5ESJB3Ad3AvzH8EuF/B15JSBIyxZm7OgwSkcDMXkcoaS2MSj0yhakEISIAmFkd8BHgm0oOAkoQIgKY2RJgH6Eq7ctVDUYmDVUxiYhISSpBiIhISTV1o9ysWbN84cKF1Q5DROSY8fDDD+929/ZS02oqQSxcuJA1aw531aOIiBQzsxcON01VTCIiUpIShIiIlKQEISIiJdVUG0Qp6XSajo4OBgYGqh1KxdXX1zN//nzq6uqqHYqI1ICaTxAdHR20tLSwcOFCCh7fXHPcna6uLjo6Oli0aFG1wxGRGlCxKiYzW2lmu8zsycNMNzO7wcw2mNnjZnZ2wbSLzGx9NO26UsuXa2BggLa2tppODgBmRltb25QoKYnIxKhkG8RNhN6+DufNhK4ZFwNXAl+Hg52ufC2avpTQDeLSw62kHLWeHPKmyn6KyMSoWBWTu68ys4VHmGU5cLOHZ33cb2atZjaH0MnKBnffCGBm34/mfbpSsYqMxt3J5JxM1hnMZDkwkDk4LRYzcjmP5oOcOzl3PFou50Xji4cL5svmoun4wXkK3x0nl+Ow68+Py8t5YVxhWsxsWCwQehzKResq2vHhgyW/m5Hf1ZGWKfV0n5HzHPkRQKXX4Uecp7w4jryOkXGMnGGs2y3eZjnrKJ6hMZXgqtcfrh+oo1fNNoh5DH9OfUc0rtT4cw+3EjO7klAC4YQTTjjcbFXR1dXFhRdeCMCOHTuIx+O0t4cbFh988EGSyeRhl12zZg0333wzN9xww4TEOhkMZXL0D2XpHcrQN5ShdzD6nH8fytI7GN6zOSeZiDGYzjKQyYX3dI7BTJZ0Nvx49vUPMZTJHVz3UNZJZ8M2MrncwQOrRwfWwoMxBQfcdDZ3cJ0ik0VhhcGs5lTNJYhS9SF+hPElufuNwI0Ay5Ytm1S/4ra2NtauXQvA5z73OZqbm/n4xz9+cHomkyGRKP0nWLZsGcuWLZuIMMeFu5POhrPSF/f1s7d3iN09g3T2DNHVM8iBgczBg/O+/jT7+obY15embyhLZ8/gweWPRn1djFQiTn1djPq6OImYYWY0pxI01MUBaGxMUBePkUwY9Yk4dfEYsVioljMgZoZZeAcOfjagLhEjGY+RiBmJeIy6uNGYTJCIh+nuYf58FV88Bsah9eXfYwYQ3mNmYftF88XN4OD8+WnD48yPL16/Ec1X8AuKFwzEQwDkolJELJaPqWBeCzEVKq65LPUDLa7eLJ5n5DpKrKV4nlG2W6pKdazbLadW9mjWMVqso8VZaplqqGaC6GB4v8DzgW2EnrxKja8J73vf+5g5cyaPPvooZ599NpdccgnXXnst/f39NDQ08K1vfYtTTjmF++67jy984QvccccdfO5zn2PLli1s3LiRLVu2cO2113LNNddMaNx9Qxm27OljS1cf+/rTbOnqYyCdZcuePnYdGGTrnj66eocOu7wZNNbFaa5PMKMxSWtjHSe1N9FSX8f0hjrq4jGaU3EakwmaovfG5PDh/HtDXZxszjGDVCI2KX5IIrWomgniduDqqI3hXGC/u283s05gsZktInTd+G5CZ/Av2d//7Cme3tY9Hqs6aOncafzd28rpz/6QZ599lrvvvpt4PE53dzerVq0ikUhw99138+lPf5pbb711xDLr1q3j3nvv5cCBA5xyyil88IMfHNf7Hdyd7oEM67Z3s7mrl13dg2zu6mPLnl42d/XReWBwxDJm0JxMcEJbI+csmsnJs1twYO70eua0NjCrOUlrY5JUIkZbU1IHcpFjTMUShJl9DzgfmGVmHcDfAXUA7r4CuJPQD+8GoA+4IpqWMbOrCX3rxoGV7v5UpeKshne9613E46HqY//+/Vx++eU899xzmBnpdLrkMm9961tJpVKkUimOO+44du7cyfz5849q+1v39PHIlr3s70/z8At7eWZ7Nxs7e8kUtVDOnpbixJlNnH9yOye2NXJCWxOtDXXMaExyyvEtJBO6EV+kllXyKqZLR5nuwIcOM+1OQgIZV2M906+Upqamg58/+9nPcsEFF3DbbbexefNmzj///JLLpFKpg5/j8TiZTKbkfMU27+7lhT19rHq2k2d3HmDrnj42d/UdnD6rOcUr503jFfOmc+rxLSxsa+K4afWcPLuZxmTN30cpIkegI0CV7d+/n3nz5gFw0003HfV68pdh9g9lue7Wx3lxXz/rdhw4WDWUTMSY19rA7Gn1vGvZAua21vPKea28rL1JVT8iUpISRJV94hOf4PLLL+dLX/oSb3jDG8a0bN9QhgMDGXoHM/Snw6WfXb1D/OjhHbysvZnXn9zOqce3cGJbE7//8lk0JOMV2gsRqUU11Sf1smXLvLjDoGeeeYYlS5ZUKaLxlfNQQtgbXSKavwkqHjNa6utIJmJs37yBk085laaUcr+IjM7MHnb3ktfU6yhyDOjuT7Ond4jeoQzZXLiGPZmI0dpQR0t9HfV1hy713FsXV3IQkXGhI8kk5O4MpPM3lKVJZ8PdwM2pBK2N4b6BeExXEIlIZSlBTCLZnLOnd5A9vWkGM1kMo7k+wcymJDObktTFlRREZOIoQUwC/UMZdnYP0j0Q7oFoqIszr7WB6Q11JJQURKRKlCCqKJ3NsW1fP/v7Q2KImbGwrZGmVEKXnopI1SlBVMFQJsuO/QPsixLDzKYk7c0pknqukIhMIkoQFVTqcd8z2maRyeb47h2/pm1aI+0tqcPesXzfffeRTCY577zzJjJsERFACaKi8o/7dneu+8zfkkuk+G9XXk1zKsH8GY2jPsvovvvuo7m5WQmiWDYDg93hOdtNbWE4noBsOuoZJwM4JBog0w+xOkgkw3QMLAa9uyA7BC1zYGB/tN4hSPdDXxdMmwfxOhg8ENZX1wCJ+rCOXCa8+vfBwF6YcxZsexQaZ0JmMMSGQcvx0NAaltn9LGxZDf17Ye5ZcPwZ4DnYej8km6GxDdbdAbuehtMvgfrpYf37XoDO9TD7NJj5MtjxOCw4F/ZtgYYZkEvDYA80zQoxPn8v9O2GGYvC9FRziGWoB3Y/B8ctgXgSYnGIJcLrwA7IZcN3mWyJvotByAxAanr0pTu88LvwnbSfCjufgraXQ/NxIcaeXWF8IhX2MzMYtnP86dCzE1oXwN7N4bvNZmDW4mg76fC9D/WEZYf6wt+mYWb4O3k2/I1ymbDOXDaMy2XC51wm/P3MDnWik3/+ei4DdY1hH9N9sOOJsP+paWGbsQR0vwgzFoZtDXaHdWYGwnID+2HmSWH8UC8km0Jcu5+NnlQ5O/ydBnvC36VpFsRT4TsplEiF/6NUS/ibJpvC337a3PAd9e+F3s5o/3shPRDijSfDvja2hf/Lgf0hds+G2PP/s7G6sM73/GDcf2pKEBWWzubYvq+f7oE001rq2fPCOj786U/S09PDrFmzuOmmm5gzZw433HADK1asIJFIsHTpUq6//npWrFhBPB7nlltu4Stf+Qqvfe1rKxuse/gRzX5F+FFPmwOZofDP3NsZfhCJZJive1v4p0z3QVN7+OHXt4Yfzv6OML5hJuzZGA6UnevCutfdCTNODAfT6Qtgw92w9YHwI927GRa9LhzY6qfD9sfCgScXPXcqngw/6ER9+BGPRdNx4cAzGTxy85Gn73hi5LjNvzn0+dFvj76NTatKj193x+jLjlU8FRJKIYuHA1nx9lLTQpLZ8KtwkIsnw3CsLvwPWSwktb494XMiFf7/EvWHDvaxWHi3OODh/y1WB/XToHd3mDZ0IGyvMUqc+YNsx0PQMjcczLs2hIP/YE/4f4rFw3ZSzWHZWDwkxVQLTJ8XkuJgD6R7Q9LKDEH3A4fibZkTkmX/3hA3hG327w2/lWwamtth974wLpYIB/hcJvx/JhvDthINIebMYJjesxPqmsJ3l+4L36tFT0UY6glJZ+FrDp0ojaOplSB+fl3pH99Lcfwr4c3Xjxjt7nT1DLFtfz8Qrkxqa6rj03/9MX7605/S3t7Of/zHf/CZz3yGlStXcv3117Np0yZSqRT79u2jtbWVq666akQnQyU2FH5AuegpsJlBuP/r4Wxz97OwdxOccSk8+wuYtyycXXasCWeNsxbD9rXhjGXP84CF6YXiyfBPmpeaFn5EL+Vgu7PE32Dv5vC+aVX4McfqoGdH+IHPOzv8IBpaoev58OMe2B/O9vZuCj+QxW8Mcc5+RVhP/fRw1rbh7nBGl2oJZ2dbH4Sly+G4pdC/Bx5YEZY//U/ghN8LB6HMYPgB59KQy4XvpuV4aD0hxBVLhIOaxULcqZbwfSabQqLL//j3bw0HjVgijF9wTvju+7rCgalhRnTQmB1iaZkTShDT5kdnsQ1hu54L64ZDiTl/gEykDp3tQjjI9O8LZ+zp/pC0Y/FDB5uGmWF9B8/CM9GZt4eDXH1rwd++Lip1RRKp8P8xeADal8CB7WE/jlsa9jm/jebZ0YEsF8a1HB8Se1N72KdKymbC3wXC9kc7YGbTYT+lpKmVICZIJptj+/4B9vYNkUzEWNjWxLSGOoaGhnjyySd54xvfCEA2m2XOnDkAnH766bznPe/h4osv5uKLLz60snwHxvkic/5sJ5cJZw/p/uEb79kFv7xu+LiHvlk60Gd/PvrOTJ8flQLmwgnnQk9nOPAteRu8sBoG9sG8V4VSwAmvDqWCJ34AC18bDngzFoZYE/Xhh5vuC/OlWsLLDPZsCtUT0+cdOviOlws/e+Tp51935Onj7aTXH3n6gnOOPH3mSaXHT5tz6HNr1PVuw4xD4xKpgpljhJ9+4bii+Q8nf3YNIQnlNc4cPl9d/fDh1gnqDnhYQijjEnElhyOaWgmixJn+eBvKZNnY2Us66xw3rZ7ZLamDVya5O6eddhqrV68esdx//ud/smrVKm7/6U/4/Oc/z1MP/QYGusF7wll+8Zl8oWRTqDvOZSC+D867JhxwZy8NCaXruXBG3b0djn9FSDj5+tNcOhwY0gPhrDKejOqTTwln6IlkOIuGULQvxzu+MbYvbfbkeAy7iAw3tRJEhQ2ks2ze3UvWnZe1N9FY9EykVCpFZ2cnq1ev5tWvfjXpdJpnn32WJUuWsPX59VxwSiu//9H38N3v3ELPi+toSUL3gXwPeBaqEiwWzrwbZkZnSza8Q9uWHjjn88MDW1RG20X99EOfm2aF91hUz6nHeohMSUoQ46RnMMPm3b2YwUmzmmgocelqLBbjRz/6Eddccw379+8nk0lz7VV/xsnTM1x22fvYf6AHd+ejf/4eWqe38LaL38E7L/8LfvrrByemkVpEpIAe9z0O+oYybNjVQyoRZ9GsRpKJw/S7kL+kr2dnuJwvV9AAWN8aVRVFr3y7wxjV0uPNRaTy9LjvCsrlnI49oaF4/oyGkckhmw6Nyr27Q5sCUX1+ogEapkNDW2jQs6JqHN1RLSJVpgTxEm3f389AJsuCGY3D+2FwD5cA7tkERKW0WAJSreFyv2RjNcIVESnblEgQ7l6RZxx1D6Tp6h2irSnFjKbkoQkD3dF9BZFkc3TV0LRxj6FQLVUXikj11XyCqK+vp6uri7a2tnFNEulsjhf39pNKxJkzPbrmO5cJl4j27IzmsnBZaazyX7O709XVRX19/egzi4iUoeYTxPz58+no6KCzs3Nc17uvL03vYIb2lhTr98bCvQLdHWFiPBnu+k2kYP9z47rdI6mvr2f+/PkTtj0RqW01nyDq6upYtGjRuK5zZ/cAy//5Xv74zHn80ztPC48TWPFa2L0+zPCpjnCvgojIMazmE8R4y+Wc6259nFzO+csLXgb7tsKXo+f/LP/fcOaf6gokEakJukV2jFZv7OLe9Z186i1LOLFxCH54eZgw6+TwUDwlBxGpESpBjNEt97/AjMY6LjupF/5lWWiYXvI2uOSWaocmIjKuVIIYg7Vb9/HzJ3dwyavmkLrxNSE5nPZ2uHhFtUMTERl3KkGMwXcfeIFUIsbHsisPjXznSlUriUhNUgmiTN0DaX7y6Db+ceFako+sDJ3vfLZLyUFEapYSRJlu/t1mMtkMb++I+pS4+Ovj3r2fiMhkogRRBnfn1kdeZOWMqC/hc6+C9pOrG5SISIXpFLgMD2zaQ6JrPeen7oJzPwgX/WO1QxIRqTiVIMrw40c6uDJ5F56oh9d9XO0OIjIlKEGMIpPNsfqpjSyP/QY7/U8OdccpIlLjKpogzOwiM1tvZhvM7LoS02eY2W1m9riZPWhmryiYttnMnjCztWa2pnjZifLApj2cO7SapA/CaX9crTBERCZcxdogzCwOfA14I9ABPGRmt7v70wWzfRpY6+5/bGanRvNfWDD9AnffXakYy/GfT2znvYm7w8CcM6sZiojIhKpkCeIcYIO7b3T3IeD7wPKieZYC9wC4+zpgoZnNrmBMY5LNOS888TtOt+fhFe+ExpnVDklEZMJUMkHMA7YWDHdE4wo9BrwdwMzOAU4E8h0aOHCXmT1sZlcebiNmdqWZrTGzNePd58MTHXv5fOZLYeC8q8d13SIik10lE0SpS32K+8S8HphhZmuBDwOPAplo2mvc/WzgzcCHzOx1pTbi7je6+zJ3X9be3j4+kUe23v9jTortIH382TD3rHFdt4jIZFfJ+yA6gAUFw/OBbYUzuHs3cAWAhf5AN0Uv3H1b9L7LzG4jVFmtqmC8I9Rv+hUAdZf9YCI3KyIyKVSyBPEQsNjMFplZEng3cHvhDGbWGk0D+ACwyt27zazJzFqieZqANwFPVjDWEfb3DnFO329Y33YhNI9vyURE5FhQsRKEu2fM7Grgl0AcWOnuT5nZVdH0FcAS4GYzywJPA++PFp8N3BYKFSSA77r7LyoVayn3Pvw4F1svPae8fiI3KyIyaVT0URvufidwZ9G4FQWfVwOLSyy3ETijkrGNZvGDnwVg7qnnVjMMEZGq0Z3UpbhzWs/vADA1TovIFKUEUcLAnnB17j0L/woSqSpHIyJSHUoQJTy/9jcAtL5c1UsiMnUpQZQwsGk1aY9z6lmvqXYoIiJVowRRLDPEqdt+wjPxk2lqaq52NCIiVaMEUWz7YzTlDnB/+zurHYmISFUpQRRJ73wGgPg8Xb0kIlObEkSR7h0byblx3LyTqh2KiEhVKUEUsU2reNFnseh4PdpbRKY2JYhCuRzT9zzGL3L/hUWzmqodjYhIVSlBFOrrIu4Zuuvn0JSq6FNIREQmPSWIQo9+G4DY9OJ+jUREph4liAK+8ykAeuaV7JtIRGRKUT1KgczOdfwmeyYLZs+qdigiIlWnEkSh7hd50WexUA3UIiJKEAdlBqkb3MtOn8H8GY3VjkZEpOqUIPIO7ABgF63Mba2vcjAiItWnBJHX1wXAQHImjUk1zYiIKEHk9e8BoK5ZDdQiIqAEcUhfSBD109urHIiIyOSgBJEXJYiWGcdVORARkclBCSIy2L2LrBsz2lSCEBEB3Sh3UH/3bnI0MXu67oEQEQEliIOyPbvZ5y20NSerHYqIyKSgKqa83i720sLMJiUIERFQgjgo0beTXd5KW1Oq2qGIiEwKShCRhoFd7PQZzGiqq3YoIiKTghIEwFAvyWwv++NtpBLxakcjIjIpKEEADPYAkEu1VDkQEZHJY9QEYWZ/ZGa1nUiGQoKIpZqrHIiIyORRzoH/3cBzZvbPZrak0gFVxVBveE8qQYiI5I2aINz9MuAs4HngW2a22syuNLPaqY+JEoSpBCEiclBZVUfu3g3cCnwfmAP8MfCImX24grFNnKiKSSUIEZFDymmDeJuZ3Qb8GqgDznH3NwNnAB+vcHwTI0oQiXolCBGRvHJKEO8C/pe7n+7u/+LuuwDcvQ/4syMtaGYXmdl6M9tgZteVmD7DzG4zs8fN7EEze0W5y44nj65iiilBiIgcVE6C+DvgwfyAmTWY2UIAd7/ncAuZWRz4GvBmYClwqZktLZrt08Badz8deC/wr2NYdtxkogRR1zitUpsQETnmlJMgfgjkCoaz0bjRnANscPeN7j5EaL9YXjTPUuAeAHdfByw0s9llLjtu0n3dANQ11E67u4jIS1VOgkhEB2kAos/lPNFuHrC1YLgjGlfoMeDtAGZ2DnAiML/MZYmWu9LM1pjZms7OzjLCGinTf4C0x2mobziq5UVEalE5CaLTzP5rfsDMlgO7y1jOSozzouHrgRlmthb4MPAokClz2TDS/UZ3X+buy9rbj66zn8xAD32kaErpOUwiInnl9AdxFfAdM/sq4cC9ldBeMJoOYEHB8HxgW+EM0eWzVwCYmQGbolfjaMuOp9xgDwPU05TSc5hERPJGTRDu/jzwe2bWDJi7Hyhz3Q8Bi81sEfAi4Y7sPy2cwcxagb6o2uoDwCp37zazUZcdT7nBXvo9RVNK/SeJiOSVdUQ0s7cCpwH14UQf3P2/H2kZd8+Y2dXAL4E4sNLdnzKzq6LpK4AlwM1mlgWeBt5/pGWPYv/KksumyRCnKakEISKSN+oR0cxWEKp8LgC+CbyTgstej8Td7wTuLBq3ouDzamBxuctWimczZIjTUFfbzyQUERmLco6I57n7e4G97v73wKsZ3j5wzPNcSBB1cSUIEZG8co6IA9F7n5nNBdLAosqFNPEsmyFLjGRCCUJEJK+cSvefRY3J/wI8Qrjc9BuVDGrC5TKkSZCIlbq6VkRkajpigog6CrrH3fcBt5rZHUC9u++fiOAmjGfIeoyEqphERA464hHR3XPAFwuGB2suOQAWtUEklSBERA4q54h4l5m9w/LXt9Ygy2XJEiMRr9ldFBEZs3LaID4GNAEZMxsg3E3t7l4zjz41z5ChQW0QIiIFyrmTuuYfcWq5LDmLU8OFJBGRMSvnRrnXlRrv7qvGP5zqME+TQ89hEhEpVE4V018XfK4n9NXwMPCGikRUBTHPkospQYiIFCqniulthcNmtgD454pFVAWhiknPYRIRKXQ013V2AK8Yda5jSMxDG4SIiBxSThvEVzjUWU8MOJPQE1zNiHkGV4IQERmmnHqVNQWfM8D33P3/VSieqghtEKpiEhEpVM5R8UfAgLtnAcwsbmaN7t5X2dAmTgxVMYmIFCunDeIeoKFguAG4uzLhVEfMs2R1mauIyDDlJIh6d+/JD0SfGysX0sT733P/kTuSF1U7DBGRSaWcBNFrZmfnB8zsVUB/5UKaeM81nsH2+NxqhyEiMqmU0wZxLfBDM9sWDc8BLqlYRFXgHh4wJSIih5Rzo9xDZnYqcArhOLrO3dMVj2wCuYMewyQiMtyoVUxm9iGgyd2fdPcngGYz+8vKhzZxHMdUhhARGaacNog/j3qUA8Dd9wJ/XrGIqkAlCBGRkcpJELHCzoLMLA4kKxeSiIhMBuU0Uv8S+IGZrSA8cuMq4OcVjWqC+eiziIhMOeUkiE8CVwIfJDRSP0q4kqlmhCom1TGJiBQatYrJ3XPA/cBGYBlwIfBMheOaYK4mahGRIoctQZjZycC7gUuBLuA/ANz9gokJbeKokVpEZKQjVTGtA34DvM3dNwCY2UcnJKoJ5ihBiIgUO1IV0zuAHcC9ZvYNM7uQGr3h2F33QYiIFDtsgnD329z9EuBU4D7go8BsM/u6mb1pguKbMCpBiIgMV04jda+7f8fd/wiYD6wFrqt0YBNJl7mKiIw0pj6p3X2Pu/8fd39DpQKqBj2sT0RkpDEliFrloDomEZEiShDkG6lFRKSQEkREBQgRkeEqmiDM7CIzW29mG8xsRMO2mU03s5+Z2WNm9pSZXVEwbbOZPWFma81sTSXjVBuEiMhI5TyL6ahET339GvBGoAN4yMxud/enC2b7EPC0u7/NzNqB9Wb2HXcfiqZf4O67KxVjUbwTsRkRkWNGJUsQ5wAb3H1jdMD/PrC8aB4HWqLHiTcDe4BMBWMqyXWhq4jICJVMEPOArQXDHdG4Ql8FlgDbgCeAj0QPB4SQPO4ys4fN7MrDbcTMrjSzNWa2prOz86gCVRWTiMhIlUwQpY65xafqf0i48W4ucCbwVTObFk17jbufDbwZ+JCZva7URtz9Rndf5u7L2tvbjypQPaxPRGSkSiaIDmBBwfB8Qkmh0BXAjz3YAGwiPNoDd98Wve8CbiNUWVWE+qQWERmpkgniIWCxmS0ysyTh0eG3F82zhdC/BGY2GzgF2GhmTWbWEo1vAt4EPFmpQN1RHZOISJGKXcXk7hkzu5rQZWkcWOnuT5nZVdH0FcDngZvM7AnCIfqT7r7bzE4CbouuLEoA33X3X1QsVpQfRESKVSxBALj7ncCdReNWFHzeRigdFC+3ETijkrEVUxuEiMhwupMa9DhXEZESlCBQI7WISClKEOgyVxGRUpQgUJ/UIiKlKEGgPqlFREpRgkAlCBGRUpQgiG6UExGRYZQgRESkJCUI8lVMqmMSESmkBAGgPqlFREZQgkCN1CIipShBoA6DRERKUYIgetSGihAiIsMoQaAShIhIKUoQERUgRESGU4JAN8qJiJSiBEG+OwgVIURECilBED2sT/lBRGQYJYiI8oOIyHBKEKjDIBGRUpQgUJejIiKlKEFEVIIQERlOCQJd5ioiUooSBHpYn4hIKUoQqE9qEZFSlCCIbpRTfhARGUYJAkAP6xMRGUEJAnU5KiJSihJEROlBRGQ4JQhCI7WIiAynBIEucxURKUUJAvUoJyJSihIE6pNaRKQUJQhUghARKaWiCcLMLjKz9Wa2wcyuKzF9upn9zMweM7OnzOyKcpcdT+4oQ4iIFKlYgjCzOPA14M3AUuBSM1taNNuHgKfd/QzgfOCLZpYsc9nxjVcZQkRkmEqWIM4BNrj7RncfAr4PLC+ax4EWCw0AzcAeIFPmsiIiUkGVTBDzgK0Fwx3RuEJfBZYA24AngI+4e67MZceN+qQWERmpkgmi1CG3+I60PwTWAnOBM4Gvmtm0MpcNGzG70szWmNmazs7OowpUTRAiIiNVMkF0AAsKhucTSgqFrgB+7MEGYBNwapnLAuDuN7r7Mndf1t7eflSBqk9qEZGRKpkgHgIWm9kiM0sC7wZuL5pnC3AhgJnNBk4BNpa57LhRn9QiIiMlKrVid8+Y2dXAL4E4sNLdnzKzq6LpK4DPAzeZ2ROEWp5PuvtugFLLVi5WlSBERIpVLEEAuPudwJ1F41YUfN4GvKncZStJCUJEZDjdSc1hWr9FRKY4JQiiO6nVBiEiMowSBAC6D0JEpJgSBHpYn4hIKUoQqMMgEZFSlCCIHrWhMoSIyDBKEBGVIEREhlOCQJe5ioiUogSBGqlFREpRgiD/uG+lCBGRQkoQqIpJRKQUJQgAPaxPRGQEJQjyHQYpQ4iIFFKCiKgEISIynBIEoZFaRESGU4JAfVKLiJSiBIF6lBMRKUUJgqhPamUIEZFhlCCAi047niVzWqodhojIpFLRPqmPFV9+91nVDkFEZNJRCUJEREpSghARkZKUIEREpCQlCBERKUkJQkRESlKCEBGRkpQgRESkJCUIEREpyWrpSaZm1gm8cJSLzwJ2j2M4xwLt89Sgfa59L2V/T3T39lITaipBvBRmtsbdl1U7jomkfZ4atM+1r1L7qyomEREpSQlCRERKUoI45MZqB1AF2uepQftc+yqyv2qDEBGRklSCEBGRkpQgRESkpCmfIMzsIjNbb2YbzOy6asczXsxsgZnda2bPmNlTZvaRaPxMM/uVmT0Xvc8oWOZT0few3sz+sHrRvzRmFjezR83sjmi4pvfZzFrN7Edmti76e796CuzzR6P/6yfN7HtmVl9r+2xmK81sl5k9WTBuzPtoZq8ysyeiaTfYWPpXdvcp+wLiwPPASUASeAxYWu24xmnf5gBnR59bgGeBpcA/A9dF468D/in6vDTa/xSwKPpe4tXej6Pc948B3wXuiIZrep+Bfwc+EH1OAq21vM/APGAT0BAN/wB4X63tM/A64GzgyYJxY95H4EHg1YABPwfeXG4MU70EcQ6wwd03uvsQ8H1geZVjGhfuvt3dH4k+HwCeIfywlhMOKETvF0eflwPfd/dBd98EbCB8P8cUM5sPvBX4ZsHomt1nM5tGOJD8G4C7D7n7Pmp4nyMJoMHMEkAjsI0a22d3XwXsKRo9pn00sznANHdf7SFb3FywzKimeoKYB2wtGO6IxtUUM1sInAU8AMx29+0QkghwXDRbrXwXXwY+AeQKxtXyPp8EdALfiqrVvmlmTdTwPrv7i8AXgC3AdmC/u99FDe9zgbHu47zoc/H4skz1BFGqLq6mrvs1s2bgVuBad+8+0qwlxh1T34WZ/RGwy90fLneREuOOqX0mnEmfDXzd3c8CeglVD4dzzO9zVO++nFCVMhdoMrPLjrRIiXHH1D6X4XD7+JL2faoniA5gQcHwfEJRtSaYWR0hOXzH3X8cjd4ZFTuJ3ndF42vhu3gN8F/NbDOhuvANZnYLtb3PHUCHuz8QDf+IkDBqeZ//ANjk7p3ungZ+DJxHbe9z3lj3sSP6XDy+LFM9QTwELDazRWaWBN4N3F7lmMZFdKXCvwHPuPuXCibdDlwefb4c+GnB+HebWcrMFgGLCY1bxwx3/5S7z3f3hYS/5a/d/TJqe593AFvN7JRo1IXA09TwPhOqln7PzBqj//MLCW1stbzPeWPax6ga6oCZ/V70Xb23YJnRVbulvtov4C2EK3yeBz5T7XjGcb9+n1CUfBxYG73eArQB9wDPRe8zC5b5TPQ9rGcMVzpMxhdwPoeuYqrpfQbOBNZEf+ufADOmwD7/PbAOeBL4NuHqnZraZ+B7hDaWNKEk8P6j2UdgWfQ9PQ98legJGuW89KgNEREpaapXMYmIyGEoQYiISElKECIiUpIShIiIlKQEISIiJSlBiIyBmWXNbG3Ba9yeAGxmCwuf3ClSbYlqByByjOl39zOrHYTIRFAJQmQcmNlmM/snM3swer08Gn+imd1jZo9H7ydE42eb2W1m9lj0Oi9aVdzMvhH1dXCXmTVUbadkylOCEBmbhqIqpksKpnW7+zmEu1W/HI37KnCzu58OfAe4IRp/A/B/3f0MwrOTnorGLwa+5u6nAfuAd1R0b0SOQHdSi4yBmfW4e3OJ8ZuBN7j7xughiTvcvc3MdgNz3D0djd/u7rPMrBOY7+6DBetYCPzK3RdHw58E6tz9HyZg10RGUAlCZPz4YT4fbp5SBgs+Z1E7oVSREoTI+Lmk4H119Pl3hCfLArwH+G30+R7gg3CwD+1pExWkSLl0diIyNg1mtrZg+Bfunr/UNWVmDxBOvC6Nxl0DrDSzvyb0/HZFNP4jwI1m9n5CSeGDhCd3ikwaaoMQGQdRG8Qyd99d7VhExouqmEREpCSVIEREpCSVIEREpCQlCBERKUkJQkRESlKCEBGRkpQgRESkpP8PxO5hWeQnsgUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss, train_acc = model.evaluate(X_train, y_train,batch_size=1, verbose=1)\n",
    "print(\"loss(train): {:.4}\".format(train_loss))\n",
    "print(\"accuracy(train): {:.4}\".format(train_acc))\n",
    "\n",
    "print()\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test,batch_size=1,verbose=1)\n",
    "print(\"loss(test): {:.4}\".format(test_loss))\n",
    "print(\"accuracy(test): {:.4}\".format(test_acc))\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim(0.94,1.0)\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               200960    \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 203,530\n",
      "Trainable params: 203,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae11be1b6255ba9be031dc28287545f08e3e06e0be9d31d8cbbfad76c747be65"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('quantum')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#print(sys.path)\n",
    "#sys.path.append('/Users/takumi/opt/anaconda3/envs/qc/lib/python3.9/site-packages')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas\n",
    "import tensorflow as tf\n",
    "from keras.layers import *\n",
    "#from keras.optimizers import *\n",
    "\n",
    "#dir(tf.keras.layers)\n",
    "#dir(tf.keras.optimizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train :  (60000, 28, 28)\n",
      "y_train :  (60000,)\n",
      "X_test :  (10000, 28, 28)\n",
      "y_test :  (10000,)\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train),(X_test, y_test) = mnist.load_data()\n",
    "print(\"X_train : \", X_train.shape)\n",
    "print(\"y_train : \", y_train.shape)\n",
    "print(\"X_test : \", X_test.shape)\n",
    "print(\"y_test : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_initialize(y_data):\n",
    "        y=[]\n",
    "        for _ in range(len(y_data)):\n",
    "            now=np.zeros(10)\n",
    "            now[y_data[_]]=1.0\n",
    "            y.append(now)\n",
    "\n",
    "        return np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_initialize(y_train)\n",
    "y_test = y_initialize(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train (i=1):  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "X_train (i=1): \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train (i=10):  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "X_train (i=10): \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train (i=100):  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "X_train (i=100): \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAMoElEQVR4nO3dXYxcdRnH8d+vqJDQBlp5cfsSFUMChiCa0phojMbUIDelFxgLMZAQV0gxNhSwqRfCBQnxBfGCNGwjsRrBGJTIhVHaxlC9qOlSStmlwWJTtHazizaleFXYPl7sqVnbmTPbc2bmTPf5fpLNzJznvDyZ7G/PmfnP7N8RIQDz34KmGwDQH4QdSIKwA0kQdiAJwg4k8b5+Hsw2b/0DPRYRbrW81pnd9k22X7f9hu1NdfYFoLdcdZzd9gWS/ipptaQjkvZIWhcRr5Vsw5kd6LFenNlXSXojIg5FxElJv5S0psb+APRQnbAvk/SPWY+PFMv+j+1h26O2R2scC0BNdd6ga3WpcNZlekSMSBqRuIwHmlTnzH5E0opZj5dLOlqvHQC9UifseyRdbfujtj8g6auSnu9OWwC6rfJlfES8Z/teSX+QdIGkpyJivGudAeiqykNvlQ7Ga3ag53ryoRoA5w/CDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKV52eXJNuHJb0jaVrSexGxshtNAei+WmEvfCEi/tWF/QDoIS7jgSTqhj0kvWD7JdvDrVawPWx71PZozWMBqMERUX1je2lEHLV9haTtkr4ZEbtK1q9+MABzEhFutbzWmT0ijha3U5Kek7Sqzv4A9E7lsNu+2Pai0/clfUnSWLcaA9Bddd6Nv1LSc7ZP7+fpiPh9V7pC3yxYUP73/tJLLy2tL1++vLR+2223nWtL/7N+/frS+sKFC0vrJ06caFt78MEHS7d98sknS+vno8phj4hDkj7RxV4A9BBDb0AShB1IgrADSRB2IAnCDiTRjS/CoGGXXHJJ29qaNWtKt129enVpvc7QWV1vv/12af3gwYOl9bKhtx07dlTq6XzGmR1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCcfR64//7729Y2b97cx07Odvz48ba1TuPkGzZsKK3v3r27Qkd5cWYHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQYZz8PbN26tbR+++23V973yZMnS+sPPPBAaX18fLy0/tZbb7WtjY0xzUA/cWYHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQcEf07mN2/g80jL7/8cmn9+uuvr7zvycnJ0vrSpUsr7xvNiAi3Wt7xzG77KdtTtsdmLVtie7vtg8Xt4m42C6D75nIZ/1NJN52xbJOknRFxtaSdxWMAA6xj2CNil6RjZyxeI2lbcX+bpFu62xaAbqv62fgrI2JCkiJiwvYV7Va0PSxpuOJxAHRJz78IExEjkkYk3qADmlR16G3S9pAkFbdT3WsJQC9UDfvzku4o7t8h6bfdaQdAr3S8jLf9jKTPS7rM9hFJ35X0qKRf2b5L0t8l3drLJrPbu3dvab3OOPuWLVsqb4vzS8ewR8S6NqUvdrkXAD3Ex2WBJAg7kARhB5Ig7EAShB1Ign8lfR7YsWNHaf3OO+9sW5ueni7ddvv27VVawnmIMzuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJME4+zzXaZx99+7dfeoETePMDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJjmG3/ZTtKdtjs5Y9ZPuftvcVPzf3tk0Adc3lzP5TSTe1WP6jiLih+Pldd9sC0G0dwx4RuyQd60MvAHqozmv2e23vLy7zF7dbyfaw7VHbozWOBaCmqmHfIuljkm6QNCHph+1WjIiRiFgZESsrHgtAF1QKe0RMRsR0RJyStFXSqu62BaDbKoXd9tCsh2sljbVbF8BgcESUr2A/I+nzki6TNCnpu8XjGySFpMOSvhEREx0PZpcfDC1dfvnlpfX9+/e3rS1ZsqR022uvvba0fujQodI6Bk9EuNXyjpNERMS6Fot/UrsjAH3FJ+iAJAg7kARhB5Ig7EAShB1IouPQW1cPxtBbT7z55ptta8uXLy/ddmpqqrR+7Fi9r0U8/fTTbWtPPPFE6bbHjx+vdeys2g29cWYHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQYZ58Hnn322ba1tWvX9rGTc/Piiy+W1h9++OFa22fFODuQHGEHkiDsQBKEHUiCsANJEHYgCcIOJME4+zywYEH7v9n33Xdf6bZjY+X/8n/lyvKJfG699dbS+nXXXVdaL/P444+X1jdu3Fh53/MZ4+xAcoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7KhlaGiotL5r1662tauuuqp021deeaW0fuONN5bWp6enS+vzVeVxdtsrbP/R9gHb47a/VSxfYnu77YPF7eJuNw2ge+ZyGf+epI0Rca2kT0tab/vjkjZJ2hkRV0vaWTwGMKA6hj0iJiJib3H/HUkHJC2TtEbStmK1bZJu6VGPALrgfeeysu2PSPqkpL9IujIiJqSZPwi2r2izzbCk4Zp9AqhpzmG3vVDSryVtiIgTdsv3AM4SESOSRop98AYd0JA5Db3Zfr9mgv6LiPhNsXjS9lBRH5JUPh0ogEZ1HHrzzCl8m6RjEbFh1vLvS/p3RDxqe5OkJRHxYId9cWZP5u67725be+yxx0q3vfDCC0vrF110UWn93XffLa3PV+2G3uZyGf8ZSV+T9KrtfcWyzZIelfQr23dJ+ruk8i82A2hUx7BHxJ8ltXuB/sXutgOgV/i4LJAEYQeSIOxAEoQdSIKwA0nwFVc0Znx8vLR+zTXXlNYZZ2+NfyUNJEfYgSQIO5AEYQeSIOxAEoQdSIKwA0mc07+lAs7V0qVL29YWLVrUx07AmR1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCcHT11zz33tK0tW7asdNuxsbHS+qlTpyr1lBVndiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IouM4u+0Vkn4m6UOSTkkaiYgf235I0tclvVWsujkifterRnF+2rNnT+VtH3nkkdL69PR05X1nNJcP1bwnaWNE7LW9SNJLtrcXtR9FxA961x6AbpnL/OwTkiaK++/YPiCp/KNPAAbOOb1mt/0RSZ+U9Jdi0b2299t+yvbiNtsM2x61PVqvVQB1zDnsthdK+rWkDRFxQtIWSR+TdINmzvw/bLVdRIxExMqIWFm/XQBVzSnstt+vmaD/IiJ+I0kRMRkR0xFxStJWSat61yaAujqG3bYl/UTSgYh4bNbyoVmrrZVU/hUlAI3qOGWz7c9K+pOkVzUz9CZJmyWt08wlfEg6LOkbxZt5Zftiymagx9pN2cz87MA8w/zsQHKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJPo9ZfO/JL056/FlxbJBNKi9DWpfEr1V1c3ePtyu0Nfvs591cHt0UP833aD2Nqh9SfRWVb964zIeSIKwA0k0HfaRho9fZlB7G9S+JHqrqi+9NfqaHUD/NH1mB9AnhB1IopGw277J9uu237C9qYke2rF92Partvc1PT9dMYfelO2xWcuW2N5u+2Bx23KOvYZ6e8j2P4vnbp/tmxvqbYXtP9o+YHvc9reK5Y0+dyV99eV56/trdtsXSPqrpNWSjkjaI2ldRLzW10basH1Y0sqIaPwDGLY/J+k/kn4WEdcVy74n6VhEPFr8oVwcEd8ekN4ekvSfpqfxLmYrGpo9zbikWyTdqQafu5K+vqI+PG9NnNlXSXojIg5FxElJv5S0poE+Bl5E7JJ07IzFayRtK+5v08wvS9+16W0gRMREROwt7r8j6fQ0440+dyV99UUTYV8m6R+zHh/RYM33HpJesP2S7eGmm2nhytPTbBW3VzTcz5k6TuPdT2dMMz4wz12V6c/raiLsraamGaTxv89ExKckfVnS+uJyFXMzp2m8+6XFNOMDoer053U1EfYjklbMerxc0tEG+mgpIo4Wt1OSntPgTUU9eXoG3eJ2quF+/meQpvFuNc24BuC5a3L68ybCvkfS1bY/avsDkr4q6fkG+jiL7YuLN05k+2JJX9LgTUX9vKQ7ivt3SPptg738n0GZxrvdNONq+LlrfPrziOj7j6SbNfOO/N8kfaeJHtr0dZWkV4qf8aZ7k/SMZi7r3tXMFdFdkj4oaaekg8XtkgHq7eeamdp7v2aCNdRQb5/VzEvD/ZL2FT83N/3clfTVl+eNj8sCSfAJOiAJwg4kQdiBJAg7kARhB5Ig7EAShB1I4r9OOgxc0KwB5wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in [1,10,100]:\n",
    "    print(\"y_train\", \"(i=\"+str(i)+\"): \", y_train[i])\n",
    "    print(\"X_train\", \"(i=\"+str(i)+\"): \")    \n",
    "    plt.imshow(X_train[i], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(Flatten(input_shape=(28,28)))\n",
    "model.add(Dense(256,input_dim=784))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10,input_dim=256))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(lr=0.01, momentum=0.9, decay=0.0)\n",
    "model.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks = []\n",
    "#callbacks.append(tf.keras.callbacks.CSVLogger(CSV_FILE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 2.1682 - accuracy: 0.3903 - val_loss: 0.2043 - val_accuracy: 0.5062\n",
      "Epoch 2/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1658 - accuracy: 0.6629 - val_loss: 0.1458 - val_accuracy: 0.7181\n",
      "Epoch 3/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1421 - accuracy: 0.7311 - val_loss: 0.1366 - val_accuracy: 0.7415\n",
      "Epoch 4/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1387 - accuracy: 0.7507 - val_loss: 0.1338 - val_accuracy: 0.7789\n",
      "Epoch 5/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1278 - accuracy: 0.7738 - val_loss: 0.1422 - val_accuracy: 0.7445\n",
      "Epoch 6/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1303 - accuracy: 0.7816 - val_loss: 0.1370 - val_accuracy: 0.7870\n",
      "Epoch 7/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1261 - accuracy: 0.7882 - val_loss: 0.1157 - val_accuracy: 0.7952\n",
      "Epoch 8/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.1205 - accuracy: 0.8003 - val_loss: 0.1188 - val_accuracy: 0.8383\n",
      "Epoch 9/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1141 - accuracy: 0.8143 - val_loss: 0.1045 - val_accuracy: 0.8440\n",
      "Epoch 10/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1001 - accuracy: 0.8435 - val_loss: 0.0960 - val_accuracy: 0.8523\n",
      "Epoch 11/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0904 - accuracy: 0.8616 - val_loss: 0.0943 - val_accuracy: 0.8794\n",
      "Epoch 12/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0888 - accuracy: 0.8814 - val_loss: 0.0854 - val_accuracy: 0.8861\n",
      "Epoch 13/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0751 - accuracy: 0.8932 - val_loss: 0.0748 - val_accuracy: 0.8988\n",
      "Epoch 14/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0710 - accuracy: 0.9028 - val_loss: 0.0719 - val_accuracy: 0.9185\n",
      "Epoch 15/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0682 - accuracy: 0.9114 - val_loss: 0.0711 - val_accuracy: 0.9196\n",
      "Epoch 16/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0669 - accuracy: 0.9142 - val_loss: 0.0751 - val_accuracy: 0.9030\n",
      "Epoch 17/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0640 - accuracy: 0.9179 - val_loss: 0.0650 - val_accuracy: 0.9233\n",
      "Epoch 18/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0618 - accuracy: 0.9219 - val_loss: 0.0628 - val_accuracy: 0.9226\n",
      "Epoch 19/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0611 - accuracy: 0.9235 - val_loss: 0.0719 - val_accuracy: 0.9111\n",
      "Epoch 20/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0591 - accuracy: 0.9251 - val_loss: 0.0657 - val_accuracy: 0.9243\n",
      "Epoch 21/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0580 - accuracy: 0.9260 - val_loss: 0.0636 - val_accuracy: 0.9247\n",
      "Epoch 22/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0562 - accuracy: 0.9279 - val_loss: 0.0617 - val_accuracy: 0.9247\n",
      "Epoch 23/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0556 - accuracy: 0.9277 - val_loss: 0.0668 - val_accuracy: 0.9145\n",
      "Epoch 24/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0546 - accuracy: 0.9287 - val_loss: 0.0629 - val_accuracy: 0.9196\n",
      "Epoch 25/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0541 - accuracy: 0.9296 - val_loss: 0.0575 - val_accuracy: 0.9255\n",
      "Epoch 26/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0542 - accuracy: 0.9289 - val_loss: 0.0592 - val_accuracy: 0.9237\n",
      "Epoch 27/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0531 - accuracy: 0.9297 - val_loss: 0.0683 - val_accuracy: 0.9103\n",
      "Epoch 28/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0523 - accuracy: 0.9310 - val_loss: 0.0606 - val_accuracy: 0.9190\n",
      "Epoch 29/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0516 - accuracy: 0.9313 - val_loss: 0.0591 - val_accuracy: 0.9223\n",
      "Epoch 30/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0524 - accuracy: 0.9312 - val_loss: 0.0583 - val_accuracy: 0.9234\n",
      "Epoch 31/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0477 - accuracy: 0.9318 - val_loss: 0.0538 - val_accuracy: 0.9255\n",
      "Epoch 32/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0454 - accuracy: 0.9328 - val_loss: 0.0548 - val_accuracy: 0.9215\n",
      "Epoch 33/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0447 - accuracy: 0.9331 - val_loss: 0.0549 - val_accuracy: 0.9227\n",
      "Epoch 34/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0444 - accuracy: 0.9330 - val_loss: 0.0579 - val_accuracy: 0.9225\n",
      "Epoch 35/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0424 - accuracy: 0.9351 - val_loss: 0.0529 - val_accuracy: 0.9277\n",
      "Epoch 36/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0428 - accuracy: 0.9352 - val_loss: 0.0528 - val_accuracy: 0.9265\n",
      "Epoch 37/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0410 - accuracy: 0.9375 - val_loss: 0.0529 - val_accuracy: 0.9304\n",
      "Epoch 38/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0411 - accuracy: 0.9372 - val_loss: 0.0542 - val_accuracy: 0.9287\n",
      "Epoch 39/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0408 - accuracy: 0.9383 - val_loss: 0.0490 - val_accuracy: 0.9318\n",
      "Epoch 40/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0411 - accuracy: 0.9374 - val_loss: 0.0497 - val_accuracy: 0.9340\n",
      "Epoch 41/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0392 - accuracy: 0.9400 - val_loss: 0.0510 - val_accuracy: 0.9268\n",
      "Epoch 42/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0398 - accuracy: 0.9392 - val_loss: 0.0486 - val_accuracy: 0.9334\n",
      "Epoch 43/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0391 - accuracy: 0.9400 - val_loss: 0.0497 - val_accuracy: 0.9339\n",
      "Epoch 44/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0390 - accuracy: 0.9401 - val_loss: 0.0512 - val_accuracy: 0.9307\n",
      "Epoch 45/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0381 - accuracy: 0.9405 - val_loss: 0.0492 - val_accuracy: 0.9290\n",
      "Epoch 46/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0381 - accuracy: 0.9407 - val_loss: 0.0487 - val_accuracy: 0.9332\n",
      "Epoch 47/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0376 - accuracy: 0.9417 - val_loss: 0.0491 - val_accuracy: 0.9341\n",
      "Epoch 48/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0365 - accuracy: 0.9430 - val_loss: 0.0488 - val_accuracy: 0.9334\n",
      "Epoch 49/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0370 - accuracy: 0.9424 - val_loss: 0.0534 - val_accuracy: 0.9294\n",
      "Epoch 50/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0380 - accuracy: 0.9418 - val_loss: 0.0487 - val_accuracy: 0.9333\n",
      "Epoch 51/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0363 - accuracy: 0.9438 - val_loss: 0.0518 - val_accuracy: 0.9338\n",
      "Epoch 52/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0378 - accuracy: 0.9421 - val_loss: 0.0492 - val_accuracy: 0.9326\n",
      "Epoch 53/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0360 - accuracy: 0.9431 - val_loss: 0.0493 - val_accuracy: 0.9321\n",
      "Epoch 54/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0351 - accuracy: 0.9450 - val_loss: 0.0480 - val_accuracy: 0.9344\n",
      "Epoch 55/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0360 - accuracy: 0.9437 - val_loss: 0.0545 - val_accuracy: 0.9231\n",
      "Epoch 56/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0358 - accuracy: 0.9431 - val_loss: 0.0490 - val_accuracy: 0.9341\n",
      "Epoch 57/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0349 - accuracy: 0.9448 - val_loss: 0.0514 - val_accuracy: 0.9298\n",
      "Epoch 58/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0351 - accuracy: 0.9449 - val_loss: 0.0495 - val_accuracy: 0.9311\n",
      "Epoch 59/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0348 - accuracy: 0.9445 - val_loss: 0.0549 - val_accuracy: 0.9263\n",
      "Epoch 60/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0350 - accuracy: 0.9449 - val_loss: 0.0489 - val_accuracy: 0.9338\n",
      "Epoch 61/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0346 - accuracy: 0.9454 - val_loss: 0.0513 - val_accuracy: 0.9287\n",
      "Epoch 62/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0348 - accuracy: 0.9457 - val_loss: 0.0496 - val_accuracy: 0.9354\n",
      "Epoch 63/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0345 - accuracy: 0.9452 - val_loss: 0.0476 - val_accuracy: 0.9352\n",
      "Epoch 64/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0348 - accuracy: 0.9455 - val_loss: 0.0557 - val_accuracy: 0.9263\n",
      "Epoch 65/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0345 - accuracy: 0.9455 - val_loss: 0.0488 - val_accuracy: 0.9361\n",
      "Epoch 66/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0342 - accuracy: 0.9460 - val_loss: 0.0486 - val_accuracy: 0.9305\n",
      "Epoch 67/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0338 - accuracy: 0.9457 - val_loss: 0.0483 - val_accuracy: 0.9324\n",
      "Epoch 68/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0343 - accuracy: 0.9460 - val_loss: 0.0482 - val_accuracy: 0.9292\n",
      "Epoch 69/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0335 - accuracy: 0.9462 - val_loss: 0.0492 - val_accuracy: 0.9317\n",
      "Epoch 70/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0334 - accuracy: 0.9467 - val_loss: 0.0494 - val_accuracy: 0.9328\n",
      "Epoch 71/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0339 - accuracy: 0.9460 - val_loss: 0.0486 - val_accuracy: 0.9340\n",
      "Epoch 72/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0330 - accuracy: 0.9473 - val_loss: 0.0469 - val_accuracy: 0.9358\n",
      "Epoch 73/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0328 - accuracy: 0.9469 - val_loss: 0.0494 - val_accuracy: 0.9296\n",
      "Epoch 74/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0329 - accuracy: 0.9476 - val_loss: 0.0488 - val_accuracy: 0.9341\n",
      "Epoch 75/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0332 - accuracy: 0.9473 - val_loss: 0.0513 - val_accuracy: 0.9275\n",
      "Epoch 76/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0326 - accuracy: 0.9476 - val_loss: 0.0496 - val_accuracy: 0.9341\n",
      "Epoch 77/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0320 - accuracy: 0.9488 - val_loss: 0.0515 - val_accuracy: 0.9336\n",
      "Epoch 78/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0330 - accuracy: 0.9477 - val_loss: 0.0500 - val_accuracy: 0.9350\n",
      "Epoch 79/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0327 - accuracy: 0.9476 - val_loss: 0.0505 - val_accuracy: 0.9306\n",
      "Epoch 80/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0327 - accuracy: 0.9474 - val_loss: 0.0519 - val_accuracy: 0.9328\n",
      "Epoch 81/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0324 - accuracy: 0.9485 - val_loss: 0.0484 - val_accuracy: 0.9344\n",
      "Epoch 82/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0330 - accuracy: 0.9473 - val_loss: 0.0503 - val_accuracy: 0.9339\n",
      "Epoch 83/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0315 - accuracy: 0.9490 - val_loss: 0.0514 - val_accuracy: 0.9356\n",
      "Epoch 84/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0329 - accuracy: 0.9468 - val_loss: 0.0510 - val_accuracy: 0.9338\n",
      "Epoch 85/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0324 - accuracy: 0.9482 - val_loss: 0.0514 - val_accuracy: 0.9324\n",
      "Epoch 86/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0323 - accuracy: 0.9485 - val_loss: 0.0530 - val_accuracy: 0.9334\n",
      "Epoch 87/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0318 - accuracy: 0.9495 - val_loss: 0.0538 - val_accuracy: 0.9331\n",
      "Epoch 88/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0316 - accuracy: 0.9495 - val_loss: 0.0537 - val_accuracy: 0.9316\n",
      "Epoch 89/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0317 - accuracy: 0.9487 - val_loss: 0.0521 - val_accuracy: 0.9315\n",
      "Epoch 90/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0326 - accuracy: 0.9477 - val_loss: 0.0537 - val_accuracy: 0.9273\n",
      "Epoch 91/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0317 - accuracy: 0.9490 - val_loss: 0.0500 - val_accuracy: 0.9326\n",
      "Epoch 92/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0317 - accuracy: 0.9493 - val_loss: 0.0602 - val_accuracy: 0.9218\n",
      "Epoch 93/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0316 - accuracy: 0.9486 - val_loss: 0.0504 - val_accuracy: 0.9348\n",
      "Epoch 94/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0316 - accuracy: 0.9495 - val_loss: 0.0493 - val_accuracy: 0.9330\n",
      "Epoch 95/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0310 - accuracy: 0.9495 - val_loss: 0.0520 - val_accuracy: 0.9322\n",
      "Epoch 96/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0312 - accuracy: 0.9487 - val_loss: 0.0525 - val_accuracy: 0.9338\n",
      "Epoch 97/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0314 - accuracy: 0.9493 - val_loss: 0.0515 - val_accuracy: 0.9321\n",
      "Epoch 98/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0309 - accuracy: 0.9499 - val_loss: 0.0528 - val_accuracy: 0.9324\n",
      "Epoch 99/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0311 - accuracy: 0.9493 - val_loss: 0.0530 - val_accuracy: 0.9298\n",
      "Epoch 100/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0314 - accuracy: 0.9488 - val_loss: 0.0527 - val_accuracy: 0.9341\n",
      "Epoch 101/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0307 - accuracy: 0.9499 - val_loss: 0.0524 - val_accuracy: 0.9349\n",
      "Epoch 102/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0303 - accuracy: 0.9505 - val_loss: 0.0548 - val_accuracy: 0.9347\n",
      "Epoch 103/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0302 - accuracy: 0.9501 - val_loss: 0.0551 - val_accuracy: 0.9298\n",
      "Epoch 104/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0304 - accuracy: 0.9503 - val_loss: 0.0508 - val_accuracy: 0.9335\n",
      "Epoch 105/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0304 - accuracy: 0.9502 - val_loss: 0.0592 - val_accuracy: 0.9231\n",
      "Epoch 106/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0306 - accuracy: 0.9503 - val_loss: 0.0569 - val_accuracy: 0.9292\n",
      "Epoch 107/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0302 - accuracy: 0.9505 - val_loss: 0.0540 - val_accuracy: 0.9336\n",
      "Epoch 108/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0304 - accuracy: 0.9506 - val_loss: 0.0546 - val_accuracy: 0.9337\n",
      "Epoch 109/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0309 - accuracy: 0.9497 - val_loss: 0.0553 - val_accuracy: 0.9329\n",
      "Epoch 110/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0307 - accuracy: 0.9494 - val_loss: 0.0524 - val_accuracy: 0.9304\n",
      "Epoch 111/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0310 - accuracy: 0.9496 - val_loss: 0.0522 - val_accuracy: 0.9341\n",
      "Epoch 112/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0306 - accuracy: 0.9499 - val_loss: 0.0583 - val_accuracy: 0.9307\n",
      "Epoch 113/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0310 - accuracy: 0.9492 - val_loss: 0.0540 - val_accuracy: 0.9276\n",
      "Epoch 114/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0307 - accuracy: 0.9489 - val_loss: 0.0527 - val_accuracy: 0.9290\n",
      "Epoch 115/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0307 - accuracy: 0.9500 - val_loss: 0.0542 - val_accuracy: 0.9334\n",
      "Epoch 116/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0299 - accuracy: 0.9511 - val_loss: 0.0529 - val_accuracy: 0.9339\n",
      "Epoch 117/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0298 - accuracy: 0.9514 - val_loss: 0.0545 - val_accuracy: 0.9334\n",
      "Epoch 118/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0309 - accuracy: 0.9492 - val_loss: 0.0575 - val_accuracy: 0.9313\n",
      "Epoch 119/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0298 - accuracy: 0.9509 - val_loss: 0.0559 - val_accuracy: 0.9306\n",
      "Epoch 120/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0298 - accuracy: 0.9511 - val_loss: 0.0550 - val_accuracy: 0.9316\n",
      "Epoch 121/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0299 - accuracy: 0.9505 - val_loss: 0.0544 - val_accuracy: 0.9362\n",
      "Epoch 122/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0307 - accuracy: 0.9500 - val_loss: 0.0554 - val_accuracy: 0.9310\n",
      "Epoch 123/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0304 - accuracy: 0.9497 - val_loss: 0.0586 - val_accuracy: 0.9300\n",
      "Epoch 124/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0301 - accuracy: 0.9506 - val_loss: 0.0579 - val_accuracy: 0.9306\n",
      "Epoch 125/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0305 - accuracy: 0.9498 - val_loss: 0.0540 - val_accuracy: 0.9340\n",
      "Epoch 126/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0300 - accuracy: 0.9502 - val_loss: 0.0558 - val_accuracy: 0.9304\n",
      "Epoch 127/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0296 - accuracy: 0.9510 - val_loss: 0.0540 - val_accuracy: 0.9334\n",
      "Epoch 128/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0295 - accuracy: 0.9511 - val_loss: 0.0547 - val_accuracy: 0.9323\n",
      "Epoch 129/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0290 - accuracy: 0.9513 - val_loss: 0.0534 - val_accuracy: 0.9339\n",
      "Epoch 130/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0303 - accuracy: 0.9497 - val_loss: 0.0567 - val_accuracy: 0.9292\n",
      "Epoch 131/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0299 - accuracy: 0.9509 - val_loss: 0.0570 - val_accuracy: 0.9303\n",
      "Epoch 132/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0292 - accuracy: 0.9513 - val_loss: 0.0559 - val_accuracy: 0.9344\n",
      "Epoch 133/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0299 - accuracy: 0.9506 - val_loss: 0.0607 - val_accuracy: 0.9280\n",
      "Epoch 134/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0294 - accuracy: 0.9512 - val_loss: 0.0561 - val_accuracy: 0.9338\n",
      "Epoch 135/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0297 - accuracy: 0.9509 - val_loss: 0.0588 - val_accuracy: 0.9327\n",
      "Epoch 136/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0293 - accuracy: 0.9511 - val_loss: 0.0609 - val_accuracy: 0.9325\n",
      "Epoch 137/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0297 - accuracy: 0.9506 - val_loss: 0.0556 - val_accuracy: 0.9356\n",
      "Epoch 138/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0291 - accuracy: 0.9518 - val_loss: 0.0563 - val_accuracy: 0.9320\n",
      "Epoch 139/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0290 - accuracy: 0.9519 - val_loss: 0.0598 - val_accuracy: 0.9347\n",
      "Epoch 140/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0294 - accuracy: 0.9513 - val_loss: 0.0555 - val_accuracy: 0.9327\n",
      "Epoch 141/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0289 - accuracy: 0.9513 - val_loss: 0.0566 - val_accuracy: 0.9324\n",
      "Epoch 142/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0291 - accuracy: 0.9512 - val_loss: 0.0549 - val_accuracy: 0.9333\n",
      "Epoch 143/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0294 - accuracy: 0.9510 - val_loss: 0.0626 - val_accuracy: 0.9288\n",
      "Epoch 144/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0296 - accuracy: 0.9516 - val_loss: 0.0599 - val_accuracy: 0.9320\n",
      "Epoch 145/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0291 - accuracy: 0.9514 - val_loss: 0.0635 - val_accuracy: 0.9258\n",
      "Epoch 146/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0297 - accuracy: 0.9510 - val_loss: 0.0590 - val_accuracy: 0.9340\n",
      "Epoch 147/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0285 - accuracy: 0.9525 - val_loss: 0.0574 - val_accuracy: 0.9326\n",
      "Epoch 148/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0292 - accuracy: 0.9518 - val_loss: 0.0611 - val_accuracy: 0.9331\n",
      "Epoch 149/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0293 - accuracy: 0.9516 - val_loss: 0.0597 - val_accuracy: 0.9359\n",
      "Epoch 150/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0285 - accuracy: 0.9518 - val_loss: 0.0583 - val_accuracy: 0.9287\n",
      "Epoch 151/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0284 - accuracy: 0.9525 - val_loss: 0.0585 - val_accuracy: 0.9319\n",
      "Epoch 152/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0291 - accuracy: 0.9513 - val_loss: 0.0615 - val_accuracy: 0.9337\n",
      "Epoch 153/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0291 - accuracy: 0.9514 - val_loss: 0.0612 - val_accuracy: 0.9289\n",
      "Epoch 154/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0294 - accuracy: 0.9510 - val_loss: 0.0596 - val_accuracy: 0.9287\n",
      "Epoch 155/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0286 - accuracy: 0.9522 - val_loss: 0.0584 - val_accuracy: 0.9323\n",
      "Epoch 156/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0287 - accuracy: 0.9521 - val_loss: 0.0547 - val_accuracy: 0.9330\n",
      "Epoch 157/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0281 - accuracy: 0.9526 - val_loss: 0.0609 - val_accuracy: 0.9294\n",
      "Epoch 158/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0291 - accuracy: 0.9518 - val_loss: 0.0581 - val_accuracy: 0.9314\n",
      "Epoch 159/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0287 - accuracy: 0.9519 - val_loss: 0.0610 - val_accuracy: 0.9331\n",
      "Epoch 160/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0284 - accuracy: 0.9520 - val_loss: 0.0641 - val_accuracy: 0.9324\n",
      "Epoch 161/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0291 - accuracy: 0.9520 - val_loss: 0.0598 - val_accuracy: 0.9310\n",
      "Epoch 162/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0282 - accuracy: 0.9526 - val_loss: 0.0573 - val_accuracy: 0.9337\n",
      "Epoch 163/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0293 - accuracy: 0.9516 - val_loss: 0.0587 - val_accuracy: 0.9327\n",
      "Epoch 164/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0281 - accuracy: 0.9521 - val_loss: 0.0642 - val_accuracy: 0.9304\n",
      "Epoch 165/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0287 - accuracy: 0.9513 - val_loss: 0.0600 - val_accuracy: 0.9357\n",
      "Epoch 166/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0279 - accuracy: 0.9537 - val_loss: 0.0609 - val_accuracy: 0.9316\n",
      "Epoch 167/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0280 - accuracy: 0.9524 - val_loss: 0.0555 - val_accuracy: 0.9324\n",
      "Epoch 168/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0276 - accuracy: 0.9536 - val_loss: 0.0573 - val_accuracy: 0.9307\n",
      "Epoch 169/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0282 - accuracy: 0.9534 - val_loss: 0.0619 - val_accuracy: 0.9286\n",
      "Epoch 170/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0282 - accuracy: 0.9525 - val_loss: 0.0615 - val_accuracy: 0.9316\n",
      "Epoch 171/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0287 - accuracy: 0.9517 - val_loss: 0.0627 - val_accuracy: 0.9297\n",
      "Epoch 172/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0280 - accuracy: 0.9531 - val_loss: 0.0596 - val_accuracy: 0.9355\n",
      "Epoch 173/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0281 - accuracy: 0.9525 - val_loss: 0.0621 - val_accuracy: 0.9317\n",
      "Epoch 174/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0279 - accuracy: 0.9532 - val_loss: 0.0589 - val_accuracy: 0.9326\n",
      "Epoch 175/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0282 - accuracy: 0.9530 - val_loss: 0.0637 - val_accuracy: 0.9301\n",
      "Epoch 176/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0282 - accuracy: 0.9528 - val_loss: 0.0645 - val_accuracy: 0.9286\n",
      "Epoch 177/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0281 - accuracy: 0.9530 - val_loss: 0.0600 - val_accuracy: 0.9285\n",
      "Epoch 178/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0275 - accuracy: 0.9534 - val_loss: 0.0621 - val_accuracy: 0.9341\n",
      "Epoch 179/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0275 - accuracy: 0.9535 - val_loss: 0.0641 - val_accuracy: 0.9309\n",
      "Epoch 180/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0275 - accuracy: 0.9531 - val_loss: 0.0587 - val_accuracy: 0.9286\n",
      "Epoch 181/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0285 - accuracy: 0.9526 - val_loss: 0.0630 - val_accuracy: 0.9328\n",
      "Epoch 182/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0276 - accuracy: 0.9532 - val_loss: 0.0657 - val_accuracy: 0.9292\n",
      "Epoch 183/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0281 - accuracy: 0.9525 - val_loss: 0.0638 - val_accuracy: 0.9310\n",
      "Epoch 184/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0284 - accuracy: 0.9524 - val_loss: 0.0632 - val_accuracy: 0.9340\n",
      "Epoch 185/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0283 - accuracy: 0.9527 - val_loss: 0.0638 - val_accuracy: 0.9348\n",
      "Epoch 186/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0276 - accuracy: 0.9531 - val_loss: 0.0667 - val_accuracy: 0.9302\n",
      "Epoch 187/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0275 - accuracy: 0.9525 - val_loss: 0.0651 - val_accuracy: 0.9311\n",
      "Epoch 188/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0278 - accuracy: 0.9528 - val_loss: 0.0697 - val_accuracy: 0.9318\n",
      "Epoch 189/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0286 - accuracy: 0.9520 - val_loss: 0.0624 - val_accuracy: 0.9313\n",
      "Epoch 190/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0280 - accuracy: 0.9531 - val_loss: 0.0606 - val_accuracy: 0.9317\n",
      "Epoch 191/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0280 - accuracy: 0.9530 - val_loss: 0.0663 - val_accuracy: 0.9268\n",
      "Epoch 192/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0274 - accuracy: 0.9540 - val_loss: 0.0623 - val_accuracy: 0.9336\n",
      "Epoch 193/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0276 - accuracy: 0.9532 - val_loss: 0.0647 - val_accuracy: 0.9289\n",
      "Epoch 194/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0277 - accuracy: 0.9533 - val_loss: 0.0643 - val_accuracy: 0.9354\n",
      "Epoch 195/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0280 - accuracy: 0.9530 - val_loss: 0.0635 - val_accuracy: 0.9324\n",
      "Epoch 196/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0273 - accuracy: 0.9537 - val_loss: 0.0671 - val_accuracy: 0.9324\n",
      "Epoch 197/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0272 - accuracy: 0.9538 - val_loss: 0.0637 - val_accuracy: 0.9307\n",
      "Epoch 198/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0275 - accuracy: 0.9531 - val_loss: 0.0656 - val_accuracy: 0.9313\n",
      "Epoch 199/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0278 - accuracy: 0.9522 - val_loss: 0.0624 - val_accuracy: 0.9329\n",
      "Epoch 200/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0273 - accuracy: 0.9531 - val_loss: 0.0643 - val_accuracy: 0.9312\n",
      "Epoch 201/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0269 - accuracy: 0.9541 - val_loss: 0.0626 - val_accuracy: 0.9281\n",
      "Epoch 202/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0271 - accuracy: 0.9540 - val_loss: 0.0603 - val_accuracy: 0.9308\n",
      "Epoch 203/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0275 - accuracy: 0.9532 - val_loss: 0.0615 - val_accuracy: 0.9318\n",
      "Epoch 204/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0272 - accuracy: 0.9532 - val_loss: 0.0633 - val_accuracy: 0.9316\n",
      "Epoch 205/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0274 - accuracy: 0.9529 - val_loss: 0.0675 - val_accuracy: 0.9288\n",
      "Epoch 206/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0277 - accuracy: 0.9528 - val_loss: 0.0659 - val_accuracy: 0.9329\n",
      "Epoch 207/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0274 - accuracy: 0.9536 - val_loss: 0.0666 - val_accuracy: 0.9287\n",
      "Epoch 208/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0277 - accuracy: 0.9527 - val_loss: 0.0610 - val_accuracy: 0.9313\n",
      "Epoch 209/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0278 - accuracy: 0.9527 - val_loss: 0.0688 - val_accuracy: 0.9316\n",
      "Epoch 210/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0269 - accuracy: 0.9536 - val_loss: 0.0703 - val_accuracy: 0.9302\n",
      "Epoch 211/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0268 - accuracy: 0.9541 - val_loss: 0.0648 - val_accuracy: 0.9317\n",
      "Epoch 212/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0268 - accuracy: 0.9548 - val_loss: 0.0684 - val_accuracy: 0.9290\n",
      "Epoch 213/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0272 - accuracy: 0.9541 - val_loss: 0.0687 - val_accuracy: 0.9287\n",
      "Epoch 214/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0265 - accuracy: 0.9540 - val_loss: 0.0685 - val_accuracy: 0.9294\n",
      "Epoch 215/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0271 - accuracy: 0.9538 - val_loss: 0.0694 - val_accuracy: 0.9284\n",
      "Epoch 216/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0268 - accuracy: 0.9544 - val_loss: 0.0755 - val_accuracy: 0.9320\n",
      "Epoch 217/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0270 - accuracy: 0.9543 - val_loss: 0.0672 - val_accuracy: 0.9285\n",
      "Epoch 218/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0268 - accuracy: 0.9542 - val_loss: 0.0633 - val_accuracy: 0.9337\n",
      "Epoch 219/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0271 - accuracy: 0.9534 - val_loss: 0.0633 - val_accuracy: 0.9289\n",
      "Epoch 220/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0268 - accuracy: 0.9546 - val_loss: 0.0699 - val_accuracy: 0.9258\n",
      "Epoch 221/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0266 - accuracy: 0.9534 - val_loss: 0.0630 - val_accuracy: 0.9318\n",
      "Epoch 222/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0270 - accuracy: 0.9536 - val_loss: 0.0671 - val_accuracy: 0.9337\n",
      "Epoch 223/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0266 - accuracy: 0.9543 - val_loss: 0.0673 - val_accuracy: 0.9341\n",
      "Epoch 224/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0268 - accuracy: 0.9543 - val_loss: 0.0654 - val_accuracy: 0.9308\n",
      "Epoch 225/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0270 - accuracy: 0.9540 - val_loss: 0.0674 - val_accuracy: 0.9342\n",
      "Epoch 226/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0268 - accuracy: 0.9545 - val_loss: 0.0690 - val_accuracy: 0.9325\n",
      "Epoch 227/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0264 - accuracy: 0.9542 - val_loss: 0.0706 - val_accuracy: 0.9290\n",
      "Epoch 228/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0267 - accuracy: 0.9537 - val_loss: 0.0685 - val_accuracy: 0.9336\n",
      "Epoch 229/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0263 - accuracy: 0.9548 - val_loss: 0.0679 - val_accuracy: 0.9289\n",
      "Epoch 230/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0260 - accuracy: 0.9552 - val_loss: 0.0676 - val_accuracy: 0.9298\n",
      "Epoch 231/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0261 - accuracy: 0.9548 - val_loss: 0.0683 - val_accuracy: 0.9322\n",
      "Epoch 232/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0264 - accuracy: 0.9544 - val_loss: 0.0722 - val_accuracy: 0.9327\n",
      "Epoch 233/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0262 - accuracy: 0.9554 - val_loss: 0.0660 - val_accuracy: 0.9316\n",
      "Epoch 234/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0265 - accuracy: 0.9542 - val_loss: 0.0678 - val_accuracy: 0.9332\n",
      "Epoch 235/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0266 - accuracy: 0.9543 - val_loss: 0.0736 - val_accuracy: 0.9328\n",
      "Epoch 236/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0271 - accuracy: 0.9532 - val_loss: 0.0713 - val_accuracy: 0.9333\n",
      "Epoch 237/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0265 - accuracy: 0.9546 - val_loss: 0.0756 - val_accuracy: 0.9281\n",
      "Epoch 238/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0266 - accuracy: 0.9548 - val_loss: 0.0681 - val_accuracy: 0.9341\n",
      "Epoch 239/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0263 - accuracy: 0.9553 - val_loss: 0.0697 - val_accuracy: 0.9312\n",
      "Epoch 240/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0254 - accuracy: 0.9556 - val_loss: 0.0684 - val_accuracy: 0.9330\n",
      "Epoch 241/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0269 - accuracy: 0.9541 - val_loss: 0.0698 - val_accuracy: 0.9330\n",
      "Epoch 242/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0264 - accuracy: 0.9545 - val_loss: 0.0708 - val_accuracy: 0.9307\n",
      "Epoch 243/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0263 - accuracy: 0.9543 - val_loss: 0.0766 - val_accuracy: 0.9308\n",
      "Epoch 244/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0260 - accuracy: 0.9549 - val_loss: 0.0718 - val_accuracy: 0.9297\n",
      "Epoch 245/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0267 - accuracy: 0.9536 - val_loss: 0.0721 - val_accuracy: 0.9285\n",
      "Epoch 246/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0262 - accuracy: 0.9546 - val_loss: 0.0693 - val_accuracy: 0.9311\n",
      "Epoch 247/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0267 - accuracy: 0.9543 - val_loss: 0.0682 - val_accuracy: 0.9314\n",
      "Epoch 248/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0258 - accuracy: 0.9547 - val_loss: 0.0689 - val_accuracy: 0.9351\n",
      "Epoch 249/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0264 - accuracy: 0.9547 - val_loss: 0.0687 - val_accuracy: 0.9308\n",
      "Epoch 250/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0258 - accuracy: 0.9554 - val_loss: 0.0671 - val_accuracy: 0.9303\n",
      "Epoch 251/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0260 - accuracy: 0.9547 - val_loss: 0.0734 - val_accuracy: 0.9303\n",
      "Epoch 252/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0260 - accuracy: 0.9542 - val_loss: 0.0680 - val_accuracy: 0.9271\n",
      "Epoch 253/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0260 - accuracy: 0.9548 - val_loss: 0.0705 - val_accuracy: 0.9285\n",
      "Epoch 254/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0260 - accuracy: 0.9549 - val_loss: 0.0742 - val_accuracy: 0.9303\n",
      "Epoch 255/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0256 - accuracy: 0.9554 - val_loss: 0.0717 - val_accuracy: 0.9333\n",
      "Epoch 256/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0261 - accuracy: 0.9548 - val_loss: 0.0723 - val_accuracy: 0.9307\n",
      "Epoch 257/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0257 - accuracy: 0.9556 - val_loss: 0.0718 - val_accuracy: 0.9306\n",
      "Epoch 258/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0255 - accuracy: 0.9557 - val_loss: 0.0734 - val_accuracy: 0.9294\n",
      "Epoch 259/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0255 - accuracy: 0.9551 - val_loss: 0.0720 - val_accuracy: 0.9304\n",
      "Epoch 260/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0262 - accuracy: 0.9542 - val_loss: 0.0735 - val_accuracy: 0.9267\n",
      "Epoch 261/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0264 - accuracy: 0.9545 - val_loss: 0.0692 - val_accuracy: 0.9320\n",
      "Epoch 262/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0259 - accuracy: 0.9553 - val_loss: 0.0721 - val_accuracy: 0.9300\n",
      "Epoch 263/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0265 - accuracy: 0.9547 - val_loss: 0.0761 - val_accuracy: 0.9269\n",
      "Epoch 264/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0259 - accuracy: 0.9548 - val_loss: 0.0686 - val_accuracy: 0.9329\n",
      "Epoch 265/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0256 - accuracy: 0.9558 - val_loss: 0.0780 - val_accuracy: 0.9325\n",
      "Epoch 266/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0259 - accuracy: 0.9549 - val_loss: 0.0732 - val_accuracy: 0.9299\n",
      "Epoch 267/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0263 - accuracy: 0.9548 - val_loss: 0.0737 - val_accuracy: 0.9329\n",
      "Epoch 268/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0269 - accuracy: 0.9542 - val_loss: 0.0780 - val_accuracy: 0.9296\n",
      "Epoch 269/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0252 - accuracy: 0.9564 - val_loss: 0.0738 - val_accuracy: 0.9332\n",
      "Epoch 270/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0254 - accuracy: 0.9554 - val_loss: 0.0729 - val_accuracy: 0.9331\n",
      "Epoch 271/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0265 - accuracy: 0.9546 - val_loss: 0.0684 - val_accuracy: 0.9301\n",
      "Epoch 272/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0265 - accuracy: 0.9538 - val_loss: 0.0754 - val_accuracy: 0.9273\n",
      "Epoch 273/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0258 - accuracy: 0.9554 - val_loss: 0.0729 - val_accuracy: 0.9332\n",
      "Epoch 274/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0253 - accuracy: 0.9557 - val_loss: 0.0817 - val_accuracy: 0.9274\n",
      "Epoch 275/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0251 - accuracy: 0.9563 - val_loss: 0.0773 - val_accuracy: 0.9334\n",
      "Epoch 276/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0252 - accuracy: 0.9560 - val_loss: 0.0775 - val_accuracy: 0.9304\n",
      "Epoch 277/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0256 - accuracy: 0.9546 - val_loss: 0.0698 - val_accuracy: 0.9286\n",
      "Epoch 278/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0260 - accuracy: 0.9552 - val_loss: 0.0782 - val_accuracy: 0.9300\n",
      "Epoch 279/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0255 - accuracy: 0.9554 - val_loss: 0.0726 - val_accuracy: 0.9277\n",
      "Epoch 280/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0257 - accuracy: 0.9551 - val_loss: 0.0726 - val_accuracy: 0.9327\n",
      "Epoch 281/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0254 - accuracy: 0.9555 - val_loss: 0.0693 - val_accuracy: 0.9291\n",
      "Epoch 282/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0254 - accuracy: 0.9560 - val_loss: 0.0738 - val_accuracy: 0.9293\n",
      "Epoch 283/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0259 - accuracy: 0.9543 - val_loss: 0.0765 - val_accuracy: 0.9296\n",
      "Epoch 284/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0258 - accuracy: 0.9551 - val_loss: 0.0715 - val_accuracy: 0.9290\n",
      "Epoch 285/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0256 - accuracy: 0.9554 - val_loss: 0.0713 - val_accuracy: 0.9311\n",
      "Epoch 286/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0262 - accuracy: 0.9551 - val_loss: 0.0783 - val_accuracy: 0.9272\n",
      "Epoch 287/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0258 - accuracy: 0.9547 - val_loss: 0.0745 - val_accuracy: 0.9292\n",
      "Epoch 288/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0255 - accuracy: 0.9546 - val_loss: 0.0737 - val_accuracy: 0.9318\n",
      "Epoch 289/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0252 - accuracy: 0.9560 - val_loss: 0.0750 - val_accuracy: 0.9322\n",
      "Epoch 290/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0254 - accuracy: 0.9556 - val_loss: 0.0779 - val_accuracy: 0.9298\n",
      "Epoch 291/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0258 - accuracy: 0.9554 - val_loss: 0.0830 - val_accuracy: 0.9271\n",
      "Epoch 292/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0271 - accuracy: 0.9536 - val_loss: 0.0753 - val_accuracy: 0.9319\n",
      "Epoch 293/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0253 - accuracy: 0.9555 - val_loss: 0.0752 - val_accuracy: 0.9294\n",
      "Epoch 294/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0257 - accuracy: 0.9545 - val_loss: 0.0759 - val_accuracy: 0.9298\n",
      "Epoch 295/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0257 - accuracy: 0.9557 - val_loss: 0.0750 - val_accuracy: 0.9298\n",
      "Epoch 296/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0257 - accuracy: 0.9549 - val_loss: 0.0793 - val_accuracy: 0.9319\n",
      "Epoch 297/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0255 - accuracy: 0.9549 - val_loss: 0.0727 - val_accuracy: 0.9308\n",
      "Epoch 298/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0258 - accuracy: 0.9548 - val_loss: 0.0760 - val_accuracy: 0.9313\n",
      "Epoch 299/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0251 - accuracy: 0.9559 - val_loss: 0.0761 - val_accuracy: 0.9290\n",
      "Epoch 300/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0253 - accuracy: 0.9554 - val_loss: 0.0741 - val_accuracy: 0.9292\n",
      "Epoch 301/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0256 - accuracy: 0.9555 - val_loss: 0.0770 - val_accuracy: 0.9320\n",
      "Epoch 302/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0258 - accuracy: 0.9551 - val_loss: 0.0767 - val_accuracy: 0.9266\n",
      "Epoch 303/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0257 - accuracy: 0.9550 - val_loss: 0.0853 - val_accuracy: 0.9308\n",
      "Epoch 304/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0255 - accuracy: 0.9556 - val_loss: 0.0748 - val_accuracy: 0.9300\n",
      "Epoch 305/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0259 - accuracy: 0.9549 - val_loss: 0.0744 - val_accuracy: 0.9302\n",
      "Epoch 306/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0262 - accuracy: 0.9552 - val_loss: 0.0802 - val_accuracy: 0.9323\n",
      "Epoch 307/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0253 - accuracy: 0.9554 - val_loss: 0.0774 - val_accuracy: 0.9326\n",
      "Epoch 308/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0255 - accuracy: 0.9563 - val_loss: 0.0774 - val_accuracy: 0.9286\n",
      "Epoch 309/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0250 - accuracy: 0.9560 - val_loss: 0.0762 - val_accuracy: 0.9317\n",
      "Epoch 310/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0253 - accuracy: 0.9552 - val_loss: 0.0776 - val_accuracy: 0.9293\n",
      "Epoch 311/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0253 - accuracy: 0.9557 - val_loss: 0.0840 - val_accuracy: 0.9301\n",
      "Epoch 312/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0253 - accuracy: 0.9550 - val_loss: 0.0739 - val_accuracy: 0.9319\n",
      "Epoch 313/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0251 - accuracy: 0.9557 - val_loss: 0.0790 - val_accuracy: 0.9324\n",
      "Epoch 314/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0250 - accuracy: 0.9548 - val_loss: 0.0781 - val_accuracy: 0.9309\n",
      "Epoch 315/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0248 - accuracy: 0.9560 - val_loss: 0.0777 - val_accuracy: 0.9302\n",
      "Epoch 316/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0262 - accuracy: 0.9549 - val_loss: 0.0827 - val_accuracy: 0.9301\n",
      "Epoch 317/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0258 - accuracy: 0.9549 - val_loss: 0.0787 - val_accuracy: 0.9297\n",
      "Epoch 318/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0259 - accuracy: 0.9542 - val_loss: 0.0759 - val_accuracy: 0.9313\n",
      "Epoch 319/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0256 - accuracy: 0.9553 - val_loss: 0.0795 - val_accuracy: 0.9319\n",
      "Epoch 320/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0253 - accuracy: 0.9556 - val_loss: 0.0778 - val_accuracy: 0.9298\n",
      "Epoch 321/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0247 - accuracy: 0.9561 - val_loss: 0.0835 - val_accuracy: 0.9280\n",
      "Epoch 322/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0253 - accuracy: 0.9560 - val_loss: 0.0763 - val_accuracy: 0.9302\n",
      "Epoch 323/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0244 - accuracy: 0.9568 - val_loss: 0.0852 - val_accuracy: 0.9301\n",
      "Epoch 324/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0246 - accuracy: 0.9567 - val_loss: 0.0814 - val_accuracy: 0.9278\n",
      "Epoch 325/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0253 - accuracy: 0.9553 - val_loss: 0.0848 - val_accuracy: 0.9327\n",
      "Epoch 326/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0247 - accuracy: 0.9558 - val_loss: 0.0808 - val_accuracy: 0.9294\n",
      "Epoch 327/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0252 - accuracy: 0.9558 - val_loss: 0.0770 - val_accuracy: 0.9306\n",
      "Epoch 328/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0246 - accuracy: 0.9559 - val_loss: 0.0797 - val_accuracy: 0.9316\n",
      "Epoch 329/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0244 - accuracy: 0.9565 - val_loss: 0.0832 - val_accuracy: 0.9312\n",
      "Epoch 330/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0254 - accuracy: 0.9553 - val_loss: 0.0790 - val_accuracy: 0.9301\n",
      "Epoch 331/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0254 - accuracy: 0.9553 - val_loss: 0.0832 - val_accuracy: 0.9266\n",
      "Epoch 332/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0251 - accuracy: 0.9560 - val_loss: 0.0821 - val_accuracy: 0.9280\n",
      "Epoch 333/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0247 - accuracy: 0.9560 - val_loss: 0.0782 - val_accuracy: 0.9305\n",
      "Epoch 334/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0243 - accuracy: 0.9569 - val_loss: 0.0782 - val_accuracy: 0.9314\n",
      "Epoch 335/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0253 - accuracy: 0.9561 - val_loss: 0.0805 - val_accuracy: 0.9267\n",
      "Epoch 336/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0256 - accuracy: 0.9553 - val_loss: 0.0796 - val_accuracy: 0.9290\n",
      "Epoch 337/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0251 - accuracy: 0.9552 - val_loss: 0.0834 - val_accuracy: 0.9270\n",
      "Epoch 338/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0253 - accuracy: 0.9552 - val_loss: 0.0764 - val_accuracy: 0.9280\n",
      "Epoch 339/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0257 - accuracy: 0.9551 - val_loss: 0.0802 - val_accuracy: 0.9313\n",
      "Epoch 340/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0252 - accuracy: 0.9561 - val_loss: 0.0776 - val_accuracy: 0.9299\n",
      "Epoch 341/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0260 - accuracy: 0.9551 - val_loss: 0.0794 - val_accuracy: 0.9321\n",
      "Epoch 342/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0254 - accuracy: 0.9555 - val_loss: 0.0806 - val_accuracy: 0.9303\n",
      "Epoch 343/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0249 - accuracy: 0.9556 - val_loss: 0.0828 - val_accuracy: 0.9297\n",
      "Epoch 344/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0249 - accuracy: 0.9561 - val_loss: 0.0809 - val_accuracy: 0.9318\n",
      "Epoch 345/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0244 - accuracy: 0.9570 - val_loss: 0.0822 - val_accuracy: 0.9314\n",
      "Epoch 346/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0242 - accuracy: 0.9566 - val_loss: 0.0838 - val_accuracy: 0.9317\n",
      "Epoch 347/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0240 - accuracy: 0.9561 - val_loss: 0.0828 - val_accuracy: 0.9268\n",
      "Epoch 348/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0250 - accuracy: 0.9555 - val_loss: 0.0776 - val_accuracy: 0.9295\n",
      "Epoch 349/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0246 - accuracy: 0.9560 - val_loss: 0.0818 - val_accuracy: 0.9290\n",
      "Epoch 350/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0251 - accuracy: 0.9558 - val_loss: 0.0805 - val_accuracy: 0.9295\n",
      "Epoch 351/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0245 - accuracy: 0.9572 - val_loss: 0.0798 - val_accuracy: 0.9318\n",
      "Epoch 352/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0253 - accuracy: 0.9560 - val_loss: 0.0816 - val_accuracy: 0.9303\n",
      "Epoch 353/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0245 - accuracy: 0.9570 - val_loss: 0.0838 - val_accuracy: 0.9268\n",
      "Epoch 354/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0246 - accuracy: 0.9572 - val_loss: 0.0838 - val_accuracy: 0.9298\n",
      "Epoch 355/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0247 - accuracy: 0.9563 - val_loss: 0.0786 - val_accuracy: 0.9305\n",
      "Epoch 356/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0241 - accuracy: 0.9570 - val_loss: 0.0809 - val_accuracy: 0.9281\n",
      "Epoch 357/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0249 - accuracy: 0.9569 - val_loss: 0.0845 - val_accuracy: 0.9309\n",
      "Epoch 358/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0238 - accuracy: 0.9578 - val_loss: 0.0834 - val_accuracy: 0.9268\n",
      "Epoch 359/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0239 - accuracy: 0.9580 - val_loss: 0.0804 - val_accuracy: 0.9294\n",
      "Epoch 360/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0252 - accuracy: 0.9559 - val_loss: 0.0840 - val_accuracy: 0.9303\n",
      "Epoch 361/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0244 - accuracy: 0.9574 - val_loss: 0.0839 - val_accuracy: 0.9270\n",
      "Epoch 362/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0243 - accuracy: 0.9575 - val_loss: 0.0865 - val_accuracy: 0.9275\n",
      "Epoch 363/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0247 - accuracy: 0.9571 - val_loss: 0.0826 - val_accuracy: 0.9292\n",
      "Epoch 364/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0242 - accuracy: 0.9580 - val_loss: 0.0908 - val_accuracy: 0.9290\n",
      "Epoch 365/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0246 - accuracy: 0.9575 - val_loss: 0.0823 - val_accuracy: 0.9312\n",
      "Epoch 366/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0244 - accuracy: 0.9573 - val_loss: 0.0781 - val_accuracy: 0.9311\n",
      "Epoch 367/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0248 - accuracy: 0.9571 - val_loss: 0.0853 - val_accuracy: 0.9309\n",
      "Epoch 368/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0242 - accuracy: 0.9578 - val_loss: 0.0872 - val_accuracy: 0.9272\n",
      "Epoch 369/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0241 - accuracy: 0.9577 - val_loss: 0.0859 - val_accuracy: 0.9290\n",
      "Epoch 370/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0245 - accuracy: 0.9575 - val_loss: 0.0815 - val_accuracy: 0.9338\n",
      "Epoch 371/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0237 - accuracy: 0.9585 - val_loss: 0.0813 - val_accuracy: 0.9282\n",
      "Epoch 372/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0247 - accuracy: 0.9572 - val_loss: 0.0852 - val_accuracy: 0.9262\n",
      "Epoch 373/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0251 - accuracy: 0.9570 - val_loss: 0.0855 - val_accuracy: 0.9313\n",
      "Epoch 374/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0247 - accuracy: 0.9574 - val_loss: 0.0904 - val_accuracy: 0.9255\n",
      "Epoch 375/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0245 - accuracy: 0.9575 - val_loss: 0.0849 - val_accuracy: 0.9293\n",
      "Epoch 376/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0250 - accuracy: 0.9566 - val_loss: 0.0828 - val_accuracy: 0.9305\n",
      "Epoch 377/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0245 - accuracy: 0.9573 - val_loss: 0.0856 - val_accuracy: 0.9302\n",
      "Epoch 378/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0248 - accuracy: 0.9567 - val_loss: 0.0848 - val_accuracy: 0.9279\n",
      "Epoch 379/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0250 - accuracy: 0.9568 - val_loss: 0.0931 - val_accuracy: 0.9279\n",
      "Epoch 380/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0245 - accuracy: 0.9574 - val_loss: 0.0883 - val_accuracy: 0.9286\n",
      "Epoch 381/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0245 - accuracy: 0.9575 - val_loss: 0.0832 - val_accuracy: 0.9259\n",
      "Epoch 382/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0244 - accuracy: 0.9571 - val_loss: 0.0857 - val_accuracy: 0.9305\n",
      "Epoch 383/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0243 - accuracy: 0.9572 - val_loss: 0.0835 - val_accuracy: 0.9298\n",
      "Epoch 384/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0242 - accuracy: 0.9572 - val_loss: 0.0815 - val_accuracy: 0.9307\n",
      "Epoch 385/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0247 - accuracy: 0.9568 - val_loss: 0.0873 - val_accuracy: 0.9298\n",
      "Epoch 386/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0240 - accuracy: 0.9589 - val_loss: 0.0887 - val_accuracy: 0.9305\n",
      "Epoch 387/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0249 - accuracy: 0.9571 - val_loss: 0.0870 - val_accuracy: 0.9294\n",
      "Epoch 388/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0246 - accuracy: 0.9576 - val_loss: 0.0832 - val_accuracy: 0.9268\n",
      "Epoch 389/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0250 - accuracy: 0.9566 - val_loss: 0.0887 - val_accuracy: 0.9274\n",
      "Epoch 390/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0248 - accuracy: 0.9569 - val_loss: 0.0855 - val_accuracy: 0.9301\n",
      "Epoch 391/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0247 - accuracy: 0.9569 - val_loss: 0.0881 - val_accuracy: 0.9282\n",
      "Epoch 392/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0244 - accuracy: 0.9574 - val_loss: 0.0855 - val_accuracy: 0.9280\n",
      "Epoch 393/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0252 - accuracy: 0.9566 - val_loss: 0.0920 - val_accuracy: 0.9300\n",
      "Epoch 394/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0243 - accuracy: 0.9578 - val_loss: 0.0891 - val_accuracy: 0.9273\n",
      "Epoch 395/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0238 - accuracy: 0.9585 - val_loss: 0.0950 - val_accuracy: 0.9315\n",
      "Epoch 396/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0241 - accuracy: 0.9580 - val_loss: 0.0886 - val_accuracy: 0.9325\n",
      "Epoch 397/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0237 - accuracy: 0.9578 - val_loss: 0.0871 - val_accuracy: 0.9234\n",
      "Epoch 398/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0243 - accuracy: 0.9582 - val_loss: 0.0896 - val_accuracy: 0.9287\n",
      "Epoch 399/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0242 - accuracy: 0.9577 - val_loss: 0.0901 - val_accuracy: 0.9325\n",
      "Epoch 400/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0239 - accuracy: 0.9584 - val_loss: 0.0908 - val_accuracy: 0.9323\n",
      "Epoch 401/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0247 - accuracy: 0.9571 - val_loss: 0.0926 - val_accuracy: 0.9311\n",
      "Epoch 402/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0246 - accuracy: 0.9574 - val_loss: 0.0850 - val_accuracy: 0.9320\n",
      "Epoch 403/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0246 - accuracy: 0.9576 - val_loss: 0.0878 - val_accuracy: 0.9307\n",
      "Epoch 404/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0238 - accuracy: 0.9580 - val_loss: 0.0856 - val_accuracy: 0.9258\n",
      "Epoch 405/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0245 - accuracy: 0.9575 - val_loss: 0.0886 - val_accuracy: 0.9241\n",
      "Epoch 406/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0237 - accuracy: 0.9584 - val_loss: 0.0918 - val_accuracy: 0.9275\n",
      "Epoch 407/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0241 - accuracy: 0.9580 - val_loss: 0.0890 - val_accuracy: 0.9300\n",
      "Epoch 408/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0250 - accuracy: 0.9570 - val_loss: 0.0961 - val_accuracy: 0.9290\n",
      "Epoch 409/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0255 - accuracy: 0.9554 - val_loss: 0.0953 - val_accuracy: 0.9335\n",
      "Epoch 410/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0238 - accuracy: 0.9586 - val_loss: 0.0869 - val_accuracy: 0.9280\n",
      "Epoch 411/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0246 - accuracy: 0.9578 - val_loss: 0.0904 - val_accuracy: 0.9289\n",
      "Epoch 412/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0247 - accuracy: 0.9577 - val_loss: 0.0859 - val_accuracy: 0.9283\n",
      "Epoch 413/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0240 - accuracy: 0.9579 - val_loss: 0.0911 - val_accuracy: 0.9291\n",
      "Epoch 414/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0240 - accuracy: 0.9580 - val_loss: 0.0953 - val_accuracy: 0.9239\n",
      "Epoch 415/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0243 - accuracy: 0.9580 - val_loss: 0.0894 - val_accuracy: 0.9257\n",
      "Epoch 416/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0252 - accuracy: 0.9564 - val_loss: 0.0895 - val_accuracy: 0.9293\n",
      "Epoch 417/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0242 - accuracy: 0.9579 - val_loss: 0.0894 - val_accuracy: 0.9267\n",
      "Epoch 418/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0243 - accuracy: 0.9576 - val_loss: 0.0852 - val_accuracy: 0.9301\n",
      "Epoch 419/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0246 - accuracy: 0.9574 - val_loss: 0.0942 - val_accuracy: 0.9320\n",
      "Epoch 420/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0252 - accuracy: 0.9566 - val_loss: 0.0933 - val_accuracy: 0.9291\n",
      "Epoch 421/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0248 - accuracy: 0.9580 - val_loss: 0.0880 - val_accuracy: 0.9258\n",
      "Epoch 422/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0238 - accuracy: 0.9584 - val_loss: 0.0930 - val_accuracy: 0.9279\n",
      "Epoch 423/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0240 - accuracy: 0.9582 - val_loss: 0.0902 - val_accuracy: 0.9298\n",
      "Epoch 424/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0243 - accuracy: 0.9574 - val_loss: 0.0914 - val_accuracy: 0.9310\n",
      "Epoch 425/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0237 - accuracy: 0.9587 - val_loss: 0.0894 - val_accuracy: 0.9304\n",
      "Epoch 426/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0246 - accuracy: 0.9572 - val_loss: 0.0901 - val_accuracy: 0.9278\n",
      "Epoch 427/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0245 - accuracy: 0.9577 - val_loss: 0.0878 - val_accuracy: 0.9278\n",
      "Epoch 428/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0243 - accuracy: 0.9575 - val_loss: 0.0878 - val_accuracy: 0.9243\n",
      "Epoch 429/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0239 - accuracy: 0.9582 - val_loss: 0.0920 - val_accuracy: 0.9324\n",
      "Epoch 430/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0243 - accuracy: 0.9574 - val_loss: 0.0881 - val_accuracy: 0.9288\n",
      "Epoch 431/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0243 - accuracy: 0.9577 - val_loss: 0.0882 - val_accuracy: 0.9265\n",
      "Epoch 432/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0236 - accuracy: 0.9582 - val_loss: 0.0870 - val_accuracy: 0.9280\n",
      "Epoch 433/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0232 - accuracy: 0.9584 - val_loss: 0.0887 - val_accuracy: 0.9303\n",
      "Epoch 434/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0237 - accuracy: 0.9585 - val_loss: 0.0868 - val_accuracy: 0.9278\n",
      "Epoch 435/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0235 - accuracy: 0.9582 - val_loss: 0.0948 - val_accuracy: 0.9315\n",
      "Epoch 436/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0246 - accuracy: 0.9571 - val_loss: 0.0888 - val_accuracy: 0.9259\n",
      "Epoch 437/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0236 - accuracy: 0.9582 - val_loss: 0.0896 - val_accuracy: 0.9271\n",
      "Epoch 438/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0243 - accuracy: 0.9575 - val_loss: 0.0962 - val_accuracy: 0.9259\n",
      "Epoch 439/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0237 - accuracy: 0.9583 - val_loss: 0.0882 - val_accuracy: 0.9274\n",
      "Epoch 440/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0231 - accuracy: 0.9595 - val_loss: 0.0851 - val_accuracy: 0.9291\n",
      "Epoch 441/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0235 - accuracy: 0.9585 - val_loss: 0.0903 - val_accuracy: 0.9305\n",
      "Epoch 442/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0240 - accuracy: 0.9582 - val_loss: 0.0886 - val_accuracy: 0.9287\n",
      "Epoch 443/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0245 - accuracy: 0.9582 - val_loss: 0.0900 - val_accuracy: 0.9308\n",
      "Epoch 444/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0239 - accuracy: 0.9583 - val_loss: 0.0912 - val_accuracy: 0.9302\n",
      "Epoch 445/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0247 - accuracy: 0.9577 - val_loss: 0.0879 - val_accuracy: 0.9263\n",
      "Epoch 446/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0238 - accuracy: 0.9587 - val_loss: 0.0967 - val_accuracy: 0.9292\n",
      "Epoch 447/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0243 - accuracy: 0.9574 - val_loss: 0.0911 - val_accuracy: 0.9282\n",
      "Epoch 448/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0246 - accuracy: 0.9565 - val_loss: 0.0929 - val_accuracy: 0.9295\n",
      "Epoch 449/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0238 - accuracy: 0.9585 - val_loss: 0.0990 - val_accuracy: 0.9289\n",
      "Epoch 450/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0238 - accuracy: 0.9593 - val_loss: 0.1001 - val_accuracy: 0.9287\n",
      "Epoch 451/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0239 - accuracy: 0.9580 - val_loss: 0.0927 - val_accuracy: 0.9282\n",
      "Epoch 452/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0240 - accuracy: 0.9582 - val_loss: 0.0987 - val_accuracy: 0.9306\n",
      "Epoch 453/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0247 - accuracy: 0.9574 - val_loss: 0.0878 - val_accuracy: 0.9295\n",
      "Epoch 454/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0237 - accuracy: 0.9587 - val_loss: 0.0920 - val_accuracy: 0.9320\n",
      "Epoch 455/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0250 - accuracy: 0.9567 - val_loss: 0.0969 - val_accuracy: 0.9273\n",
      "Epoch 456/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0251 - accuracy: 0.9569 - val_loss: 0.0914 - val_accuracy: 0.9294\n",
      "Epoch 457/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0249 - accuracy: 0.9567 - val_loss: 0.0953 - val_accuracy: 0.9262\n",
      "Epoch 458/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0237 - accuracy: 0.9587 - val_loss: 0.0901 - val_accuracy: 0.9325\n",
      "Epoch 459/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0240 - accuracy: 0.9582 - val_loss: 0.0949 - val_accuracy: 0.9311\n",
      "Epoch 460/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0236 - accuracy: 0.9588 - val_loss: 0.0924 - val_accuracy: 0.9274\n",
      "Epoch 461/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0238 - accuracy: 0.9583 - val_loss: 0.0941 - val_accuracy: 0.9282\n",
      "Epoch 462/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0237 - accuracy: 0.9584 - val_loss: 0.0937 - val_accuracy: 0.9283\n",
      "Epoch 463/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0239 - accuracy: 0.9582 - val_loss: 0.0929 - val_accuracy: 0.9284\n",
      "Epoch 464/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0244 - accuracy: 0.9577 - val_loss: 0.0910 - val_accuracy: 0.9290\n",
      "Epoch 465/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0239 - accuracy: 0.9582 - val_loss: 0.0927 - val_accuracy: 0.9258\n",
      "Epoch 466/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0236 - accuracy: 0.9589 - val_loss: 0.0962 - val_accuracy: 0.9305\n",
      "Epoch 467/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0237 - accuracy: 0.9587 - val_loss: 0.0960 - val_accuracy: 0.9286\n",
      "Epoch 468/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0241 - accuracy: 0.9586 - val_loss: 0.0930 - val_accuracy: 0.9288\n",
      "Epoch 469/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0242 - accuracy: 0.9587 - val_loss: 0.0916 - val_accuracy: 0.9284\n",
      "Epoch 470/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0238 - accuracy: 0.9586 - val_loss: 0.0932 - val_accuracy: 0.9269\n",
      "Epoch 471/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0237 - accuracy: 0.9593 - val_loss: 0.0953 - val_accuracy: 0.9305\n",
      "Epoch 472/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0234 - accuracy: 0.9594 - val_loss: 0.0920 - val_accuracy: 0.9308\n",
      "Epoch 473/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0232 - accuracy: 0.9593 - val_loss: 0.0964 - val_accuracy: 0.9335\n",
      "Epoch 474/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0240 - accuracy: 0.9580 - val_loss: 0.0984 - val_accuracy: 0.9299\n",
      "Epoch 475/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0232 - accuracy: 0.9600 - val_loss: 0.0958 - val_accuracy: 0.9269\n",
      "Epoch 476/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0229 - accuracy: 0.9597 - val_loss: 0.0943 - val_accuracy: 0.9323\n",
      "Epoch 477/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0234 - accuracy: 0.9586 - val_loss: 0.0926 - val_accuracy: 0.9296\n",
      "Epoch 478/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0231 - accuracy: 0.9599 - val_loss: 0.0941 - val_accuracy: 0.9335\n",
      "Epoch 479/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0231 - accuracy: 0.9600 - val_loss: 0.0934 - val_accuracy: 0.9309\n",
      "Epoch 480/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0226 - accuracy: 0.9604 - val_loss: 0.1000 - val_accuracy: 0.9256\n",
      "Epoch 481/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0228 - accuracy: 0.9603 - val_loss: 0.0884 - val_accuracy: 0.9335\n",
      "Epoch 482/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0236 - accuracy: 0.9596 - val_loss: 0.0957 - val_accuracy: 0.9257\n",
      "Epoch 483/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0233 - accuracy: 0.9599 - val_loss: 0.0947 - val_accuracy: 0.9288\n",
      "Epoch 484/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0235 - accuracy: 0.9588 - val_loss: 0.0936 - val_accuracy: 0.9295\n",
      "Epoch 485/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0228 - accuracy: 0.9604 - val_loss: 0.0939 - val_accuracy: 0.9276\n",
      "Epoch 486/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0228 - accuracy: 0.9602 - val_loss: 0.0969 - val_accuracy: 0.9326\n",
      "Epoch 487/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0235 - accuracy: 0.9594 - val_loss: 0.0944 - val_accuracy: 0.9304\n",
      "Epoch 488/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0228 - accuracy: 0.9599 - val_loss: 0.0957 - val_accuracy: 0.9316\n",
      "Epoch 489/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0225 - accuracy: 0.9603 - val_loss: 0.0941 - val_accuracy: 0.9322\n",
      "Epoch 490/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0227 - accuracy: 0.9599 - val_loss: 0.1005 - val_accuracy: 0.9302\n",
      "Epoch 491/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0243 - accuracy: 0.9585 - val_loss: 0.0952 - val_accuracy: 0.9323\n",
      "Epoch 492/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0224 - accuracy: 0.9605 - val_loss: 0.0925 - val_accuracy: 0.9308\n",
      "Epoch 493/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0227 - accuracy: 0.9609 - val_loss: 0.0912 - val_accuracy: 0.9266\n",
      "Epoch 494/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0232 - accuracy: 0.9593 - val_loss: 0.0968 - val_accuracy: 0.9310\n",
      "Epoch 495/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0235 - accuracy: 0.9592 - val_loss: 0.0975 - val_accuracy: 0.9326\n",
      "Epoch 496/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0231 - accuracy: 0.9597 - val_loss: 0.0997 - val_accuracy: 0.9313\n",
      "Epoch 497/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0223 - accuracy: 0.9602 - val_loss: 0.0969 - val_accuracy: 0.9295\n",
      "Epoch 498/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0231 - accuracy: 0.9599 - val_loss: 0.0935 - val_accuracy: 0.9298\n",
      "Epoch 499/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0228 - accuracy: 0.9600 - val_loss: 0.1058 - val_accuracy: 0.9295\n",
      "Epoch 500/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0226 - accuracy: 0.9605 - val_loss: 0.0957 - val_accuracy: 0.9311\n",
      "Epoch 501/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0227 - accuracy: 0.9606 - val_loss: 0.0935 - val_accuracy: 0.9305\n",
      "Epoch 502/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0228 - accuracy: 0.9604 - val_loss: 0.0986 - val_accuracy: 0.9333\n",
      "Epoch 503/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0230 - accuracy: 0.9599 - val_loss: 0.0931 - val_accuracy: 0.9288\n",
      "Epoch 504/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0226 - accuracy: 0.9599 - val_loss: 0.0984 - val_accuracy: 0.9340\n",
      "Epoch 505/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0221 - accuracy: 0.9610 - val_loss: 0.0969 - val_accuracy: 0.9317\n",
      "Epoch 506/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0220 - accuracy: 0.9615 - val_loss: 0.1036 - val_accuracy: 0.9286\n",
      "Epoch 507/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0232 - accuracy: 0.9591 - val_loss: 0.1002 - val_accuracy: 0.9265\n",
      "Epoch 508/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0224 - accuracy: 0.9607 - val_loss: 0.0962 - val_accuracy: 0.9317\n",
      "Epoch 509/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0228 - accuracy: 0.9604 - val_loss: 0.0969 - val_accuracy: 0.9331\n",
      "Epoch 510/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0237 - accuracy: 0.9592 - val_loss: 0.0913 - val_accuracy: 0.9303\n",
      "Epoch 511/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0224 - accuracy: 0.9604 - val_loss: 0.0989 - val_accuracy: 0.9264\n",
      "Epoch 512/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0221 - accuracy: 0.9612 - val_loss: 0.1003 - val_accuracy: 0.9272\n",
      "Epoch 513/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0230 - accuracy: 0.9594 - val_loss: 0.1032 - val_accuracy: 0.9308\n",
      "Epoch 514/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0221 - accuracy: 0.9610 - val_loss: 0.0994 - val_accuracy: 0.9310\n",
      "Epoch 515/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0227 - accuracy: 0.9602 - val_loss: 0.0984 - val_accuracy: 0.9297\n",
      "Epoch 516/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0230 - accuracy: 0.9599 - val_loss: 0.0997 - val_accuracy: 0.9322\n",
      "Epoch 517/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0226 - accuracy: 0.9604 - val_loss: 0.1007 - val_accuracy: 0.9307\n",
      "Epoch 518/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0229 - accuracy: 0.9601 - val_loss: 0.1035 - val_accuracy: 0.9306\n",
      "Epoch 519/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0226 - accuracy: 0.9601 - val_loss: 0.0951 - val_accuracy: 0.9282\n",
      "Epoch 520/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0221 - accuracy: 0.9609 - val_loss: 0.1024 - val_accuracy: 0.9301\n",
      "Epoch 521/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0228 - accuracy: 0.9603 - val_loss: 0.0979 - val_accuracy: 0.9289\n",
      "Epoch 522/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0228 - accuracy: 0.9608 - val_loss: 0.0965 - val_accuracy: 0.9292\n",
      "Epoch 523/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0227 - accuracy: 0.9604 - val_loss: 0.0973 - val_accuracy: 0.9298\n",
      "Epoch 524/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0225 - accuracy: 0.9610 - val_loss: 0.0989 - val_accuracy: 0.9302\n",
      "Epoch 525/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0229 - accuracy: 0.9603 - val_loss: 0.0990 - val_accuracy: 0.9286\n",
      "Epoch 526/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0235 - accuracy: 0.9599 - val_loss: 0.0952 - val_accuracy: 0.9302\n",
      "Epoch 527/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0235 - accuracy: 0.9600 - val_loss: 0.0978 - val_accuracy: 0.9241\n",
      "Epoch 528/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0235 - accuracy: 0.9592 - val_loss: 0.0971 - val_accuracy: 0.9319\n",
      "Epoch 529/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0224 - accuracy: 0.9610 - val_loss: 0.0975 - val_accuracy: 0.9298\n",
      "Epoch 530/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0227 - accuracy: 0.9608 - val_loss: 0.1007 - val_accuracy: 0.9303\n",
      "Epoch 531/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0226 - accuracy: 0.9609 - val_loss: 0.1005 - val_accuracy: 0.9253\n",
      "Epoch 532/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0225 - accuracy: 0.9607 - val_loss: 0.0997 - val_accuracy: 0.9317\n",
      "Epoch 533/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0223 - accuracy: 0.9613 - val_loss: 0.1005 - val_accuracy: 0.9300\n",
      "Epoch 534/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0224 - accuracy: 0.9609 - val_loss: 0.1042 - val_accuracy: 0.9264\n",
      "Epoch 535/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0227 - accuracy: 0.9603 - val_loss: 0.0962 - val_accuracy: 0.9300\n",
      "Epoch 536/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0221 - accuracy: 0.9608 - val_loss: 0.1030 - val_accuracy: 0.9260\n",
      "Epoch 537/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0223 - accuracy: 0.9610 - val_loss: 0.1018 - val_accuracy: 0.9318\n",
      "Epoch 538/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0220 - accuracy: 0.9615 - val_loss: 0.1017 - val_accuracy: 0.9325\n",
      "Epoch 539/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0229 - accuracy: 0.9605 - val_loss: 0.1010 - val_accuracy: 0.9299\n",
      "Epoch 540/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0233 - accuracy: 0.9601 - val_loss: 0.1046 - val_accuracy: 0.9277\n",
      "Epoch 541/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0225 - accuracy: 0.9603 - val_loss: 0.1024 - val_accuracy: 0.9303\n",
      "Epoch 542/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0230 - accuracy: 0.9600 - val_loss: 0.0959 - val_accuracy: 0.9324\n",
      "Epoch 543/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0226 - accuracy: 0.9609 - val_loss: 0.1010 - val_accuracy: 0.9309\n",
      "Epoch 544/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0225 - accuracy: 0.9609 - val_loss: 0.0996 - val_accuracy: 0.9329\n",
      "Epoch 545/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9622 - val_loss: 0.1029 - val_accuracy: 0.9324\n",
      "Epoch 546/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0228 - accuracy: 0.9602 - val_loss: 0.1008 - val_accuracy: 0.9310\n",
      "Epoch 547/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0224 - accuracy: 0.9611 - val_loss: 0.0966 - val_accuracy: 0.9291\n",
      "Epoch 548/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0223 - accuracy: 0.9612 - val_loss: 0.1037 - val_accuracy: 0.9317\n",
      "Epoch 549/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0225 - accuracy: 0.9611 - val_loss: 0.1145 - val_accuracy: 0.9286\n",
      "Epoch 550/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0228 - accuracy: 0.9610 - val_loss: 0.0990 - val_accuracy: 0.9333\n",
      "Epoch 551/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0230 - accuracy: 0.9604 - val_loss: 0.1022 - val_accuracy: 0.9324\n",
      "Epoch 552/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0233 - accuracy: 0.9601 - val_loss: 0.1040 - val_accuracy: 0.9323\n",
      "Epoch 553/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0229 - accuracy: 0.9601 - val_loss: 0.1044 - val_accuracy: 0.9302\n",
      "Epoch 554/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0220 - accuracy: 0.9610 - val_loss: 0.1033 - val_accuracy: 0.9303\n",
      "Epoch 555/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0227 - accuracy: 0.9605 - val_loss: 0.1037 - val_accuracy: 0.9301\n",
      "Epoch 556/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0220 - accuracy: 0.9618 - val_loss: 0.1044 - val_accuracy: 0.9300\n",
      "Epoch 557/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0223 - accuracy: 0.9613 - val_loss: 0.1026 - val_accuracy: 0.9310\n",
      "Epoch 558/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0235 - accuracy: 0.9593 - val_loss: 0.1039 - val_accuracy: 0.9253\n",
      "Epoch 559/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0228 - accuracy: 0.9604 - val_loss: 0.0995 - val_accuracy: 0.9312\n",
      "Epoch 560/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0229 - accuracy: 0.9603 - val_loss: 0.1023 - val_accuracy: 0.9250\n",
      "Epoch 561/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0224 - accuracy: 0.9612 - val_loss: 0.1021 - val_accuracy: 0.9320\n",
      "Epoch 562/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0224 - accuracy: 0.9607 - val_loss: 0.0988 - val_accuracy: 0.9322\n",
      "Epoch 563/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9618 - val_loss: 0.1053 - val_accuracy: 0.9282\n",
      "Epoch 564/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0219 - accuracy: 0.9613 - val_loss: 0.1040 - val_accuracy: 0.9322\n",
      "Epoch 565/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0224 - accuracy: 0.9609 - val_loss: 0.1056 - val_accuracy: 0.9307\n",
      "Epoch 566/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0229 - accuracy: 0.9593 - val_loss: 0.1052 - val_accuracy: 0.9319\n",
      "Epoch 567/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0219 - accuracy: 0.9609 - val_loss: 0.1015 - val_accuracy: 0.9313\n",
      "Epoch 568/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0232 - accuracy: 0.9597 - val_loss: 0.1065 - val_accuracy: 0.9272\n",
      "Epoch 569/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0228 - accuracy: 0.9600 - val_loss: 0.1051 - val_accuracy: 0.9302\n",
      "Epoch 570/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0222 - accuracy: 0.9609 - val_loss: 0.1027 - val_accuracy: 0.9254\n",
      "Epoch 571/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0226 - accuracy: 0.9604 - val_loss: 0.1004 - val_accuracy: 0.9285\n",
      "Epoch 572/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0219 - accuracy: 0.9620 - val_loss: 0.1026 - val_accuracy: 0.9288\n",
      "Epoch 573/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0218 - accuracy: 0.9615 - val_loss: 0.1050 - val_accuracy: 0.9320\n",
      "Epoch 574/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0224 - accuracy: 0.9606 - val_loss: 0.1090 - val_accuracy: 0.9295\n",
      "Epoch 575/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0232 - accuracy: 0.9604 - val_loss: 0.1136 - val_accuracy: 0.9279\n",
      "Epoch 576/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0233 - accuracy: 0.9593 - val_loss: 0.1098 - val_accuracy: 0.9342\n",
      "Epoch 577/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9621 - val_loss: 0.1043 - val_accuracy: 0.9331\n",
      "Epoch 578/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0212 - accuracy: 0.9626 - val_loss: 0.0999 - val_accuracy: 0.9308\n",
      "Epoch 579/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0217 - accuracy: 0.9614 - val_loss: 0.1030 - val_accuracy: 0.9291\n",
      "Epoch 580/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0231 - accuracy: 0.9603 - val_loss: 0.1036 - val_accuracy: 0.9300\n",
      "Epoch 581/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0231 - accuracy: 0.9599 - val_loss: 0.1061 - val_accuracy: 0.9311\n",
      "Epoch 582/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0224 - accuracy: 0.9607 - val_loss: 0.1092 - val_accuracy: 0.9307\n",
      "Epoch 583/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0222 - accuracy: 0.9609 - val_loss: 0.1110 - val_accuracy: 0.9333\n",
      "Epoch 584/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0221 - accuracy: 0.9614 - val_loss: 0.1072 - val_accuracy: 0.9263\n",
      "Epoch 585/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0220 - accuracy: 0.9619 - val_loss: 0.1094 - val_accuracy: 0.9283\n",
      "Epoch 586/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0220 - accuracy: 0.9611 - val_loss: 0.1049 - val_accuracy: 0.9303\n",
      "Epoch 587/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0220 - accuracy: 0.9612 - val_loss: 0.1048 - val_accuracy: 0.9306\n",
      "Epoch 588/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0217 - accuracy: 0.9620 - val_loss: 0.1024 - val_accuracy: 0.9291\n",
      "Epoch 589/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0215 - accuracy: 0.9619 - val_loss: 0.1060 - val_accuracy: 0.9308\n",
      "Epoch 590/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0221 - accuracy: 0.9613 - val_loss: 0.1069 - val_accuracy: 0.9318\n",
      "Epoch 591/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0228 - accuracy: 0.9601 - val_loss: 0.1090 - val_accuracy: 0.9289\n",
      "Epoch 592/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0229 - accuracy: 0.9600 - val_loss: 0.1047 - val_accuracy: 0.9325\n",
      "Epoch 593/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0222 - accuracy: 0.9614 - val_loss: 0.1059 - val_accuracy: 0.9273\n",
      "Epoch 594/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0220 - accuracy: 0.9611 - val_loss: 0.1069 - val_accuracy: 0.9299\n",
      "Epoch 595/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0219 - accuracy: 0.9612 - val_loss: 0.1053 - val_accuracy: 0.9324\n",
      "Epoch 596/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0222 - accuracy: 0.9612 - val_loss: 0.1073 - val_accuracy: 0.9312\n",
      "Epoch 597/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0222 - accuracy: 0.9613 - val_loss: 0.1077 - val_accuracy: 0.9316\n",
      "Epoch 598/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0218 - accuracy: 0.9617 - val_loss: 0.1083 - val_accuracy: 0.9282\n",
      "Epoch 599/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0224 - accuracy: 0.9605 - val_loss: 0.1107 - val_accuracy: 0.9323\n",
      "Epoch 600/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0221 - accuracy: 0.9619 - val_loss: 0.1134 - val_accuracy: 0.9314\n",
      "Epoch 601/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0217 - accuracy: 0.9612 - val_loss: 0.1045 - val_accuracy: 0.9265\n",
      "Epoch 602/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0222 - accuracy: 0.9606 - val_loss: 0.1143 - val_accuracy: 0.9265\n",
      "Epoch 603/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0226 - accuracy: 0.9612 - val_loss: 0.1111 - val_accuracy: 0.9311\n",
      "Epoch 604/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0223 - accuracy: 0.9608 - val_loss: 0.1099 - val_accuracy: 0.9277\n",
      "Epoch 605/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0222 - accuracy: 0.9614 - val_loss: 0.1130 - val_accuracy: 0.9288\n",
      "Epoch 606/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0222 - accuracy: 0.9607 - val_loss: 0.1085 - val_accuracy: 0.9271\n",
      "Epoch 607/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0222 - accuracy: 0.9610 - val_loss: 0.1086 - val_accuracy: 0.9310\n",
      "Epoch 608/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0230 - accuracy: 0.9602 - val_loss: 0.1155 - val_accuracy: 0.9257\n",
      "Epoch 609/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0219 - accuracy: 0.9614 - val_loss: 0.1104 - val_accuracy: 0.9303\n",
      "Epoch 610/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0225 - accuracy: 0.9611 - val_loss: 0.1040 - val_accuracy: 0.9282\n",
      "Epoch 611/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0221 - accuracy: 0.9616 - val_loss: 0.1072 - val_accuracy: 0.9277\n",
      "Epoch 612/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0217 - accuracy: 0.9618 - val_loss: 0.1059 - val_accuracy: 0.9291\n",
      "Epoch 613/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0226 - accuracy: 0.9612 - val_loss: 0.1089 - val_accuracy: 0.9293\n",
      "Epoch 614/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0223 - accuracy: 0.9606 - val_loss: 0.1067 - val_accuracy: 0.9308\n",
      "Epoch 615/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0227 - accuracy: 0.9601 - val_loss: 0.1145 - val_accuracy: 0.9257\n",
      "Epoch 616/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0224 - accuracy: 0.9604 - val_loss: 0.1139 - val_accuracy: 0.9350\n",
      "Epoch 617/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0223 - accuracy: 0.9610 - val_loss: 0.1107 - val_accuracy: 0.9312\n",
      "Epoch 618/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0219 - accuracy: 0.9613 - val_loss: 0.1090 - val_accuracy: 0.9312\n",
      "Epoch 619/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9621 - val_loss: 0.1142 - val_accuracy: 0.9311\n",
      "Epoch 620/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0223 - accuracy: 0.9607 - val_loss: 0.1103 - val_accuracy: 0.9322\n",
      "Epoch 621/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0221 - accuracy: 0.9612 - val_loss: 0.1079 - val_accuracy: 0.9264\n",
      "Epoch 622/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0221 - accuracy: 0.9608 - val_loss: 0.1161 - val_accuracy: 0.9313\n",
      "Epoch 623/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0229 - accuracy: 0.9602 - val_loss: 0.1103 - val_accuracy: 0.9316\n",
      "Epoch 624/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0223 - accuracy: 0.9613 - val_loss: 0.1151 - val_accuracy: 0.9311\n",
      "Epoch 625/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9619 - val_loss: 0.1113 - val_accuracy: 0.9301\n",
      "Epoch 626/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0233 - accuracy: 0.9598 - val_loss: 0.1055 - val_accuracy: 0.9266\n",
      "Epoch 627/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0230 - accuracy: 0.9604 - val_loss: 0.1093 - val_accuracy: 0.9285\n",
      "Epoch 628/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0222 - accuracy: 0.9610 - val_loss: 0.1132 - val_accuracy: 0.9314\n",
      "Epoch 629/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0217 - accuracy: 0.9610 - val_loss: 0.1120 - val_accuracy: 0.9249\n",
      "Epoch 630/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0217 - accuracy: 0.9616 - val_loss: 0.1122 - val_accuracy: 0.9323\n",
      "Epoch 631/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0218 - accuracy: 0.9615 - val_loss: 0.1180 - val_accuracy: 0.9275\n",
      "Epoch 632/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0218 - accuracy: 0.9619 - val_loss: 0.1119 - val_accuracy: 0.9339\n",
      "Epoch 633/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0215 - accuracy: 0.9622 - val_loss: 0.1090 - val_accuracy: 0.9311\n",
      "Epoch 634/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0210 - accuracy: 0.9625 - val_loss: 0.1157 - val_accuracy: 0.9295\n",
      "Epoch 635/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9615 - val_loss: 0.1196 - val_accuracy: 0.9320\n",
      "Epoch 636/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9619 - val_loss: 0.1186 - val_accuracy: 0.9295\n",
      "Epoch 637/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9619 - val_loss: 0.1108 - val_accuracy: 0.9300\n",
      "Epoch 638/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0212 - accuracy: 0.9625 - val_loss: 0.1144 - val_accuracy: 0.9321\n",
      "Epoch 639/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0213 - accuracy: 0.9621 - val_loss: 0.1147 - val_accuracy: 0.9308\n",
      "Epoch 640/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0221 - accuracy: 0.9611 - val_loss: 0.1119 - val_accuracy: 0.9307\n",
      "Epoch 641/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0228 - accuracy: 0.9600 - val_loss: 0.1093 - val_accuracy: 0.9250\n",
      "Epoch 642/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0231 - accuracy: 0.9597 - val_loss: 0.1076 - val_accuracy: 0.9288\n",
      "Epoch 643/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0220 - accuracy: 0.9617 - val_loss: 0.1130 - val_accuracy: 0.9324\n",
      "Epoch 644/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0218 - accuracy: 0.9618 - val_loss: 0.1155 - val_accuracy: 0.9305\n",
      "Epoch 645/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0230 - accuracy: 0.9604 - val_loss: 0.1262 - val_accuracy: 0.9287\n",
      "Epoch 646/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0218 - accuracy: 0.9613 - val_loss: 0.1089 - val_accuracy: 0.9295\n",
      "Epoch 647/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9618 - val_loss: 0.1110 - val_accuracy: 0.9313\n",
      "Epoch 648/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0220 - accuracy: 0.9615 - val_loss: 0.1121 - val_accuracy: 0.9289\n",
      "Epoch 649/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9621 - val_loss: 0.1096 - val_accuracy: 0.9267\n",
      "Epoch 650/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9621 - val_loss: 0.1163 - val_accuracy: 0.9327\n",
      "Epoch 651/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9613 - val_loss: 0.1118 - val_accuracy: 0.9308\n",
      "Epoch 652/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0213 - accuracy: 0.9620 - val_loss: 0.1116 - val_accuracy: 0.9298\n",
      "Epoch 653/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9621 - val_loss: 0.1130 - val_accuracy: 0.9301\n",
      "Epoch 654/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0226 - accuracy: 0.9613 - val_loss: 0.1135 - val_accuracy: 0.9249\n",
      "Epoch 655/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0223 - accuracy: 0.9605 - val_loss: 0.1212 - val_accuracy: 0.9269\n",
      "Epoch 656/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0217 - accuracy: 0.9617 - val_loss: 0.1145 - val_accuracy: 0.9319\n",
      "Epoch 657/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0223 - accuracy: 0.9606 - val_loss: 0.1178 - val_accuracy: 0.9287\n",
      "Epoch 658/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0235 - accuracy: 0.9599 - val_loss: 0.1153 - val_accuracy: 0.9296\n",
      "Epoch 659/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0244 - accuracy: 0.9596 - val_loss: 0.1221 - val_accuracy: 0.9295\n",
      "Epoch 660/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0237 - accuracy: 0.9589 - val_loss: 0.1083 - val_accuracy: 0.9292\n",
      "Epoch 661/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0217 - accuracy: 0.9620 - val_loss: 0.1120 - val_accuracy: 0.9290\n",
      "Epoch 662/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0222 - accuracy: 0.9611 - val_loss: 0.1093 - val_accuracy: 0.9313\n",
      "Epoch 663/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0207 - accuracy: 0.9632 - val_loss: 0.1155 - val_accuracy: 0.9305\n",
      "Epoch 664/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0219 - accuracy: 0.9614 - val_loss: 0.1108 - val_accuracy: 0.9257\n",
      "Epoch 665/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0220 - accuracy: 0.9614 - val_loss: 0.1163 - val_accuracy: 0.9318\n",
      "Epoch 666/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0224 - accuracy: 0.9608 - val_loss: 0.1194 - val_accuracy: 0.9316\n",
      "Epoch 667/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0219 - accuracy: 0.9617 - val_loss: 0.1148 - val_accuracy: 0.9288\n",
      "Epoch 668/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0219 - accuracy: 0.9608 - val_loss: 0.1149 - val_accuracy: 0.9311\n",
      "Epoch 669/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9621 - val_loss: 0.1167 - val_accuracy: 0.9307\n",
      "Epoch 670/1000\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0219 - accuracy: 0.9617 - val_loss: 0.1110 - val_accuracy: 0.9322\n",
      "Epoch 671/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9617 - val_loss: 0.1173 - val_accuracy: 0.9315\n",
      "Epoch 672/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9617 - val_loss: 0.1165 - val_accuracy: 0.9287\n",
      "Epoch 673/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0217 - accuracy: 0.9618 - val_loss: 0.1116 - val_accuracy: 0.9292\n",
      "Epoch 674/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0220 - accuracy: 0.9616 - val_loss: 0.1160 - val_accuracy: 0.9301\n",
      "Epoch 675/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0225 - accuracy: 0.9608 - val_loss: 0.1110 - val_accuracy: 0.9289\n",
      "Epoch 676/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0211 - accuracy: 0.9622 - val_loss: 0.1182 - val_accuracy: 0.9259\n",
      "Epoch 677/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0215 - accuracy: 0.9616 - val_loss: 0.1102 - val_accuracy: 0.9290\n",
      "Epoch 678/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0222 - accuracy: 0.9613 - val_loss: 0.1118 - val_accuracy: 0.9315\n",
      "Epoch 679/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0224 - accuracy: 0.9607 - val_loss: 0.1206 - val_accuracy: 0.9277\n",
      "Epoch 680/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9613 - val_loss: 0.1140 - val_accuracy: 0.9316\n",
      "Epoch 681/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0225 - accuracy: 0.9606 - val_loss: 0.1140 - val_accuracy: 0.9287\n",
      "Epoch 682/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9621 - val_loss: 0.1164 - val_accuracy: 0.9289\n",
      "Epoch 683/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0215 - accuracy: 0.9620 - val_loss: 0.1141 - val_accuracy: 0.9274\n",
      "Epoch 684/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0213 - accuracy: 0.9620 - val_loss: 0.1126 - val_accuracy: 0.9299\n",
      "Epoch 685/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9621 - val_loss: 0.1109 - val_accuracy: 0.9298\n",
      "Epoch 686/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0223 - accuracy: 0.9612 - val_loss: 0.1080 - val_accuracy: 0.9312\n",
      "Epoch 687/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0219 - accuracy: 0.9613 - val_loss: 0.1114 - val_accuracy: 0.9280\n",
      "Epoch 688/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0228 - accuracy: 0.9603 - val_loss: 0.1150 - val_accuracy: 0.9267\n",
      "Epoch 689/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0218 - accuracy: 0.9614 - val_loss: 0.1157 - val_accuracy: 0.9301\n",
      "Epoch 690/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0215 - accuracy: 0.9618 - val_loss: 0.1186 - val_accuracy: 0.9249\n",
      "Epoch 691/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0218 - accuracy: 0.9615 - val_loss: 0.1121 - val_accuracy: 0.9258\n",
      "Epoch 692/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0222 - accuracy: 0.9611 - val_loss: 0.1124 - val_accuracy: 0.9294\n",
      "Epoch 693/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0217 - accuracy: 0.9614 - val_loss: 0.1064 - val_accuracy: 0.9280\n",
      "Epoch 694/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0225 - accuracy: 0.9606 - val_loss: 0.1207 - val_accuracy: 0.9272\n",
      "Epoch 695/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0213 - accuracy: 0.9620 - val_loss: 0.1168 - val_accuracy: 0.9283\n",
      "Epoch 696/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0225 - accuracy: 0.9608 - val_loss: 0.1200 - val_accuracy: 0.9295\n",
      "Epoch 697/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0219 - accuracy: 0.9608 - val_loss: 0.1149 - val_accuracy: 0.9306\n",
      "Epoch 698/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0236 - accuracy: 0.9594 - val_loss: 0.1144 - val_accuracy: 0.9264\n",
      "Epoch 699/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0222 - accuracy: 0.9610 - val_loss: 0.1156 - val_accuracy: 0.9306\n",
      "Epoch 700/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0229 - accuracy: 0.9600 - val_loss: 0.1169 - val_accuracy: 0.9290\n",
      "Epoch 701/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0224 - accuracy: 0.9608 - val_loss: 0.1141 - val_accuracy: 0.9294\n",
      "Epoch 702/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0223 - accuracy: 0.9609 - val_loss: 0.1181 - val_accuracy: 0.9270\n",
      "Epoch 703/1000\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0216 - accuracy: 0.9621 - val_loss: 0.1185 - val_accuracy: 0.9285\n",
      "Epoch 704/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9620 - val_loss: 0.1202 - val_accuracy: 0.9261\n",
      "Epoch 705/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0212 - accuracy: 0.9624 - val_loss: 0.1215 - val_accuracy: 0.9289\n",
      "Epoch 706/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0211 - accuracy: 0.9625 - val_loss: 0.1205 - val_accuracy: 0.9309\n",
      "Epoch 707/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9620 - val_loss: 0.1161 - val_accuracy: 0.9302\n",
      "Epoch 708/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0213 - accuracy: 0.9622 - val_loss: 0.1209 - val_accuracy: 0.9310\n",
      "Epoch 709/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0210 - accuracy: 0.9624 - val_loss: 0.1138 - val_accuracy: 0.9254\n",
      "Epoch 710/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0223 - accuracy: 0.9609 - val_loss: 0.1246 - val_accuracy: 0.9286\n",
      "Epoch 711/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0213 - accuracy: 0.9621 - val_loss: 0.1181 - val_accuracy: 0.9308\n",
      "Epoch 712/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0215 - accuracy: 0.9625 - val_loss: 0.1221 - val_accuracy: 0.9323\n",
      "Epoch 713/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9617 - val_loss: 0.1227 - val_accuracy: 0.9309\n",
      "Epoch 714/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9623 - val_loss: 0.1226 - val_accuracy: 0.9282\n",
      "Epoch 715/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9618 - val_loss: 0.1122 - val_accuracy: 0.9299\n",
      "Epoch 716/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0225 - accuracy: 0.9607 - val_loss: 0.1240 - val_accuracy: 0.9303\n",
      "Epoch 717/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0213 - accuracy: 0.9626 - val_loss: 0.1180 - val_accuracy: 0.9302\n",
      "Epoch 718/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0215 - accuracy: 0.9619 - val_loss: 0.1172 - val_accuracy: 0.9245\n",
      "Epoch 719/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0221 - accuracy: 0.9615 - val_loss: 0.1188 - val_accuracy: 0.9258\n",
      "Epoch 720/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0212 - accuracy: 0.9623 - val_loss: 0.1213 - val_accuracy: 0.9255\n",
      "Epoch 721/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9623 - val_loss: 0.1208 - val_accuracy: 0.9295\n",
      "Epoch 722/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9620 - val_loss: 0.1248 - val_accuracy: 0.9297\n",
      "Epoch 723/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9618 - val_loss: 0.1222 - val_accuracy: 0.9309\n",
      "Epoch 724/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0213 - accuracy: 0.9626 - val_loss: 0.1210 - val_accuracy: 0.9282\n",
      "Epoch 725/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0213 - accuracy: 0.9628 - val_loss: 0.1235 - val_accuracy: 0.9298\n",
      "Epoch 726/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0218 - accuracy: 0.9620 - val_loss: 0.1200 - val_accuracy: 0.9292\n",
      "Epoch 727/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0224 - accuracy: 0.9612 - val_loss: 0.1285 - val_accuracy: 0.9244\n",
      "Epoch 728/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0217 - accuracy: 0.9617 - val_loss: 0.1146 - val_accuracy: 0.9287\n",
      "Epoch 729/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0220 - accuracy: 0.9617 - val_loss: 0.1238 - val_accuracy: 0.9300\n",
      "Epoch 730/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0215 - accuracy: 0.9622 - val_loss: 0.1219 - val_accuracy: 0.9287\n",
      "Epoch 731/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9615 - val_loss: 0.1245 - val_accuracy: 0.9306\n",
      "Epoch 732/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0212 - accuracy: 0.9626 - val_loss: 0.1207 - val_accuracy: 0.9284\n",
      "Epoch 733/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9625 - val_loss: 0.1243 - val_accuracy: 0.9318\n",
      "Epoch 734/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0211 - accuracy: 0.9618 - val_loss: 0.1211 - val_accuracy: 0.9294\n",
      "Epoch 735/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0218 - accuracy: 0.9612 - val_loss: 0.1258 - val_accuracy: 0.9275\n",
      "Epoch 736/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0222 - accuracy: 0.9614 - val_loss: 0.1232 - val_accuracy: 0.9271\n",
      "Epoch 737/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0213 - accuracy: 0.9622 - val_loss: 0.1175 - val_accuracy: 0.9266\n",
      "Epoch 738/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0220 - accuracy: 0.9612 - val_loss: 0.1193 - val_accuracy: 0.9287\n",
      "Epoch 739/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0223 - accuracy: 0.9608 - val_loss: 0.1246 - val_accuracy: 0.9325\n",
      "Epoch 740/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0217 - accuracy: 0.9615 - val_loss: 0.1233 - val_accuracy: 0.9280\n",
      "Epoch 741/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0219 - accuracy: 0.9619 - val_loss: 0.1213 - val_accuracy: 0.9281\n",
      "Epoch 742/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9619 - val_loss: 0.1207 - val_accuracy: 0.9275\n",
      "Epoch 743/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9622 - val_loss: 0.1197 - val_accuracy: 0.9276\n",
      "Epoch 744/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9618 - val_loss: 0.1237 - val_accuracy: 0.9303\n",
      "Epoch 745/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0219 - accuracy: 0.9613 - val_loss: 0.1159 - val_accuracy: 0.9288\n",
      "Epoch 746/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0210 - accuracy: 0.9625 - val_loss: 0.1187 - val_accuracy: 0.9290\n",
      "Epoch 747/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0217 - accuracy: 0.9617 - val_loss: 0.1173 - val_accuracy: 0.9301\n",
      "Epoch 748/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0220 - accuracy: 0.9619 - val_loss: 0.1186 - val_accuracy: 0.9288\n",
      "Epoch 749/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0207 - accuracy: 0.9627 - val_loss: 0.1241 - val_accuracy: 0.9290\n",
      "Epoch 750/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9620 - val_loss: 0.1210 - val_accuracy: 0.9283\n",
      "Epoch 751/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9622 - val_loss: 0.1185 - val_accuracy: 0.9273\n",
      "Epoch 752/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9619 - val_loss: 0.1191 - val_accuracy: 0.9289\n",
      "Epoch 753/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0207 - accuracy: 0.9635 - val_loss: 0.1270 - val_accuracy: 0.9244\n",
      "Epoch 754/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9627 - val_loss: 0.1289 - val_accuracy: 0.9283\n",
      "Epoch 755/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0215 - accuracy: 0.9621 - val_loss: 0.1214 - val_accuracy: 0.9300\n",
      "Epoch 756/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0222 - accuracy: 0.9610 - val_loss: 0.1263 - val_accuracy: 0.9301\n",
      "Epoch 757/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9623 - val_loss: 0.1228 - val_accuracy: 0.9281\n",
      "Epoch 758/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0220 - accuracy: 0.9612 - val_loss: 0.1312 - val_accuracy: 0.9295\n",
      "Epoch 759/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0213 - accuracy: 0.9625 - val_loss: 0.1208 - val_accuracy: 0.9255\n",
      "Epoch 760/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0212 - accuracy: 0.9624 - val_loss: 0.1217 - val_accuracy: 0.9301\n",
      "Epoch 761/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0209 - accuracy: 0.9629 - val_loss: 0.1242 - val_accuracy: 0.9328\n",
      "Epoch 762/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0211 - accuracy: 0.9627 - val_loss: 0.1266 - val_accuracy: 0.9307\n",
      "Epoch 763/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0213 - accuracy: 0.9620 - val_loss: 0.1316 - val_accuracy: 0.9263\n",
      "Epoch 764/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0220 - accuracy: 0.9607 - val_loss: 0.1236 - val_accuracy: 0.9273\n",
      "Epoch 765/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0235 - accuracy: 0.9606 - val_loss: 0.1222 - val_accuracy: 0.9276\n",
      "Epoch 766/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0225 - accuracy: 0.9613 - val_loss: 0.1211 - val_accuracy: 0.9287\n",
      "Epoch 767/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0211 - accuracy: 0.9624 - val_loss: 0.1205 - val_accuracy: 0.9307\n",
      "Epoch 768/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0218 - accuracy: 0.9617 - val_loss: 0.1291 - val_accuracy: 0.9291\n",
      "Epoch 769/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0212 - accuracy: 0.9624 - val_loss: 0.1222 - val_accuracy: 0.9294\n",
      "Epoch 770/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0213 - accuracy: 0.9624 - val_loss: 0.1227 - val_accuracy: 0.9287\n",
      "Epoch 771/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0211 - accuracy: 0.9624 - val_loss: 0.1267 - val_accuracy: 0.9305\n",
      "Epoch 772/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0211 - accuracy: 0.9627 - val_loss: 0.1215 - val_accuracy: 0.9305\n",
      "Epoch 773/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0208 - accuracy: 0.9629 - val_loss: 0.1266 - val_accuracy: 0.9294\n",
      "Epoch 774/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0208 - accuracy: 0.9624 - val_loss: 0.1212 - val_accuracy: 0.9276\n",
      "Epoch 775/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0211 - accuracy: 0.9625 - val_loss: 0.1297 - val_accuracy: 0.9244\n",
      "Epoch 776/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0211 - accuracy: 0.9628 - val_loss: 0.1329 - val_accuracy: 0.9269\n",
      "Epoch 777/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0214 - accuracy: 0.9620 - val_loss: 0.1321 - val_accuracy: 0.9284\n",
      "Epoch 778/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0219 - accuracy: 0.9616 - val_loss: 0.1228 - val_accuracy: 0.9300\n",
      "Epoch 779/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0212 - accuracy: 0.9621 - val_loss: 0.1261 - val_accuracy: 0.9293\n",
      "Epoch 780/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0217 - accuracy: 0.9620 - val_loss: 0.1312 - val_accuracy: 0.9295\n",
      "Epoch 781/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9623 - val_loss: 0.1246 - val_accuracy: 0.9281\n",
      "Epoch 782/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9617 - val_loss: 0.1351 - val_accuracy: 0.9305\n",
      "Epoch 783/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0210 - accuracy: 0.9625 - val_loss: 0.1271 - val_accuracy: 0.9306\n",
      "Epoch 784/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0218 - accuracy: 0.9614 - val_loss: 0.1341 - val_accuracy: 0.9253\n",
      "Epoch 785/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9617 - val_loss: 0.1285 - val_accuracy: 0.9254\n",
      "Epoch 786/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0210 - accuracy: 0.9631 - val_loss: 0.1300 - val_accuracy: 0.9271\n",
      "Epoch 787/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0210 - accuracy: 0.9631 - val_loss: 0.1260 - val_accuracy: 0.9266\n",
      "Epoch 788/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0216 - accuracy: 0.9617 - val_loss: 0.1290 - val_accuracy: 0.9273\n",
      "Epoch 789/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0208 - accuracy: 0.9632 - val_loss: 0.1217 - val_accuracy: 0.9303\n",
      "Epoch 790/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0214 - accuracy: 0.9621 - val_loss: 0.1249 - val_accuracy: 0.9301\n",
      "Epoch 791/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0212 - accuracy: 0.9625 - val_loss: 0.1290 - val_accuracy: 0.9278\n",
      "Epoch 792/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0205 - accuracy: 0.9638 - val_loss: 0.1260 - val_accuracy: 0.9252\n",
      "Epoch 793/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0207 - accuracy: 0.9623 - val_loss: 0.1291 - val_accuracy: 0.9309\n",
      "Epoch 794/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0206 - accuracy: 0.9624 - val_loss: 0.1253 - val_accuracy: 0.9278\n",
      "Epoch 795/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0204 - accuracy: 0.9631 - val_loss: 0.1268 - val_accuracy: 0.9305\n",
      "Epoch 796/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0215 - accuracy: 0.9620 - val_loss: 0.1305 - val_accuracy: 0.9280\n",
      "Epoch 797/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9626 - val_loss: 0.1258 - val_accuracy: 0.9318\n",
      "Epoch 798/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0211 - accuracy: 0.9625 - val_loss: 0.1322 - val_accuracy: 0.9300\n",
      "Epoch 799/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0210 - accuracy: 0.9629 - val_loss: 0.1376 - val_accuracy: 0.9300\n",
      "Epoch 800/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0213 - accuracy: 0.9619 - val_loss: 0.1279 - val_accuracy: 0.9268\n",
      "Epoch 801/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0215 - accuracy: 0.9617 - val_loss: 0.1319 - val_accuracy: 0.9293\n",
      "Epoch 802/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0220 - accuracy: 0.9611 - val_loss: 0.1336 - val_accuracy: 0.9283\n",
      "Epoch 803/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0215 - accuracy: 0.9621 - val_loss: 0.1263 - val_accuracy: 0.9288\n",
      "Epoch 804/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0210 - accuracy: 0.9624 - val_loss: 0.1335 - val_accuracy: 0.9293\n",
      "Epoch 805/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0220 - accuracy: 0.9620 - val_loss: 0.1212 - val_accuracy: 0.9273\n",
      "Epoch 806/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0227 - accuracy: 0.9610 - val_loss: 0.1304 - val_accuracy: 0.9305\n",
      "Epoch 807/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0219 - accuracy: 0.9617 - val_loss: 0.1268 - val_accuracy: 0.9296\n",
      "Epoch 808/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0214 - accuracy: 0.9625 - val_loss: 0.1290 - val_accuracy: 0.9292\n",
      "Epoch 809/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0217 - accuracy: 0.9615 - val_loss: 0.1306 - val_accuracy: 0.9221\n",
      "Epoch 810/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0216 - accuracy: 0.9616 - val_loss: 0.1239 - val_accuracy: 0.9304\n",
      "Epoch 811/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0206 - accuracy: 0.9629 - val_loss: 0.1325 - val_accuracy: 0.9269\n",
      "Epoch 812/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9621 - val_loss: 0.1321 - val_accuracy: 0.9287\n",
      "Epoch 813/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9623 - val_loss: 0.1339 - val_accuracy: 0.9228\n",
      "Epoch 814/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0227 - accuracy: 0.9609 - val_loss: 0.1342 - val_accuracy: 0.9291\n",
      "Epoch 815/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0220 - accuracy: 0.9615 - val_loss: 0.1297 - val_accuracy: 0.9268\n",
      "Epoch 816/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0217 - accuracy: 0.9614 - val_loss: 0.1294 - val_accuracy: 0.9300\n",
      "Epoch 817/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0210 - accuracy: 0.9621 - val_loss: 0.1290 - val_accuracy: 0.9270\n",
      "Epoch 818/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0211 - accuracy: 0.9621 - val_loss: 0.1269 - val_accuracy: 0.9297\n",
      "Epoch 819/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0209 - accuracy: 0.9632 - val_loss: 0.1352 - val_accuracy: 0.9271\n",
      "Epoch 820/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0204 - accuracy: 0.9630 - val_loss: 0.1275 - val_accuracy: 0.9294\n",
      "Epoch 821/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0210 - accuracy: 0.9627 - val_loss: 0.1314 - val_accuracy: 0.9286\n",
      "Epoch 822/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0216 - accuracy: 0.9617 - val_loss: 0.1353 - val_accuracy: 0.9265\n",
      "Epoch 823/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0213 - accuracy: 0.9617 - val_loss: 0.1429 - val_accuracy: 0.9284\n",
      "Epoch 824/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0215 - accuracy: 0.9615 - val_loss: 0.1293 - val_accuracy: 0.9306\n",
      "Epoch 825/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0216 - accuracy: 0.9613 - val_loss: 0.1302 - val_accuracy: 0.9295\n",
      "Epoch 826/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0211 - accuracy: 0.9629 - val_loss: 0.1322 - val_accuracy: 0.9269\n",
      "Epoch 827/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0221 - accuracy: 0.9608 - val_loss: 0.1309 - val_accuracy: 0.9262\n",
      "Epoch 828/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0214 - accuracy: 0.9621 - val_loss: 0.1263 - val_accuracy: 0.9259\n",
      "Epoch 829/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0208 - accuracy: 0.9628 - val_loss: 0.1313 - val_accuracy: 0.9308\n",
      "Epoch 830/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0215 - accuracy: 0.9618 - val_loss: 0.1297 - val_accuracy: 0.9318\n",
      "Epoch 831/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0205 - accuracy: 0.9631 - val_loss: 0.1314 - val_accuracy: 0.9307\n",
      "Epoch 832/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0204 - accuracy: 0.9632 - val_loss: 0.1291 - val_accuracy: 0.9289\n",
      "Epoch 833/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0204 - accuracy: 0.9630 - val_loss: 0.1299 - val_accuracy: 0.9293\n",
      "Epoch 834/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0212 - accuracy: 0.9624 - val_loss: 0.1248 - val_accuracy: 0.9292\n",
      "Epoch 835/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0212 - accuracy: 0.9619 - val_loss: 0.1327 - val_accuracy: 0.9295\n",
      "Epoch 836/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0210 - accuracy: 0.9623 - val_loss: 0.1312 - val_accuracy: 0.9288\n",
      "Epoch 837/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0204 - accuracy: 0.9628 - val_loss: 0.1303 - val_accuracy: 0.9303\n",
      "Epoch 838/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0214 - accuracy: 0.9623 - val_loss: 0.1323 - val_accuracy: 0.9260\n",
      "Epoch 839/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0215 - accuracy: 0.9623 - val_loss: 0.1322 - val_accuracy: 0.9261\n",
      "Epoch 840/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0211 - accuracy: 0.9629 - val_loss: 0.1301 - val_accuracy: 0.9271\n",
      "Epoch 841/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0219 - accuracy: 0.9615 - val_loss: 0.1305 - val_accuracy: 0.9265\n",
      "Epoch 842/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0229 - accuracy: 0.9601 - val_loss: 0.1276 - val_accuracy: 0.9289\n",
      "Epoch 843/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0218 - accuracy: 0.9619 - val_loss: 0.1358 - val_accuracy: 0.9321\n",
      "Epoch 844/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0218 - accuracy: 0.9620 - val_loss: 0.1196 - val_accuracy: 0.9277\n",
      "Epoch 845/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0211 - accuracy: 0.9620 - val_loss: 0.1293 - val_accuracy: 0.9318\n",
      "Epoch 846/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9617 - val_loss: 0.1289 - val_accuracy: 0.9280\n",
      "Epoch 847/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0221 - accuracy: 0.9613 - val_loss: 0.1289 - val_accuracy: 0.9293\n",
      "Epoch 848/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0206 - accuracy: 0.9627 - val_loss: 0.1400 - val_accuracy: 0.9290\n",
      "Epoch 849/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0208 - accuracy: 0.9628 - val_loss: 0.1315 - val_accuracy: 0.9291\n",
      "Epoch 850/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0203 - accuracy: 0.9635 - val_loss: 0.1331 - val_accuracy: 0.9280\n",
      "Epoch 851/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0209 - accuracy: 0.9624 - val_loss: 0.1275 - val_accuracy: 0.9288\n",
      "Epoch 852/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0203 - accuracy: 0.9628 - val_loss: 0.1348 - val_accuracy: 0.9308\n",
      "Epoch 853/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0211 - accuracy: 0.9619 - val_loss: 0.1386 - val_accuracy: 0.9308\n",
      "Epoch 854/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0211 - accuracy: 0.9625 - val_loss: 0.1383 - val_accuracy: 0.9258\n",
      "Epoch 855/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0213 - accuracy: 0.9624 - val_loss: 0.1343 - val_accuracy: 0.9252\n",
      "Epoch 856/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0212 - accuracy: 0.9619 - val_loss: 0.1337 - val_accuracy: 0.9287\n",
      "Epoch 857/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0211 - accuracy: 0.9625 - val_loss: 0.1317 - val_accuracy: 0.9299\n",
      "Epoch 858/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0204 - accuracy: 0.9632 - val_loss: 0.1401 - val_accuracy: 0.9248\n",
      "Epoch 859/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9620 - val_loss: 0.1265 - val_accuracy: 0.9309\n",
      "Epoch 860/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0210 - accuracy: 0.9629 - val_loss: 0.1297 - val_accuracy: 0.9299\n",
      "Epoch 861/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0206 - accuracy: 0.9631 - val_loss: 0.1325 - val_accuracy: 0.9294\n",
      "Epoch 862/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0213 - accuracy: 0.9624 - val_loss: 0.1312 - val_accuracy: 0.9276\n",
      "Epoch 863/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0208 - accuracy: 0.9625 - val_loss: 0.1341 - val_accuracy: 0.9281\n",
      "Epoch 864/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0227 - accuracy: 0.9606 - val_loss: 0.1354 - val_accuracy: 0.9302\n",
      "Epoch 865/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9614 - val_loss: 0.1354 - val_accuracy: 0.9265\n",
      "Epoch 866/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0208 - accuracy: 0.9625 - val_loss: 0.1326 - val_accuracy: 0.9307\n",
      "Epoch 867/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0206 - accuracy: 0.9632 - val_loss: 0.1339 - val_accuracy: 0.9293\n",
      "Epoch 868/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0212 - accuracy: 0.9624 - val_loss: 0.1389 - val_accuracy: 0.9296\n",
      "Epoch 869/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0214 - accuracy: 0.9619 - val_loss: 0.1371 - val_accuracy: 0.9302\n",
      "Epoch 870/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0202 - accuracy: 0.9634 - val_loss: 0.1410 - val_accuracy: 0.9292\n",
      "Epoch 871/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0211 - accuracy: 0.9620 - val_loss: 0.1357 - val_accuracy: 0.9270\n",
      "Epoch 872/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0208 - accuracy: 0.9627 - val_loss: 0.1402 - val_accuracy: 0.9285\n",
      "Epoch 873/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0216 - accuracy: 0.9617 - val_loss: 0.1387 - val_accuracy: 0.9301\n",
      "Epoch 874/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0216 - accuracy: 0.9622 - val_loss: 0.1348 - val_accuracy: 0.9282\n",
      "Epoch 875/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0210 - accuracy: 0.9625 - val_loss: 0.1357 - val_accuracy: 0.9258\n",
      "Epoch 876/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0208 - accuracy: 0.9622 - val_loss: 0.1416 - val_accuracy: 0.9246\n",
      "Epoch 877/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0215 - accuracy: 0.9618 - val_loss: 0.1283 - val_accuracy: 0.9296\n",
      "Epoch 878/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0219 - accuracy: 0.9617 - val_loss: 0.1467 - val_accuracy: 0.9278\n",
      "Epoch 879/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0218 - accuracy: 0.9618 - val_loss: 0.1344 - val_accuracy: 0.9289\n",
      "Epoch 880/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0220 - accuracy: 0.9611 - val_loss: 0.1375 - val_accuracy: 0.9284\n",
      "Epoch 881/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0210 - accuracy: 0.9624 - val_loss: 0.1427 - val_accuracy: 0.9288\n",
      "Epoch 882/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0216 - accuracy: 0.9621 - val_loss: 0.1341 - val_accuracy: 0.9261\n",
      "Epoch 883/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0220 - accuracy: 0.9613 - val_loss: 0.1260 - val_accuracy: 0.9294\n",
      "Epoch 884/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0215 - accuracy: 0.9621 - val_loss: 0.1279 - val_accuracy: 0.9298\n",
      "Epoch 885/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0212 - accuracy: 0.9624 - val_loss: 0.1276 - val_accuracy: 0.9273\n",
      "Epoch 886/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0214 - accuracy: 0.9623 - val_loss: 0.1324 - val_accuracy: 0.9291\n",
      "Epoch 887/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0217 - accuracy: 0.9615 - val_loss: 0.1341 - val_accuracy: 0.9257\n",
      "Epoch 888/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0207 - accuracy: 0.9627 - val_loss: 0.1343 - val_accuracy: 0.9266\n",
      "Epoch 889/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0203 - accuracy: 0.9632 - val_loss: 0.1376 - val_accuracy: 0.9307\n",
      "Epoch 890/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0202 - accuracy: 0.9632 - val_loss: 0.1323 - val_accuracy: 0.9283\n",
      "Epoch 891/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0212 - accuracy: 0.9623 - val_loss: 0.1371 - val_accuracy: 0.9283\n",
      "Epoch 892/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0213 - accuracy: 0.9618 - val_loss: 0.1353 - val_accuracy: 0.9273\n",
      "Epoch 893/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0209 - accuracy: 0.9623 - val_loss: 0.1378 - val_accuracy: 0.9298\n",
      "Epoch 894/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0209 - accuracy: 0.9627 - val_loss: 0.1340 - val_accuracy: 0.9291\n",
      "Epoch 895/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0207 - accuracy: 0.9627 - val_loss: 0.1341 - val_accuracy: 0.9309\n",
      "Epoch 896/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0205 - accuracy: 0.9631 - val_loss: 0.1399 - val_accuracy: 0.9290\n",
      "Epoch 897/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0207 - accuracy: 0.9632 - val_loss: 0.1327 - val_accuracy: 0.9280\n",
      "Epoch 898/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0206 - accuracy: 0.9627 - val_loss: 0.1370 - val_accuracy: 0.9280\n",
      "Epoch 899/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0210 - accuracy: 0.9626 - val_loss: 0.1369 - val_accuracy: 0.9292\n",
      "Epoch 900/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0208 - accuracy: 0.9629 - val_loss: 0.1329 - val_accuracy: 0.9301\n",
      "Epoch 901/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0217 - accuracy: 0.9617 - val_loss: 0.1430 - val_accuracy: 0.9278\n",
      "Epoch 902/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0217 - accuracy: 0.9616 - val_loss: 0.1361 - val_accuracy: 0.9273\n",
      "Epoch 903/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0215 - accuracy: 0.9615 - val_loss: 0.1323 - val_accuracy: 0.9267\n",
      "Epoch 904/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0210 - accuracy: 0.9630 - val_loss: 0.1387 - val_accuracy: 0.9236\n",
      "Epoch 905/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9618 - val_loss: 0.1360 - val_accuracy: 0.9296\n",
      "Epoch 906/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0201 - accuracy: 0.9634 - val_loss: 0.1406 - val_accuracy: 0.9279\n",
      "Epoch 907/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0208 - accuracy: 0.9627 - val_loss: 0.1412 - val_accuracy: 0.9277\n",
      "Epoch 908/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0208 - accuracy: 0.9630 - val_loss: 0.1454 - val_accuracy: 0.9237\n",
      "Epoch 909/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0210 - accuracy: 0.9622 - val_loss: 0.1457 - val_accuracy: 0.9273\n",
      "Epoch 910/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0211 - accuracy: 0.9622 - val_loss: 0.1459 - val_accuracy: 0.9313\n",
      "Epoch 911/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0207 - accuracy: 0.9630 - val_loss: 0.1392 - val_accuracy: 0.9279\n",
      "Epoch 912/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9618 - val_loss: 0.1374 - val_accuracy: 0.9280\n",
      "Epoch 913/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0236 - accuracy: 0.9598 - val_loss: 0.1373 - val_accuracy: 0.9273\n",
      "Epoch 914/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0223 - accuracy: 0.9603 - val_loss: 0.1391 - val_accuracy: 0.9280\n",
      "Epoch 915/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9616 - val_loss: 0.1417 - val_accuracy: 0.9263\n",
      "Epoch 916/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0218 - accuracy: 0.9612 - val_loss: 0.1326 - val_accuracy: 0.9278\n",
      "Epoch 917/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0209 - accuracy: 0.9626 - val_loss: 0.1394 - val_accuracy: 0.9256\n",
      "Epoch 918/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0204 - accuracy: 0.9629 - val_loss: 0.1390 - val_accuracy: 0.9286\n",
      "Epoch 919/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0207 - accuracy: 0.9624 - val_loss: 0.1364 - val_accuracy: 0.9278\n",
      "Epoch 920/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9615 - val_loss: 0.1403 - val_accuracy: 0.9262\n",
      "Epoch 921/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0209 - accuracy: 0.9630 - val_loss: 0.1466 - val_accuracy: 0.9278\n",
      "Epoch 922/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9622 - val_loss: 0.1429 - val_accuracy: 0.9256\n",
      "Epoch 923/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0213 - accuracy: 0.9619 - val_loss: 0.1410 - val_accuracy: 0.9287\n",
      "Epoch 924/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0204 - accuracy: 0.9625 - val_loss: 0.1287 - val_accuracy: 0.9279\n",
      "Epoch 925/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9620 - val_loss: 0.1420 - val_accuracy: 0.9277\n",
      "Epoch 926/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0212 - accuracy: 0.9622 - val_loss: 0.1373 - val_accuracy: 0.9310\n",
      "Epoch 927/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0210 - accuracy: 0.9626 - val_loss: 0.1435 - val_accuracy: 0.9304\n",
      "Epoch 928/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9618 - val_loss: 0.1469 - val_accuracy: 0.9274\n",
      "Epoch 929/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0210 - accuracy: 0.9624 - val_loss: 0.1339 - val_accuracy: 0.9256\n",
      "Epoch 930/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0214 - accuracy: 0.9623 - val_loss: 0.1341 - val_accuracy: 0.9281\n",
      "Epoch 931/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0211 - accuracy: 0.9623 - val_loss: 0.1345 - val_accuracy: 0.9278\n",
      "Epoch 932/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0202 - accuracy: 0.9633 - val_loss: 0.1397 - val_accuracy: 0.9292\n",
      "Epoch 933/1000\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0202 - accuracy: 0.9633 - val_loss: 0.1380 - val_accuracy: 0.9263\n",
      "Epoch 934/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0213 - accuracy: 0.9621 - val_loss: 0.1426 - val_accuracy: 0.9284\n",
      "Epoch 935/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0215 - accuracy: 0.9621 - val_loss: 0.1450 - val_accuracy: 0.9255\n",
      "Epoch 936/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0213 - accuracy: 0.9622 - val_loss: 0.1422 - val_accuracy: 0.9271\n",
      "Epoch 937/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0207 - accuracy: 0.9634 - val_loss: 0.1386 - val_accuracy: 0.9282\n",
      "Epoch 938/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0211 - accuracy: 0.9623 - val_loss: 0.1475 - val_accuracy: 0.9295\n",
      "Epoch 939/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0218 - accuracy: 0.9616 - val_loss: 0.1401 - val_accuracy: 0.9302\n",
      "Epoch 940/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0210 - accuracy: 0.9627 - val_loss: 0.1415 - val_accuracy: 0.9295\n",
      "Epoch 941/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0205 - accuracy: 0.9629 - val_loss: 0.1355 - val_accuracy: 0.9303\n",
      "Epoch 942/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0207 - accuracy: 0.9633 - val_loss: 0.1418 - val_accuracy: 0.9311\n",
      "Epoch 943/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9618 - val_loss: 0.1329 - val_accuracy: 0.9238\n",
      "Epoch 944/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0207 - accuracy: 0.9627 - val_loss: 0.1345 - val_accuracy: 0.9289\n",
      "Epoch 945/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0207 - accuracy: 0.9631 - val_loss: 0.1351 - val_accuracy: 0.9293\n",
      "Epoch 946/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0211 - accuracy: 0.9626 - val_loss: 0.1405 - val_accuracy: 0.9287\n",
      "Epoch 947/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9628 - val_loss: 0.1368 - val_accuracy: 0.9287\n",
      "Epoch 948/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0206 - accuracy: 0.9632 - val_loss: 0.1387 - val_accuracy: 0.9281\n",
      "Epoch 949/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9619 - val_loss: 0.1297 - val_accuracy: 0.9265\n",
      "Epoch 950/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0231 - accuracy: 0.9602 - val_loss: 0.1466 - val_accuracy: 0.9295\n",
      "Epoch 951/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0209 - accuracy: 0.9624 - val_loss: 0.1337 - val_accuracy: 0.9269\n",
      "Epoch 952/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0210 - accuracy: 0.9626 - val_loss: 0.1329 - val_accuracy: 0.9304\n",
      "Epoch 953/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0206 - accuracy: 0.9630 - val_loss: 0.1430 - val_accuracy: 0.9282\n",
      "Epoch 954/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0203 - accuracy: 0.9632 - val_loss: 0.1437 - val_accuracy: 0.9282\n",
      "Epoch 955/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0203 - accuracy: 0.9638 - val_loss: 0.1360 - val_accuracy: 0.9303\n",
      "Epoch 956/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0206 - accuracy: 0.9631 - val_loss: 0.1377 - val_accuracy: 0.9282\n",
      "Epoch 957/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0215 - accuracy: 0.9622 - val_loss: 0.1377 - val_accuracy: 0.9266\n",
      "Epoch 958/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0203 - accuracy: 0.9634 - val_loss: 0.1340 - val_accuracy: 0.9264\n",
      "Epoch 959/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9618 - val_loss: 0.1339 - val_accuracy: 0.9244\n",
      "Epoch 960/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0211 - accuracy: 0.9624 - val_loss: 0.1382 - val_accuracy: 0.9283\n",
      "Epoch 961/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0220 - accuracy: 0.9615 - val_loss: 0.1437 - val_accuracy: 0.9314\n",
      "Epoch 962/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0228 - accuracy: 0.9610 - val_loss: 0.1420 - val_accuracy: 0.9297\n",
      "Epoch 963/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9623 - val_loss: 0.1452 - val_accuracy: 0.9290\n",
      "Epoch 964/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0206 - accuracy: 0.9632 - val_loss: 0.1408 - val_accuracy: 0.9302\n",
      "Epoch 965/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0212 - accuracy: 0.9622 - val_loss: 0.1318 - val_accuracy: 0.9268\n",
      "Epoch 966/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0209 - accuracy: 0.9628 - val_loss: 0.1385 - val_accuracy: 0.9300\n",
      "Epoch 967/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0208 - accuracy: 0.9627 - val_loss: 0.1360 - val_accuracy: 0.9298\n",
      "Epoch 968/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0205 - accuracy: 0.9634 - val_loss: 0.1421 - val_accuracy: 0.9294\n",
      "Epoch 969/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0204 - accuracy: 0.9630 - val_loss: 0.1376 - val_accuracy: 0.9280\n",
      "Epoch 970/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0212 - accuracy: 0.9622 - val_loss: 0.1359 - val_accuracy: 0.9276\n",
      "Epoch 971/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0215 - accuracy: 0.9618 - val_loss: 0.1352 - val_accuracy: 0.9259\n",
      "Epoch 972/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0212 - accuracy: 0.9623 - val_loss: 0.1395 - val_accuracy: 0.9319\n",
      "Epoch 973/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0215 - accuracy: 0.9623 - val_loss: 0.1406 - val_accuracy: 0.9288\n",
      "Epoch 974/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0215 - accuracy: 0.9621 - val_loss: 0.1381 - val_accuracy: 0.9237\n",
      "Epoch 975/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0205 - accuracy: 0.9632 - val_loss: 0.1485 - val_accuracy: 0.9277\n",
      "Epoch 976/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0205 - accuracy: 0.9631 - val_loss: 0.1431 - val_accuracy: 0.9277\n",
      "Epoch 977/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0211 - accuracy: 0.9622 - val_loss: 0.1533 - val_accuracy: 0.9252\n",
      "Epoch 978/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0205 - accuracy: 0.9629 - val_loss: 0.1585 - val_accuracy: 0.9287\n",
      "Epoch 979/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0222 - accuracy: 0.9613 - val_loss: 0.1457 - val_accuracy: 0.9311\n",
      "Epoch 980/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0210 - accuracy: 0.9623 - val_loss: 0.1348 - val_accuracy: 0.9289\n",
      "Epoch 981/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0210 - accuracy: 0.9624 - val_loss: 0.1450 - val_accuracy: 0.9270\n",
      "Epoch 982/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0207 - accuracy: 0.9630 - val_loss: 0.1356 - val_accuracy: 0.9315\n",
      "Epoch 983/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0206 - accuracy: 0.9625 - val_loss: 0.1417 - val_accuracy: 0.9290\n",
      "Epoch 984/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0208 - accuracy: 0.9620 - val_loss: 0.1396 - val_accuracy: 0.9315\n",
      "Epoch 985/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0206 - accuracy: 0.9631 - val_loss: 0.1434 - val_accuracy: 0.9305\n",
      "Epoch 986/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0212 - accuracy: 0.9621 - val_loss: 0.1469 - val_accuracy: 0.9257\n",
      "Epoch 987/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0209 - accuracy: 0.9629 - val_loss: 0.1432 - val_accuracy: 0.9286\n",
      "Epoch 988/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0207 - accuracy: 0.9631 - val_loss: 0.1431 - val_accuracy: 0.9298\n",
      "Epoch 989/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0204 - accuracy: 0.9632 - val_loss: 0.1428 - val_accuracy: 0.9273\n",
      "Epoch 990/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0220 - accuracy: 0.9618 - val_loss: 0.1643 - val_accuracy: 0.9276\n",
      "Epoch 991/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0221 - accuracy: 0.9609 - val_loss: 0.1481 - val_accuracy: 0.9273\n",
      "Epoch 992/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0212 - accuracy: 0.9625 - val_loss: 0.1426 - val_accuracy: 0.9293\n",
      "Epoch 993/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0204 - accuracy: 0.9637 - val_loss: 0.1463 - val_accuracy: 0.9291\n",
      "Epoch 994/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0217 - accuracy: 0.9617 - val_loss: 0.1453 - val_accuracy: 0.9194\n",
      "Epoch 995/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9616 - val_loss: 0.1474 - val_accuracy: 0.9294\n",
      "Epoch 996/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0213 - accuracy: 0.9622 - val_loss: 0.1429 - val_accuracy: 0.9300\n",
      "Epoch 997/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0211 - accuracy: 0.9629 - val_loss: 0.1487 - val_accuracy: 0.9287\n",
      "Epoch 998/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0211 - accuracy: 0.9620 - val_loss: 0.1500 - val_accuracy: 0.9274\n",
      "Epoch 999/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0207 - accuracy: 0.9625 - val_loss: 0.1478 - val_accuracy: 0.9281\n",
      "Epoch 1000/1000\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0217 - accuracy: 0.9620 - val_loss: 0.1608 - val_accuracy: 0.9277\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    batch_size=100, \n",
    "                    epochs=1000,\n",
    "                    verbose=1, \n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 50s 824us/step - loss: 0.0235 - accuracy: 0.9612\n",
      "loss(train): 0.02346\n",
      "accuracy(train): 0.9612\n",
      "\n",
      "10000/10000 [==============================] - 8s 750us/step - loss: 0.1608 - accuracy: 0.9277\n",
      "loss(test): 0.1608\n",
      "accuracy(test): 0.9277\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss, train_acc = model.evaluate(X_train, y_train,batch_size=1, verbose=1)\n",
    "print(\"loss(train): {:.4}\".format(train_loss))\n",
    "print(\"accuracy(train): {:.4}\".format(train_acc))\n",
    "\n",
    "print()\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test,batch_size=1,verbose=1)\n",
    "print(\"loss(test): {:.4}\".format(test_loss))\n",
    "print(\"accuracy(test): {:.4}\".format(test_acc))\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               200960    \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 203,530\n",
      "Trainable params: 203,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae11be1b6255ba9be031dc28287545f08e3e06e0be9d31d8cbbfad76c747be65"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('quantum')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
